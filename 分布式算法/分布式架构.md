## RPC
>RPC 是O一种语言级别的通讯协议，它允许运行于一台计算机上的程序以某种管道作为通讯媒介(即传输协议的网络)，去调用另外一个地址空间(通常为网络上的另外一台计算机)。

几种进程间通讯机制(Inter-Process Communication，IPC)：
- 管道或具名管道(Named Pipe)，管道其实类似于两个进程之间的桥梁，用于进程间传递少量的字符流或字节流。
- 信号(Signal) 信号是用来通知目标进程有某种事情发生的。
- 信号量(Semaphore) 信号量是用于两个进程之间同步协作的手段，相当于操作系统提供的一个特殊变量。
- 消息队列(Message Queue)，消息队列克服了信号承载信息量少、管道只能用于无格式字节流，以及缓冲区大小受限等缺点，但实时性相对受限。
- 共享内存(Shared Memory) 允许多个进程访问同一块内存空间，这是效率最高的进程间通信方式。进程的内存地址空间是独立隔离的，但操作系统提供了让进程主动创建、映射、分离、控制某一块内存的接口。
- 本地套接字接口(IPC Socket) 套接字接口，是更为普适的进程间通信机制，可用于不同机器之间的进程通信。
## RPC需要解决的三个基本问题：
1. 如何表示数据？
将交互上方涉及的数据，转换为某种实现约定好的中立数据流格式来传输，将数据流转换会不同语言中对应的数据类型来使用。**就是序列化与反序列化**
2. 如何传递数据？
准确地说，如何传递数据是指如何通过网络，在两个服务Endpoint之间相互操作、交换数据。这里"传递数据"通常指的是应用层协议，实际传输一般是基于标准的TCP、UDP等传输层协议来完成的。
3. 如何表示方法？
简单的方式是：只要给程序中的每个方法，都规定一个通用的又绝对不会重复的编号；在调用的时候，直接传这个编号就可以找到对应的方法。

## Rest
Rest与RPC在思想上存在差异的核心，是抽象的目标不一样，也就是面向资源编程思想与面向过程的编程思想之间的区别。

Rest，即"表征状态转移" (Representational State Transer)的缩写，REST中的一些关键概念：
- 资源(Resource)
- 表征(Representation)，"表征"这个概念是指信息与用户交互时的表示形式。
- 状态(State)，在特定语境中才能产生的上下文信息就被称为"状态"。
- 转移(Transfer)，服务器通过某种方式，把"用户当前阅读的文章"转变成"下一篇章"，这就被称为"表征状态转移".

### RESTFul风格的系统特征
- 服务端与客户端分离(Client-Server)
- 无状态(Stateless)
- 可缓存(Cacheability)
- 分层系统(Layered System)
- 统一接口(Uniform Interface)
- 按需代码(Code-On-Demand)，例如Java Applet、WebAssembly。

### REST提出以主体进行服务设计的风格，为它带来了不少好处：
- 降低了服务接口的学习成本
- 资源天然具有集合与层次结构
- REST绑定于HTTP协议

## Richardson成熟度模型(Richardson Maturity Model，RMM)
Richardson将服务接口按照"REST的程度"，从低到高分为0至3共4级：
1. The Swamp of Plain Old XML：完全不REST。
2. Resources：开始引入资源的概念。
3. HTTP Verbs：引入统一接口，映射到HTTP协议的方法上。
4. Hypermedia Controls(超文本驱动)。
![[Pasted image 20250826134455.png]]
### REST的不足与争议
- 面向资源的编程思想只适合做CRUD，只有面向过程、面向对象编程才能处理真正复杂的业务逻辑。（针对那些比较抽象的场景，如果确实不好把 HTTP 方法映射为资源的所需操作，REST 也并不会刻板地要求一定要做映射。这时，用户可以使用自定义方法，按 Google 推荐的 REST API 风格来拓展 HTTP 标准方法。）
- REST与HTTP完全绑定，不适用于要求高性能传输的场景中。
- REST不利于事务支持。
- REST没有传输可靠性支持，应对传输可靠性最简单粗暴的做法，就是把消息再重发一遍。这种简单处理能够成立的前提，是服务具有幂等性(Idempotency)。
- REST缺乏对资源进行"部分"和"批量的处理能力"。如果要在REST上实现"部分"操作的能力，只能自己在GET方法的Endpoint上设计各种参数。而要解决批量操作这类问题，目前一种从理论上看还比较优秀的解决方案是GraphQL。

## 本地事务
ACID中的A、I、D是手段，C是目的，AID具有正交性。

《ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging》着重解决了事务的 ACID 三个属性中，原子性（A）和持久性（D）在算法层面上应当如何实现；

而另一篇《ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes》则是现代数据库隔离性（I）奠基式的文章。

### 实现原子性与持久性的实现方式
- Commit Logging（较具代表性的是阿里的 OceanBase）
为了能够顺利的地完成奔溃恢复，在磁盘中写数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的值，必须将修改数据这个操作所需的全部信息(上下文)，以日志的形式先记录到磁盘中。

只有在日志记录全部都安全落盘，见到代表事务成功提交的"Commit Record"后，数据库才会根据日志上的信息对真正的数据进行修改，修改完成后，在日志中加入一条"End Record"表示事务已完成持久化，这种事务实现方法被称为"Commit Logging"。

Commit Logging存在一个巨大的缺陷：所有对数据的真实修改都必须发生在事务提交、日志写入了Commit Record之后，这一点对提升数据库的性能是很不利的。

- Shadow Paging，有点类似于copy on write。
- Write-Ahead Logging(ARIES提出来的)，Write-Ahead其实就是允许在事务提交之前提现写入变动数据的意思。
>Write-Ahead Logging 先将何时写入数据，按照事务提交时点为界，分为了FORCE和STEAL两类：
>- **FORCE:** 当事务提交后，要求变动数据必须同时完成写入则称为FORCE，如果不强制变动数据必须同时完成写入则称为NO-FORCE。现实中绝大多数数据库采用的都是NO-FORCE策略，只要有了日志，变动数据随时可以持久化，从优化磁盘I/O性能考虑，没有必要强制数据写入立即进行。
>- **STEAL:** 在事务提交前，允许变动数据提前写入则称为STEAL，不允许则称为NO-STEAL。STEAL有利于利用空闲I/O资源，也有利于节省数据库缓存区的内存。

Write-Ahead Logging允许No-FORCE，也允许STEAL，它给出的解决办法是增加另一种称为Undo Log的日志。当变动数据写入磁盘前，必须先记录Undo Log，写明修改那个位置的数据、从什么值改成什么值，以便在事务回滚或者奔溃恢复时，根据Undo Log对提前写入的数据变动进行擦除。

由于Uno Log的加入，Write-Ahead Logging在奔溃恢复时，会因此经历以下三个阶段：
- **分析阶段(Analysis):** 该阶段从最后一次检查点(Checkpoint，可理解为在这个点之前所有应该持久化的变动都已经安全落盘)开始扫描，找出所有没有End Record的事务，组成待恢复的事务集合(一般包括Transaction Table和Dirty Page Table).
- **重做阶段(Redo)**：该阶段以及分析阶段中，产生的待恢复的事务集合来重演历史，找出所有包含Commit Record的日志，将它们写入磁盘，写入完成后增加一条End Record，然后移除出待恢复事务集合。
- **回滚阶段(Undo)：** 该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要恢复的事务，根据Undo Log中的信息回滚这些事务。
![[Pasted image 20250826172442.png]]

## 本地事务的隔离级别
### **可串行化**
串行化访问提供了强度更高的隔离性,ANSI/ISO SQL-92中定义的最高等级的隔离级别便是可串行化(Serializable)。

可串行化比较符合普通程序员对数据竞争加锁的理解，如果不考虑性能的话，对事务所有读、写的数据全都加上读锁、写锁和范围所即可(这种可串行化的实现方案称为 Two-Phase Lock)。
### **可重复读**
可重复读(Repeatable Read)的意思就是对事务所涉及到的数据加读锁和写锁，并且一直持续到事务结束，但不再加范围锁。

可重复读比可串行化弱化的地方在于幻读问题(Phatom Reads)，幻读问题其实也就是一个事务遭到其他事务的影响隔离性被破坏的表现。

**需要注意**，这里的介绍实际上是以ARIES理论作为讨论目标的，而具体的数据库并不一定要完全遵照这个理论去实现。例如：Mysql/InnoDB的默认隔离级别是可重复读，但它在只读事务中就可以完全避免幻读问题(Mysql中加间隙锁(范围锁的一种实现))。
### **读已提交**
读已提交(Read Commited)对事务涉及到的数据加的写锁，会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。

读已提交比可重复读弱化的地方在于**不可重复读(Non-Repeatab Reads)问题**，该问题是指在事务执行过程中，对同一行数据的两次查询得到了不同的结果。
### **读未提交**
读未提交(Read Uncommited)对事务涉及到的数据只加写锁，这会一直持续到事务结束，但完全不加读锁。

读未提交比读已提交弱化的地方在于**脏读问题(Dirty Reads)**，它是指在事务执行过程中，一个事务读取到了另一个事务未提交的数据。

```ad-note
**其实，不同隔离级别以及幻读、脏读等问题都只是表面现象，它们是各种锁在不同加锁时间上组合应用所产生的结果，锁才是根本的原因。**
```

## MVCC基础
>针对"一个事务读 + 另一个事务写"的隔离问题，有一种名为"多版本并发控制"（Multi-Version Concurrency Control，MVCC)的无锁优化方案被主流的商业数据库广泛采用。

**MVCC是一种读取优化策略，它的"无锁"是特指读取时不需要加锁。** MVCC的基本思路是读数据库的任何修改不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。

不妨将其理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION 和 DELETE_VERSION，这两个字段记录的值都是事务 ID（事务 ID 是一个全局严格递增的数值），然后：
- 数据被插入时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。
- 数据被删除时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。
- 数据被修改时：将修改视为“删除旧数据，插入新数据”，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。

此时，当有另外一个事务要读取这些发生了变化的数据时，会根据隔离级别来决定到底应该读取哪个版本的数据：

- 隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。
- 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。

**MVCC 是只针对“读 + 写”场景的优化，如果是两个事务同时修改数据，即“写 + 写”的情况，那就没有多少优化的空间了，加锁几乎是唯一可行的解决方案。**

## XA 全局事务
### **两段式提交**
![[Pasted image 20250827151040.png]]
两段式提交有三个非常明显的缺点：
- 单点问题：协调者在两段式提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送Commit或者Rollback的指令，那所有参与者都必须一直等待。
- 性能问题：两段提交过程中，所有参与者相当于被绑定称为一个统一调度的整体，期间要经过两次远程服务调用、三次数据持久化(准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入Commit Record)，整个过程将持续到参与者集群中最慢的那一个处理操作结束位置。
- 一致性风险：当网络稳定性和宕机恢复能力的假设不成立时，两段式提交可能会出现一致性问题。
### **三段式提交**
**在事务需要回滚的场景中，三段式的性能通常要比两段式好很多，但在事务能够正常提交的场景中，两段式和三段式提交的性能都很差，三段式因为多了一次询问，性能还要更差一些。**

在三段式提交中，如果协调者在 PreCommit 阶段开始之后发生了宕机，参与者没有能等到 DoCommit 的消息的话，默认的操作策略将是提交事务而不是回滚事务或者持续等待。
![[Pasted image 20250827151902.png]]

## 可靠消息队列
![[Pasted image 20250827170415.png]]
消息表，里面存入一条消息：“事务 ID：UUID；扣款：100 元（状态：已完成）；仓库出库《深入理解 Java 虚拟机》：1 本（状态：进行中）；某商家收款：100 元（状态：进行中）”。注意，这个步骤中“扣款业务”和“写入消息”是依靠同一个本地事务写入自身数据库的。

前面这种靠着持续重试来保证可靠性的操作，在计算机中就非常常见，它有个专门的名字，叫做"最大努力交付"(Best-Effort Delivery)，而"可靠事件队列"有一种更普通的形式，被称为"最大努力一次提交"(Best-Effort 1PC)，意思就是系统会把最有可能出错的业务，以本地事务的方式完成后，通过不断重试的方式(不限于消息系统)来促使同个事务的其他关联业务完成。

可靠消息队列的整个实现过程完全没有任何隔离性可言。
## TCC事务的实现过程
TCC方案，天生适合用于需要强隔离性的分布式事务中。它是一种业务侵入性较强的事务方案，要求业务处理过程必须拆分为"预留业务资源"和"确认/释放消费资源"两个子过程。

TCC的实现过程分为三个阶段：
- Try：尝试执行阶段，完成所有业务可执行性的检查(保障一致性)，并且预留好事务需要用到的所有业务资源(保障隔离性)。
- Confirm：确认执行阶段，不进行任何业务检查，直接使用Try阶段准备的资源来完成业务处理。注意，Confirm阶段可能会重复执行，因此需要满足幂等性。
- Cancel：取消阶段，释放Try阶段预留的业务资源。注意，Cancel阶段也可能会重复执行，因此也需要满足幂等性。
![[Pasted image 20250828111816.png]]
TCC 在业务执行的时候，只操作预留资源，几乎不会涉及到锁和资源的争用，所以它具有很高的性能潜力。常我们并不会完全靠裸编码来实现 TCC，而是会基于某些分布式事务中间件（如阿里开源的Seata）来完成，以尽量减轻一些编码工作量。

由于Try阶段需要业务配合进行冻结(预留资源)的操作，所以对于第三方的调用无法保证他们会配合，所以Try阶段就无法进行下去。

## SAGA事务基于数据补偿代替回滚的解决思路
SAGA由两部分操作组成：
1. 把大事务拆分成若干小事务，将整个分布式事务T分解为n个子事务，我们命名为T1, T2,  ..., Ti, ..., Tn。每个子事务都应该、或者能被看做是原子行为。如果分布式事务T能够正常提交，那么它对数据的影响(最终一致性)就应该于连续按顺序成功提交子事务Ti等价。
2. 另一部分是为每一个子事务涉及对应的补偿动作，我们命名为C1, C2, ..., Ci, ..., Cn。
Ti与Ci必须满足以下条件：
- Ti与Ci都具备幂等性
- Ti与Ci满足交换律(Commutative)，即不管是先执行Ti还是先执行Ci，效果都是一样的；
- Ci必须能够成功过提交，即不考虑Ci本身提交失败被回滚的情况，如果出现就必须持续重试直至成功，或者人工介入。

如果 T1 到 Tn 均成功提交，那么事务就可以顺利完成。否则，我们就要采取以下两种恢复策略之一：
- 正向恢复(Forward Recovery): 如果Ti事务提交失败，则一直对Ti进行重试，直至成功为止(最大努力交付)。
- 反向恢复(Backward Recovery)：如果Ti事务提交失败，则一直执行Ci对Ti进行补偿，直至成功过为止(最大努力交付)。

尽管补偿操作通常比冻结 / 撤销更容易实现，但要保证正向、反向恢复过程能严谨地进行，也需要你花费不少的工夫。比如，你可能需要通过服务编排、可靠事件队列等方式来完成。所以，SAGA 事务通常也不会直接靠裸编码来实现，一般也是在事务中间件的基础上完成。我前面提到的 Seata 就同样支持 SAGA 事务模式。

SAGA同样也需要通过引入语义锁之类的机制来避免并发问题导致隔离性被破坏的情况。

## 基于数据补偿的另一种应用模式：AT事务
它大致的做法是在业务数据提交时，自动拦截所有 SQL，分别保存 SQL 对数据修改前后结果的快照，生成行锁，通过本地事务一起提交到操作的数据源中，这就相当于自动记录了重做和回滚日志

基于这种补偿方式，分布式事务中所涉及的每一个数据源都可以单独提交，然后立刻释放锁和资源。AT 事务这种异步提交的模式，相比 2PC 极大地提升了系统的吞吐量水平。而使用的代价就是大幅度地牺牲了隔离性，甚至直接影响到了原子性。因为在缺乏隔离性的前提下，以补偿代替回滚不一定总能成功。

## 理解透明多集分流系统的设计原则
作为系统的设计者，我们应该意识到不同的设施、部件在系统中，都具有各自不同的价值：
- 有一些部件位于客户端或网路的边缘，能够迅速响应用户的请求，避免给后方的I/O与CPU带来压力，典型的如**本地缓存、内容分发网络、反向代理**等。
- 有一些部件的处理能力能够线性拓展，易于伸缩，可以通过使用较小的代价堆叠机器，来获得与用户数量相匹配的并发性能，并且应尽量作为业务逻辑的主要载体，典型的如**集群中能够自动扩缩的服务节点。**
- 有一些部件的稳定服务，对系统运行具有全局性的影响，要时刻保持着容错备份，维护着高可用性，典型的如**服务注册中心、配置中心**。
- 有一些设施是天生的单点部件，只能依靠升级机器本身的网络、存储和运算性能来提升处理能力，比如位于**系统入口的路由、网关或者负载均衡器** (它们都可以做集群，但一次网络请求中无可避免至少有一个是单点的部件)、位于**请求调用链末端的传统关系数据库等**，都是典型的容易形成单点的部件。

两个简单、普适的原则，能知道我们进行设计：
- **第一个原则是尽可能减少单点部件，如果单点是无可避免的，则应尽最大限度减少到达单点部件的流量。**
- **第二个原则是奥卡姆剃刀原则，如无必要，务增实体。**
**在能满足需求的前提下，最简单的系统就是最好的系统。**

## DNS的工作原理
DNS的解析步骤如下：
- 第一步，客户端先检查本地的 DNS 缓存，查看是否存在并且是存活着的该域名的地址记录。
- 第二步，客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS）。这个本地 DNS 服务器可以由用户手工设置，也可以在 DHCP 分配时或者在拨号时，从 PPP 服务器中自动获取。
- 第三步，本地 DNS 收到查询请求后，会按照“是否有 www.icyfenix.com.cn 的权威服务器”→“是否有 icyfenix.com.cn 的权威服务器”→“是否有 com.cn 的权威服务器”→“是否有 cn 的权威服务器”的顺序，依次查询自己的地址记录。如果都没有查询到，本地 DNS 就会一直找到最后点号代表的根域名服务器为止。
```ad-note
这里涉及两个重要的名词：
1. **权威域名服务器(Authoritative DNS)**: 是指负责翻译特定域名的DNS服务器，"权威"是指服务器决定了这个域名应该翻译出怎样的结果。权威DNS可以用于内容分发网络、服务发现。
2. **根域名服务器(Root DNS)**：是指固定的、无需查询的顶级域名(Top-Level Domain)服务器，可以默认为它们已内置在操作系统代码之中。全世界一共有13组根域名服务器。
```
- 第四步，现在假设本地 DNS 是全新的，上面不存在任何域名的权威服务器记录，所以当 DNS 查询请求按步骤 3 的顺序，一直查到根域名服务器之后，它将会得到“cn 的权威服务器”的地址记录，然后通过“cn 的权威服务器”，得到“com.cn 的权威服务器”的地址记录，以此类推，最后找到能够解释 www.icyfenix.com.cn 的权威服务器地址。
- 第五步，通过“www.icyfenix.com.cn 的权威服务器”，查询 www.icyfenix.com.cn 的地址记录。这里的地址记录并不一定就是指 IP 地址，在 RFC 规范中，有定义的地址记录类型已经多达几十种，比如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。

DNS的缺陷：
- 响应速度慢
解决方案：前端进行DNS预取，`<link rel="dns-prefetch" href="//domain.not-icyfenx.cn"> `。
- DNS的分级查询意味着每一级都有可能受到中间人攻击的威胁，产生被劫持的风险。
解决方案：HTTPDNS，把原本的DNS解析服务开放为一个基于HTTPS协议的查询服务，代替基于UDP传输协议的DNS域名解析。
## 客户端缓存
### 状态缓存
指不经过服务器，客户端直接根据缓存信息来判断目标网站的状态。以前只有301/Moved Permannently(永久重定向)这一种；后来增加了HSTS(Http Strict Transport Security)机制，用来避免301/302跳转https时，可能产生的降级中间人劫持问题。

### 实现强制缓存机制的两类Headers
- 第一类：Expires，它是HTTP/1.0中开始提供的Header，后面跟随一个截止时间参数。当服务器返回某个资源时，如果带有该 Header 的话，就意味着服务器承诺在截止时间之前，资源不会发生变动，浏览器可直接缓存该数据，不再重新发请求。
```shell
HTTP/1.1 200 OK
Expires: Wed, 8 Apr 2020 07:28:00 GMT
```
>Expires存在一些限制：
>- 受限于客户端的本地时间
>- 无法处理涉及到用户身份的私有资源
>- 无法描述"不缓存"的语义

- 第二类：Cache-Control，它是 HTTP/1.1 协议中定义的强制缓存 Header，它的语义比起 Expires 来说就丰富了很多。而如果 Cache-Control 和 Expires 同时存在，并且语义存在冲突（比如 Expires 与 max-age / s-maxage 冲突）的话，IETF 规定必须以 Cache-Control 为准。
```shell
HTTP/1.1 200 OK
Cache-Control: max-age=600
```
实际上，在客户端的请求Header或服务器的响应Header中，Cache-Control都可以存在，它定义了一系列的参数，并且允许自行扩展。下面是6种主要的标准参数：
>- max-age和s-maxage (单位是秒)
>- public和private
>- no-cache和no-store
>- no-transform
>- min-fresh和only-if-cached
>- must-revalidate和proxy-revalidate

### 协商缓存的两种变动检查机制
- **根据资源的修改时间进行检查**, 它的语义中包含了两种标准参数：Last-Modified 和 If-Modified-Since。
>Last-Modified 是服务器的响应 Header，用来告诉客户端这个资源的最后修改时间。
>
>而对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-Modified-Since，把之前收到的资源最后修改时间发送回服务端。
>
>如果此时，服务端发现资源在该时间后没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无需附带消息体，从而达到了节省流量的目的：
```shell
>HTTP/1.1 304 Not Modified
Cache-Control: public, max-age=600
Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
>```
- **根据资源唯一标识是否发生变化来进行检查**，它的语义中也包含了两种标准参数：Etag 和 If-None-Match。
>Etag 是服务器的响应 Header，用于告诉客户端这个资源的唯一标识。HTTP 服务器可以根据自己的意愿，来选择如何生成这个标识，比如 Apache 服务器的 Etag 值，就默认是对文件的索引节点（INode）、大小和最后修改时间进行哈希计算后而得到的。
>
>然后，对于带有这个 Header 的资源，当客户端需要再次请求时，就会通过 If-None-Match，把之前收到的资源唯一标识发送回服务端。
>
>如果此时，服务端计算后发现资源的唯一标识与上传回来的一致，就说明资源没有被修改过，同样也只需要返回一个 304/Not Modified 的响应即可，无需附带消息体，达到节省流量的目的：
```
HTTP/1.1 304 Not Modified
Cache-Control: public, max-age=600
ETag: "28c3f612-ceb0-4ddc-ae35-791ca840c5fa"
```

### HTTP的内容协商机制
在 HTTP 协议的设计中，一个 URL 地址是有可能提供多份不同版本的资源的，比如说，一段文字的不同语言版本，一个文件的不同编码格式版本，一份数据的不同压缩方式版本，等等。因此针对请求的缓存机制，也必须能够提供对应的支持。

```shell
HTTP/1.1 200 OK
Vary: Accept, User-Agent
```
这个响应的含义是应该根据 MINE 类型和浏览器类型来缓存资源，另外服务端在获取资源时，也需要根据请求 Header 中对应的字段，来筛选出适合的资源版本。

## 传输链路，HTTP的演化
### **1. HTTP/1.x时代的困境与"奇技淫巧"**
- 根本矛盾：HTTP协议(短小快速的资源传输) 与TCP协议(为长连接大数据量设计)之间的不匹配。TCP建立连接的三次握手和慢启动成本很高。
- 优化策略：为环节这个矛盾，前端开发者被迫采用各种技巧：
	- 减少请求数：雪碧图、文件合并、内联资源等。
	- 增加连接数：域名分片，以突破浏览器对单个域名的连接数限制。
- 副作用：这些技巧带来了缓存失效、响应延迟、DNS负担加重、缓存效率下降等新问题，是一种"两害相权取其轻"的无奈选择。
### **2. HTTP/1.x的改进与局限：连接复用**
- 持久连接(Keep-Alive)：复用TCP连接，避免多次握手。但引入了**队首阻塞(Head-of-Line Blocking)** 问题 --- 一个慢请求会阻塞同连接上所有后续请求。
- HTTP管道(Pipelining)：尝试让服务器管理请求队列，但因此实现复杂且未能根本解决队首阻塞，推广失败。
### **3. 革命性的解决方案：HTTP/2的多路复用**
- 核心机制：引入了帧(Frame) 和 流(Stream) 的概念。
	- 帧：最小的数据单位，每个帧都携带一个流ID。
	- 流：一个独立的、虚拟(逻辑上)的请求-响应双向通道。
- 如何解决队首阻塞：在同一个TCP连接上，多个流的帧可以混杂在一起传输，接收方根据流ID重新组装。这意味着一个流的阻塞不会影响其他流。
- 带来的改变：
	- 但域名单链接：彻底摆脱了连接数的限制，域名分片不再需要。
	- 请求合并称为反模式：合并小文件反而会降低缓存效率和传输灵活性。
	- 头部压缩：HTTP/2专门设计了HPACK头部压缩算法，进一步减少了传输开销。
#### **4. 传输压缩与持久化连接的冲突以及解决方案**
- 冲突：现代服务器使用即使压缩以加快首字节时间(TTFFB)，但这导致无法再传输前知道body的准确长度(即无法给出Content-length Header)，这与HTTP/1.1的持久连接机制冲突。
- 解决方案：HTTP/1.1引入了分块传输编码(Chunked Transfer Encoding)，将数据分成若干块一次发送，最后一个零长度的块标记结束，完美解决了这一冲突。
### **5. 面向未来的根本性变革：HTTP/3与QUIC**
- 为什么需要HTTP/3：HTTP/2虽然解决了应用层的对首阻塞，但底层依然基于TCP。TCP协议本身的机制(丢失重传)会导致传输层的队首阻塞 --- 一个TCP包丢失会阻塞所有流。
- 核心：HTTP/3弃用TCP，代用基于UDP的QUIC协议。
- QUIC的优势：
	- 解决队首阻塞：在QUIC层实现了可靠的传输，每个流独立处理，彻底解决了所有层面的队首阻塞。
	- 极快的连接建立：继承了TLS1.3，通常只需要0-RTT或1-RTT即可完成建连和加密握手。
	- 连接迁移：使用连接ID而非IP地址来标识连接，网络切换(如Wifi换4G)时连接不会中断。

## CDN
### **一、CDN的本质与价值**
- 解决的核心问题：主要改善网络传输速度，针对以下三点：
	1. 网站服务器出口带宽：分流，减轻原站压力。
	2. 跨运营商互联点带宽：优化跨网访问
	3. 物理链路传输时延：通过就近访问降低延迟
- 用户客户端入口带宽无法通过CDN改善，需用户自行升级。
### **二、CDN的工作原理**
1. **路由解析(依靠DNS实现)**
	- 流程：
		- 将原站IP在CDN服务商注册，获取一个`CNAME`记录
		- 在域名DNS服务商处，为该域名配置这条`CNAME`记录
		- 用户首次访问时，本地DNS查询最终被只想CDN服务商的权威DNS服务器
		- CDN的DNS根据策略(拓扑、容量、时延等)返回最合适的CDN缓存节点IP给用户。
		- 用户直接访问该CDN节点获取资源。
	- 关键：对用户和源站(几乎)时透明的。
2. **内容分发(如何获取和管理资源)**
	- 两种分发方式：
		- 主动分发(Push)：需要源站主动将资源推送到CDN节点，需API配合。
		- 被动回源(Pull)：用户请求未命中缓存时，CDN节点实时从源站拉取资源。
	- 资源管理(更新)策略：
		- 无统一标准，常见结合两种方式：
			- 超时被动失效: 为缓存设置生存时间(TTL)
			- 手动主动失效：通过CDN提供的API接口主动刷新缓存(常与持续集成流水线结合)
### **三、CDN的广泛应用**
1. 加速静态资源
2. 安全防御：作为源站的堡垒机，有效抵御DDos等攻击。
3. 协议升级：
	- HTTP源站 -> HTTPS对外服务
	- HTTP/1.x -> HTTP/2/3
	- IPv4 -> IPv6
4. 状态缓存：缓存源站状态码。
5. 修改资源：
	1. 自动压缩资源 + 修改  `Content-Encoding`
	2. 为资源添加缓存Header
	3. 修改CORS Header实现跨域
6. 访问控制：
	1. IP黑/白名单那
	2. 根据IP提供不同响应、QoS控制、防盗链
7. 注入功能

## 四层和七层负载均衡
### **1. 负载均衡的两种形式与总体印象**
- 四层负载均衡：工作于OSI模型的传输层。优势是性能高，因为它通常维持同一个TCP连接，只处理底层(如IP、端口)的转发。
- 七层负载均衡：工作于OSI模型的应用层。优势是功能强大，它能解析HTTP等应用层协议内容，从而做出更智能的决策。
- 关键原则：在实际架构中，通常采用多级混合负载均衡，并且是低层(四层)在前，高层(七层)在后。这样可以用四层处理大量流量，七层处理更复杂的业务逻辑。
### **2. 常见的四层负载均衡工作模式**
它们都维持客户端到服务器的同一个TCP连接。
1. 数据链路层负载均衡(三角传输/直接路由-DSR)
	- 工作原理：修改传入数据帧的目标MAC地址，直接转发给后台的真实服务器(Real Server)。
	- 要求：负载均衡器和所有真实服务器必须配置相同的虚拟IP(VIP)，且必须在同一个子网内(二层可达)。
	- 最大优点：响应数据包不需要经过负载均衡器，可以直接返回给客户端，性能及高。
	- 缺点：不能跨VLAN，网络约束大。
2. 网络层负载均衡 - IP隧道模式
	- 工作原理：将原始数据包整个作为新数据包的Payload，通过IP隧道封装转发给真实的服务器。服务器收到后需要拆包。
	- 优点：可以跨越VLAN。同样具备三角传输特性，响应可以直接返回给客户端。
	- 缺点：仍需配置VIP，封装和解包带来额外性能开销。
3. 网络层负载均衡 - NAT模式
	- 工作原理：直接修改数据包头的目标IP地址，将其改为真实服务器的IP。
	- 最大问题：响应必须返回给负载均衡器，由它修改源IP后再发给客户端。这使得负载均衡器容易成为带宽瓶颈。
	- 变种SNAT：连源IP也修改，对服务器更透明，当服务器无法获取客户端的真实IP。
	- 优点：配置简单(服务器网关指向均衡器即可)，不需要VIP。
### **3. 七层负载均衡(应用层负载均衡)**
- 本质是反向代理：客户端与负载均衡器、负载均衡器与真实服务器之间是两条独立的TCP连接。
- 性能对比：性能低于四层模式，因为需要完整的TCP代理和应用层解析，消耗更多CPU。
- 功能强大：因其感知应用内容，可实现：
	- 智能路由：根据URL、Cookie、用户身份等路由请求。
	- 流量优化：静态资源缓存、SSL卸载、压缩等。
	- 安全防护：抵御SYN Flood等DDos攻击，过滤SQL注入等应用层攻击。
	- 链路治理：实现服务降级、熔断等微服务治理策略。
### **4. 均衡策略与实现**
- 常见策略：轮询、加权轮询、随机、加权随机、一致性哈希、响应速度、最少连接数等。
- 实现方式：
	- 软件均衡器：
		- 内核态：如LVS(性能好)。
		- 应用态：如NGINX、HAProxy(功能丰富，使用方便)。
	- 硬件均衡器：如F5、A10，采用专用芯片(ASIC)，性能更高。

## 服务端缓存(进程内缓存)
### **一、引入缓存的理由与风险**
- 目的：主要为缓解CPU压力(如存储计算结果、复用数据)和缓存I/O压力(如将磁盘/网络访问转为内存访问)。
- 风险：引入缓存会增加系统复杂度(需考虑失效、更新、一致性)、增加运维难度(可能掩盖缺陷、延迟问题暴露)、带来安全隐患(可能泄露保密数据)。
### **二、缓存的关键属性**

1. **吞吐量(Throughput)**
	- 衡量并发读写效率(OPS)。高并发场景下，不同缓存方案的吞吐量差异显著(最高最低可差一个数量级)。
	- 优化手段：避免数据竞争是关键。以Caffine为例，其采用异步日志提交机制(读取状态变更写入专用环形缓冲Ring Buffer，由后台线程异步处理，容忍部分状态丢失)来减少锁竞争，使其读取性能接近ConcurrentHashMap，写入性能约低10%。
2. **命中率(Hit Rate)**
	- 命中率直接决定引入缓存的价值。
	- 核心问题是淘汰缓存(决定那些数据是"低价值"的):
		- FIFO：淘汰最早进入的数据。实现简单，但效果往往较差，可能误伤热点数据。
		- LRU：淘汰最久未访问的数据。在java中可以采用HashMap + LinkedList实现，适合处理短期热点，但可能因近期未访问而误伤"老热点"。
		- LFU：淘汰访问频率最低的数据，需要维护计数器，开销大且难以应对热度变化(旧数据计数器难衰减)。
		- 高级改进算法(如TinyLFU、W-TinyLFU)：
			- TinyLFU：采用Count-Min Sketch算法 (类似布隆过滤器) 用少量空间估算频率，并结合时间衰退算法定期减半计数器，解决旧热点问题。
			- W-TinyLFU：结合LRU和LFU。新增数据先进入一个小的LRU Window Cache，积累热度后再经TinyLFU筛选进入主缓存(Segmented LRU)，更好地应对突发稀疏访问。
		- 高级算法(如W-TinyLFU，ARC，LIRS) 在多数场景下命中率更接近理想状态，远优于基础策略。
3. **扩展功能(Extended Features)**
	- 加载器(CacheLoader)：支持主动加载数据，是实现自动刷新的基础。
	- 多种淘汰策略：可供选择。
	- 失效/刷新策略：支持基于时间的自动失效或刷新。
	- 时间通知：支持监听数据移除、刷新等时间。
	- 并发级别设置：对于分段锁缓存(如Guava Cache)，可调整并发段数。
	- 容量控制：支持设置初始容量和最大容量。
	- 引用方式：支持软引用、弱引用，与JVM GC联动。
	- 统计信息：提供命中率、平均加载时间等统计。
	- 持久化：分布式缓存常支持将数据持久化到数据库或磁盘，但是对于进程内缓存，一般不需要。
## 分布式缓存
### ***一、分布式缓存的两种主要形式*
1. 负值式缓存
	- 每个节点存储完整数据副本，读取快(无网络开销)，但写入性能随着节点增加急剧下降。
	- 代表产品：JBossCache、Infinspan
	- 适合场景：读多写少的数据。
2. 集中式缓存
	- 数据集中存储，读写均需网络访问，但扩展性好，适合异构系统。
	- 代表产品：Redis。
	- 使用场景：读写均频繁的数据。
### **二、透明多级缓存(TMC)**
- 结合进程内缓存(一级) 和分布式缓存(二级)，提升性能的同时减少网络开销。
- 设计原则：
	- 变更以分布式缓存为准。
	- 访问优先读取一级缓存，未命中再读取二级缓存。
	- 通过消息通知(如Redis PUB/SUB或Zookeeper/Etcd)同步一级缓存失效。
### **三、缓存常见风险及应对策略**
1. 缓存穿透(查询不存在的数据)
	- 原因：业务逻辑缺陷或恶意攻击。
	- 解决：
		- 缓存空值(短时间有效，等有值了再更新缓存)。
		- 使用布隆过滤器快速判断数据是否存在。
2. 缓存击穿(热点数据突然失效)
	- 解决：
		- 加锁(互斥锁或分布式锁)，只允许一个请求重建缓存。
		- 手动管理热点数据(避免自动失效)
3. 缓存雪崩(大量数据同时失效)
	- 解决：
		- 提升缓存系统可用性(集群部署).
		- 采用多级缓存(分散过期时间)。
		- 设置随机过期时间(避免)
4. 缓存污染(数据不一致)
	- 原因：缓存更新不规范。
	- 解决：采用Cache Aside模式：
		- 读：先读缓存，未命中读数据库并回填。
		- 写：先写数据库，再失效缓存(而非更新)。

## 系统认证技术：原理、标准与实现
### **一、认证的基本概念**
认证(Authentication) 是系统安全的第一道防线，核心任务是解决"你是谁"的问题，即确认操者的身份。它与授权(Authorization，解决"你能做什么")、凭证(Credentials，解决"你如何证明")、保密(Confidentiality)、传输安全(Transport Security)和验证(Verification)共同构成了软件架构安全的基础。

### **二、认证的主要方法和技术**
认证可以根据其发生的位置和方式分为三种层面：
1. 通讯信道上的认证：在建立通信连接之前验证身份，如基于SSL/TLS的认证。
2. 通讯协议上的认证：在请求资源之前验证身份，即HTTP认证框架。
3. 通讯内容上的认证：在使用服务之前验证身份，即Web认证(如表单登录和新兴的WebAuthn)。

**基于通讯协议的HTTP认证**
| 认证方案 | 基本原理 | 安全性 |
| --------------- | --------------- | --------------- |
| Basic | 用户名和密码经过Base64编码后传输 | 非常低，相当于铭文传输 |
| Digest | 对用户名、密码、服务器提供的Nonce值进行哈希处理 | 较低，仍可能受到中间人攻击 |
| Bearer | 基于OAuth2.0协议的令牌机制 | 高，依赖于令牌的安全性和传输加密 |
| HOBA | 基于自签名证书的认证 | 高，依赖于公钥基础设置(PKI) |
| AWS4-HMAC-SHA256 | 亚马逊AWS使用的基于HMAC-SHA256 | 高 |
| NTLM/Negotiate | 微软Windows NT LAN Manager认证协议 | 中等 |

**基于通讯内容的Web认证**
这是目前最常见的方式，尤其时表单认证(Form Authentication)。其优点时灵活自由，开发者可以抗旨登录页面的样式/交互逻辑等。但其背后通信的安全保障(如防窃听、防篡改)人需遵循成熟的标准和最佳实践。

**WebAuthn** 是新一代Web认证标准，它彻底摒弃密码，改用生物识别或物理安全密钥作为凭证。其核心流程是：
1. 注册：服务其生成Challenge(随机字符串)和用户ID发送给客户端。用户设备上的验证器(Authenticator)生成非对称密钥对，私钥本地安全存储，公钥签名后的Challenge发回服务器存储。
2. 登录：服务器再次下发Challenge。用户使用注册时的私钥对challenge签名并返回。服务器用存储的公钥验证签名，确认用户身份。

WebAuthn的优势在于极强的安全性(避免密码泄露和钓鱼攻击)和便捷性(无需记忆密码)。

### **三、认证的标准与规范**
- HTTP认证框架(RFC 7235)
- OAuth 2.0 / OIDC：用户授权的框架，也常被用于认证(如社交登录)。
- WebAuthn：由W3C和FIDO联盟指定的无密码认证标准。
- JAAS(Java Authentication and Authorization Service)：Java早期的安全规范，提出了许多核心概念(如Subject，Principal)，但因复杂性和与容器绑定过紧而未被广泛应用。

### **四、认证的安全考虑和最佳实践**
- 传输安全：无论使用何种安全认证方案，都必须通过HTTPS(SSL/TLS)来加密传输过程，防止凭证在传输中被窃听或篡改。
- 密码安全：如果使用密码，服务器端不应该存储明文密码，而应该存储经过加盐哈希处理后的值。
- 会话管理：认证成功后生成会话标识需安全管理，如设置合理的过期时间、防止泄露。
- 防范常见攻击：需采取措施防范重放攻击(可通过Nonce/时间戳)、CSRF攻击、XSS攻击(防止Token被窃取)等。

### **五、认证技术的未来发展趋势**
- 无密码：像WebAuthn这样的标准
- 多因素认证(MFA)：结合多种不同因素的认证方式(如密码+手机验证)
- 分布式与标准化：在微服务、云原生架构中，认证技术趋向于标准化(如OIDC)，并将认证功能外置到专门的API网关或服务网格中统一处理。




