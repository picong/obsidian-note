# RPC
>
>RPC 是O一种语言级别的通讯协议，它允许运行于一台计算机上的程序以某种管道作为通讯媒介(即传输协议的网络)，去调用另外一个地址空间(通常为网络上的另外一台计算机)。

几种进程间通讯机制(Inter-Process Communication，IPC)：

- 管道或具名管道(Named Pipe)，管道其实类似于两个进程之间的桥梁，用于进程间传递少量的字符流或字节流。
- 信号(Signal) 信号是用来通知目标进程有某种事情发生的。
- 信号量(Semaphore) 信号量是用于两个进程之间同步协作的手段，相当于操作系统提供的一个特殊变量。
- 消息队列(Message Queue)，消息队列克服了信号承载信息量少、管道只能用于无格式字节流，以及缓冲区大小受限等缺点，但实时性相对受限。
- 共享内存(Shared Memory) 允许多个进程访问同一块内存空间，这是效率最高的进程间通信方式。进程的内存地址空间是独立隔离的，但操作系统提供了让进程主动创建、映射、分离、控制某一块内存的接口。
- 本地套接字接口(IPC Socket) 套接字接口，是更为普适的进程间通信机制，可用于不同机器之间的进程通信。

## RPC需要解决的三个基本问题

1. 如何表示数据？
将交互上方涉及的数据，转换为某种实现约定好的中立数据流格式来传输，将数据流转换会不同语言中对应的数据类型来使用。**就是序列化与反序列化**
2. 如何传递数据？
准确地说，如何传递数据是指如何通过网络，在两个服务Endpoint之间相互操作、交换数据。这里"传递数据"通常指的是应用层协议，实际传输一般是基于标准的TCP、UDP等传输层协议来完成的。
3. 如何表示方法？
简单的方式是：只要给程序中的每个方法，都规定一个通用的又绝对不会重复的编号；在调用的时候，直接传这个编号就可以找到对应的方法。

## Rest

Rest与RPC在思想上存在差异的核心，是抽象的目标不一样，也就是面向资源编程思想与面向过程的编程思想之间的区别。

Rest，即"表征状态转移" (Representational State Transer)的缩写，REST中的一些关键概念：

- 资源(Resource)
- 表征(Representation)，"表征"这个概念是指信息与用户交互时的表示形式。
- 状态(State)，在特定语境中才能产生的上下文信息就被称为"状态"。
- 转移(Transfer)，服务器通过某种方式，把"用户当前阅读的文章"转变成"下一篇章"，这就被称为"表征状态转移".

### RESTFul风格的系统特征

- 服务端与客户端分离(Client-Server)
- 无状态(Stateless)
- 可缓存(Cacheability)
- 分层系统(Layered System)
- 统一接口(Uniform Interface)
- 按需代码(Code-On-Demand)，例如Java Applet、WebAssembly。

### REST提出以主体进行服务设计的风格，为它带来了不少好处

- 降低了服务接口的学习成本
- 资源天然具有集合与层次结构
- REST绑定于HTTP协议

## Richardson成熟度模型(Richardson Maturity Model，RMM)

Richardson将服务接口按照"REST的程度"，从低到高分为0至3共4级：

1. The Swamp of Plain Old XML：完全不REST。
2. Resources：开始引入资源的概念。
3. HTTP Verbs：引入统一接口，映射到HTTP协议的方法上。
4. Hypermedia Controls(超文本驱动)。
![[Pasted image 20250826134455.png]]

### REST的不足与争议

- 面向资源的编程思想只适合做CRUD，只有面向过程、面向对象编程才能处理真正复杂的业务逻辑。（针对那些比较抽象的场景，如果确实不好把 HTTP 方法映射为资源的所需操作，REST 也并不会刻板地要求一定要做映射。这时，用户可以使用自定义方法，按 Google 推荐的 REST API 风格来拓展 HTTP 标准方法。）
- REST与HTTP完全绑定，不适用于要求高性能传输的场景中。
- REST不利于事务支持。
- REST没有传输可靠性支持，应对传输可靠性最简单粗暴的做法，就是把消息再重发一遍。这种简单处理能够成立的前提，是服务具有幂等性(Idempotency)。
- REST缺乏对资源进行"部分"和"批量的处理能力"。如果要在REST上实现"部分"操作的能力，只能自己在GET方法的Endpoint上设计各种参数。而要解决批量操作这类问题，目前一种从理论上看还比较优秀的解决方案是GraphQL。

## 本地事务

ACID中的A、I、D是手段，C是目的，AID具有正交性。

《ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging》着重解决了事务的 ACID 三个属性中，原子性（A）和持久性（D）在算法层面上应当如何实现；

而另一篇《ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes》则是现代数据库隔离性（I）奠基式的文章。

### 实现原子性与持久性的实现方式

- Commit Logging（较具代表性的是阿里的 OceanBase）
为了能够顺利的地完成奔溃恢复，在磁盘中写数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的值，必须将修改数据这个操作所需的全部信息(上下文)，以日志的形式先记录到磁盘中。

只有在日志记录全部都安全落盘，见到代表事务成功提交的"Commit Record"后，数据库才会根据日志上的信息对真正的数据进行修改，修改完成后，在日志中加入一条"End Record"表示事务已完成持久化，这种事务实现方法被称为"Commit Logging"。

Commit Logging存在一个巨大的缺陷：所有对数据的真实修改都必须发生在事务提交、日志写入了Commit Record之后，这一点对提升数据库的性能是很不利的。

- Shadow Paging，有点类似于copy on write。
- Write-Ahead Logging(ARIES提出来的)，Write-Ahead其实就是允许在事务提交之前提现写入变动数据的意思。

>Write-Ahead Logging 先将何时写入数据，按照事务提交时点为界，分为了FORCE和STEAL两类：
>
>- **FORCE:** 当事务提交后，要求变动数据必须同时完成写入则称为FORCE，如果不强制变动数据必须同时完成写入则称为NO-FORCE。现实中绝大多数数据库采用的都是NO-FORCE策略，只要有了日志，变动数据随时可以持久化，从优化磁盘I/O性能考虑，没有必要强制数据写入立即进行。
>- **STEAL:** 在事务提交前，允许变动数据提前写入则称为STEAL，不允许则称为NO-STEAL。STEAL有利于利用空闲I/O资源，也有利于节省数据库缓存区的内存。

Write-Ahead Logging允许No-FORCE，也允许STEAL，它给出的解决办法是增加另一种称为Undo Log的日志。当变动数据写入磁盘前，必须先记录Undo Log，写明修改那个位置的数据、从什么值改成什么值，以便在事务回滚或者奔溃恢复时，根据Undo Log对提前写入的数据变动进行擦除。

由于Uno Log的加入，Write-Ahead Logging在奔溃恢复时，会因此经历以下三个阶段：

- **分析阶段(Analysis):** 该阶段从最后一次检查点(Checkpoint，可理解为在这个点之前所有应该持久化的变动都已经安全落盘)开始扫描，找出所有没有End Record的事务，组成待恢复的事务集合(一般包括Transaction Table和Dirty Page Table).
- **重做阶段(Redo)**：该阶段以及分析阶段中，产生的待恢复的事务集合来重演历史，找出所有包含Commit Record的日志，将它们写入磁盘，写入完成后增加一条End Record，然后移除出待恢复事务集合。
- **回滚阶段(Undo)：** 该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要恢复的事务，根据Undo Log中的信息回滚这些事务。
![[Pasted image 20250826172442.png]]

## 本地事务的隔离级别

### **可串行化**

串行化访问提供了强度更高的隔离性,ANSI/ISO SQL-92中定义的最高等级的隔离级别便是可串行化(Serializable)。

可串行化比较符合普通程序员对数据竞争加锁的理解，如果不考虑性能的话，对事务所有读、写的数据全都加上读锁、写锁和范围所即可(这种可串行化的实现方案称为 Two-Phase Lock)。

### **可重复读**

可重复读(Repeatable Read)的意思就是对事务所涉及到的数据加读锁和写锁，并且一直持续到事务结束，但不再加范围锁。

可重复读比可串行化弱化的地方在于幻读问题(Phatom Reads)，幻读问题其实也就是一个事务遭到其他事务的影响隔离性被破坏的表现。

**需要注意**，这里的介绍实际上是以ARIES理论作为讨论目标的，而具体的数据库并不一定要完全遵照这个理论去实现。例如：Mysql/InnoDB的默认隔离级别是可重复读，但它在只读事务中就可以完全避免幻读问题(Mysql中加间隙锁(范围锁的一种实现))。

### **读已提交**

读已提交(Read Commited)对事务涉及到的数据加的写锁，会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。

读已提交比可重复读弱化的地方在于**不可重复读(Non-Repeatab Reads)问题**，该问题是指在事务执行过程中，对同一行数据的两次查询得到了不同的结果。

### **读未提交**

读未提交(Read Uncommited)对事务涉及到的数据只加写锁，这会一直持续到事务结束，但完全不加读锁。

读未提交比读已提交弱化的地方在于**脏读问题(Dirty Reads)**，它是指在事务执行过程中，一个事务读取到了另一个事务未提交的数据。

```ad-note
**其实，不同隔离级别以及幻读、脏读等问题都只是表面现象，它们是各种锁在不同加锁时间上组合应用所产生的结果，锁才是根本的原因。**
```

## MVCC基础
>
>针对"一个事务读 + 另一个事务写"的隔离问题，有一种名为"多版本并发控制"（Multi-Version Concurrency Control，MVCC)的无锁优化方案被主流的商业数据库广泛采用。

**MVCC是一种读取优化策略，它的"无锁"是特指读取时不需要加锁。** MVCC的基本思路是读数据库的任何修改不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。

不妨将其理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION 和 DELETE_VERSION，这两个字段记录的值都是事务 ID（事务 ID 是一个全局严格递增的数值），然后：

- 数据被插入时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。
- 数据被删除时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。
- 数据被修改时：将修改视为“删除旧数据，插入新数据”，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。

此时，当有另外一个事务要读取这些发生了变化的数据时，会根据隔离级别来决定到底应该读取哪个版本的数据：

- 隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。
- 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。

**MVCC 是只针对“读 + 写”场景的优化，如果是两个事务同时修改数据，即“写 + 写”的情况，那就没有多少优化的空间了，加锁几乎是唯一可行的解决方案。**

## XA 全局事务

### **两段式提交**

![[Pasted image 20250827151040.png]]
两段式提交有三个非常明显的缺点：

- 单点问题：协调者在两段式提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送Commit或者Rollback的指令，那所有参与者都必须一直等待。
- 性能问题：两段提交过程中，所有参与者相当于被绑定称为一个统一调度的整体，期间要经过两次远程服务调用、三次数据持久化(准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入Commit Record)，整个过程将持续到参与者集群中最慢的那一个处理操作结束位置。
- 一致性风险：当网络稳定性和宕机恢复能力的假设不成立时，两段式提交可能会出现一致性问题。

### **三段式提交**

**在事务需要回滚的场景中，三段式的性能通常要比两段式好很多，但在事务能够正常提交的场景中，两段式和三段式提交的性能都很差，三段式因为多了一次询问，性能还要更差一些。**

在三段式提交中，如果协调者在 PreCommit 阶段开始之后发生了宕机，参与者没有能等到 DoCommit 的消息的话，默认的操作策略将是提交事务而不是回滚事务或者持续等待。
![[Pasted image 20250827151902.png]]

## 可靠消息队列

![[Pasted image 20250827170415.png]]
消息表，里面存入一条消息：“事务 ID：UUID；扣款：100 元（状态：已完成）；仓库出库《深入理解 Java 虚拟机》：1 本（状态：进行中）；某商家收款：100 元（状态：进行中）”。注意，这个步骤中“扣款业务”和“写入消息”是依靠同一个本地事务写入自身数据库的。

前面这种靠着持续重试来保证可靠性的操作，在计算机中就非常常见，它有个专门的名字，叫做"最大努力交付"(Best-Effort Delivery)，而"可靠事件队列"有一种更普通的形式，被称为"最大努力一次提交"(Best-Effort 1PC)，意思就是系统会把最有可能出错的业务，以本地事务的方式完成后，通过不断重试的方式(不限于消息系统)来促使同个事务的其他关联业务完成。

可靠消息队列的整个实现过程完全没有任何隔离性可言。

## TCC事务的实现过程

TCC方案，天生适合用于需要强隔离性的分布式事务中。它是一种业务侵入性较强的事务方案，要求业务处理过程必须拆分为"预留业务资源"和"确认/释放消费资源"两个子过程。

TCC的实现过程分为三个阶段：

- Try：尝试执行阶段，完成所有业务可执行性的检查(保障一致性)，并且预留好事务需要用到的所有业务资源(保障隔离性)。
- Confirm：确认执行阶段，不进行任何业务检查，直接使用Try阶段准备的资源来完成业务处理。注意，Confirm阶段可能会重复执行，因此需要满足幂等性。
- Cancel：取消阶段，释放Try阶段预留的业务资源。注意，Cancel阶段也可能会重复执行，因此也需要满足幂等性。
![[Pasted image 20250828111816.png]]
TCC 在业务执行的时候，只操作预留资源，几乎不会涉及到锁和资源的争用，所以它具有很高的性能潜力。常我们并不会完全靠裸编码来实现 TCC，而是会基于某些分布式事务中间件（如阿里开源的Seata）来完成，以尽量减轻一些编码工作量。

由于Try阶段需要业务配合进行冻结(预留资源)的操作，所以对于第三方的调用无法保证他们会配合，所以Try阶段就无法进行下去。

## SAGA事务基于数据补偿代替回滚的解决思路

SAGA由两部分操作组成：

1. 把大事务拆分成若干小事务，将整个分布式事务T分解为n个子事务，我们命名为T1, T2,  ..., Ti, ..., Tn。每个子事务都应该、或者能被看做是原子行为。如果分布式事务T能够正常提交，那么它对数据的影响(最终一致性)就应该于连续按顺序成功提交子事务Ti等价。
2. 另一部分是为每一个子事务涉及对应的补偿动作，我们命名为C1, C2, ..., Ci, ..., Cn。
Ti与Ci必须满足以下条件：

- Ti与Ci都具备幂等性
- Ti与Ci满足交换律(Commutative)，即不管是先执行Ti还是先执行Ci，效果都是一样的；
- Ci必须能够成功过提交，即不考虑Ci本身提交失败被回滚的情况，如果出现就必须持续重试直至成功，或者人工介入。

如果 T1 到 Tn 均成功提交，那么事务就可以顺利完成。否则，我们就要采取以下两种恢复策略之一：

- 正向恢复(Forward Recovery): 如果Ti事务提交失败，则一直对Ti进行重试，直至成功为止(最大努力交付)。
- 反向恢复(Backward Recovery)：如果Ti事务提交失败，则一直执行Ci对Ti进行补偿，直至成功过为止(最大努力交付)。

尽管补偿操作通常比冻结 / 撤销更容易实现，但要保证正向、反向恢复过程能严谨地进行，也需要你花费不少的工夫。比如，你可能需要通过服务编排、可靠事件队列等方式来完成。所以，SAGA 事务通常也不会直接靠裸编码来实现，一般也是在事务中间件的基础上完成。我前面提到的 Seata 就同样支持 SAGA 事务模式。

SAGA同样也需要通过引入语义锁之类的机制来避免并发问题导致隔离性被破坏的情况。

## 基于数据补偿的另一种应用模式：AT事务

它大致的做法是在业务数据提交时，自动拦截所有 SQL，分别保存 SQL 对数据修改前后结果的快照，生成行锁，通过本地事务一起提交到操作的数据源中，这就相当于自动记录了重做和回滚日志

基于这种补偿方式，分布式事务中所涉及的每一个数据源都可以单独提交，然后立刻释放锁和资源。AT 事务这种异步提交的模式，相比 2PC 极大地提升了系统的吞吐量水平。而使用的代价就是大幅度地牺牲了隔离性，甚至直接影响到了原子性。因为在缺乏隔离性的前提下，以补偿代替回滚不一定总能成功。

## 理解透明多集分流系统的设计原则

作为系统的设计者，我们应该意识到不同的设施、部件在系统中，都具有各自不同的价值：

- 有一些部件位于客户端或网路的边缘，能够迅速响应用户的请求，避免给后方的I/O与CPU带来压力，典型的如**本地缓存、内容分发网络、反向代理**等。
- 有一些部件的处理能力能够线性拓展，易于伸缩，可以通过使用较小的代价堆叠机器，来获得与用户数量相匹配的并发性能，并且应尽量作为业务逻辑的主要载体，典型的如**集群中能够自动扩缩的服务节点。**
- 有一些部件的稳定服务，对系统运行具有全局性的影响，要时刻保持着容错备份，维护着高可用性，典型的如**服务注册中心、配置中心**。
- 有一些设施是天生的单点部件，只能依靠升级机器本身的网络、存储和运算性能来提升处理能力，比如位于**系统入口的路由、网关或者负载均衡器** (它们都可以做集群，但一次网络请求中无可避免至少有一个是单点的部件)、位于**请求调用链末端的传统关系数据库等**，都是典型的容易形成单点的部件。

两个简单、普适的原则，能知道我们进行设计：

- **第一个原则是尽可能减少单点部件，如果单点是无可避免的，则应尽最大限度减少到达单点部件的流量。**
- **第二个原则是奥卡姆剃刀原则，如无必要，务增实体。**
**在能满足需求的前提下，最简单的系统就是最好的系统。**

## DNS的工作原理

DNS的解析步骤如下：

- 第一步，客户端先检查本地的 DNS 缓存，查看是否存在并且是存活着的该域名的地址记录。
- 第二步，客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS）。这个本地 DNS 服务器可以由用户手工设置，也可以在 DHCP 分配时或者在拨号时，从 PPP 服务器中自动获取。
- 第三步，本地 DNS 收到查询请求后，会按照“是否有 <www.icyfenix.com.cn> 的权威服务器”→“是否有 icyfenix.com.cn 的权威服务器”→“是否有 com.cn 的权威服务器”→“是否有 cn 的权威服务器”的顺序，依次查询自己的地址记录。如果都没有查询到，本地 DNS 就会一直找到最后点号代表的根域名服务器为止。

```ad-note
这里涉及两个重要的名词：
1. **权威域名服务器(Authoritative DNS)**: 是指负责翻译特定域名的DNS服务器，"权威"是指服务器决定了这个域名应该翻译出怎样的结果。权威DNS可以用于内容分发网络、服务发现。
2. **根域名服务器(Root DNS)**：是指固定的、无需查询的顶级域名(Top-Level Domain)服务器，可以默认为它们已内置在操作系统代码之中。全世界一共有13组根域名服务器。
```

- 第四步，现在假设本地 DNS 是全新的，上面不存在任何域名的权威服务器记录，所以当 DNS 查询请求按步骤 3 的顺序，一直查到根域名服务器之后，它将会得到“cn 的权威服务器”的地址记录，然后通过“cn 的权威服务器”，得到“com.cn 的权威服务器”的地址记录，以此类推，最后找到能够解释 <www.icyfenix.com.cn> 的权威服务器地址。
- 第五步，通过“www.icyfenix.com.cn 的权威服务器”，查询 <www.icyfenix.com.cn> 的地址记录。这里的地址记录并不一定就是指 IP 地址，在 RFC 规范中，有定义的地址记录类型已经多达几十种，比如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。

DNS的缺陷：

- 响应速度慢
解决方案：前端进行DNS预取，`<link rel="dns-prefetch" href="//domain.not-icyfenx.cn">`。
- DNS的分级查询意味着每一级都有可能受到中间人攻击的威胁，产生被劫持的风险。
解决方案：HTTPDNS，把原本的DNS解析服务开放为一个基于HTTPS协议的查询服务，代替基于UDP传输协议的DNS域名解析。

## 客户端缓存

### 状态缓存

指不经过服务器，客户端直接根据缓存信息来判断目标网站的状态。以前只有301/Moved Permannently(永久重定向)这一种；后来增加了HSTS(Http Strict Transport Security)机制，用来避免301/302跳转https时，可能产生的降级中间人劫持问题。

### 实现强制缓存机制的两类Headers

- 第一类：Expires，它是HTTP/1.0中开始提供的Header，后面跟随一个截止时间参数。当服务器返回某个资源时，如果带有该 Header 的话，就意味着服务器承诺在截止时间之前，资源不会发生变动，浏览器可直接缓存该数据，不再重新发请求。

```shell
HTTP/1.1 200 OK
Expires: Wed, 8 Apr 2020 07:28:00 GMT
```

>Expires存在一些限制：
>
>- 受限于客户端的本地时间
>- 无法处理涉及到用户身份的私有资源
>- 无法描述"不缓存"的语义

- 第二类：Cache-Control，它是 HTTP/1.1 协议中定义的强制缓存 Header，它的语义比起 Expires 来说就丰富了很多。而如果 Cache-Control 和 Expires 同时存在，并且语义存在冲突（比如 Expires 与 max-age / s-maxage 冲突）的话，IETF 规定必须以 Cache-Control 为准。

```shell
HTTP/1.1 200 OK
Cache-Control: max-age=600
```

实际上，在客户端的请求Header或服务器的响应Header中，Cache-Control都可以存在，它定义了一系列的参数，并且允许自行扩展。下面是6种主要的标准参数：
>
>- max-age和s-maxage (单位是秒)
>- public和private
>- no-cache和no-store
>- no-transform
>- min-fresh和only-if-cached
>- must-revalidate和proxy-revalidate

### 协商缓存的两种变动检查机制

- **根据资源的修改时间进行检查**, 它的语义中包含了两种标准参数：Last-Modified 和 If-Modified-Since。

>Last-Modified 是服务器的响应 Header，用来告诉客户端这个资源的最后修改时间。
>
>而对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-Modified-Since，把之前收到的资源最后修改时间发送回服务端。
>
>如果此时，服务端发现资源在该时间后没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无需附带消息体，从而达到了节省流量的目的：

```shell
>HTTP/1.1 304 Not Modified
Cache-Control: public, max-age=600
Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
>```
- **根据资源唯一标识是否发生变化来进行检查**，它的语义中也包含了两种标准参数：Etag 和 If-None-Match。
>Etag 是服务器的响应 Header，用于告诉客户端这个资源的唯一标识。HTTP 服务器可以根据自己的意愿，来选择如何生成这个标识，比如 Apache 服务器的 Etag 值，就默认是对文件的索引节点（INode）、大小和最后修改时间进行哈希计算后而得到的。
>
>然后，对于带有这个 Header 的资源，当客户端需要再次请求时，就会通过 If-None-Match，把之前收到的资源唯一标识发送回服务端。
>
>如果此时，服务端计算后发现资源的唯一标识与上传回来的一致，就说明资源没有被修改过，同样也只需要返回一个 304/Not Modified 的响应即可，无需附带消息体，达到节省流量的目的：
```

HTTP/1.1 304 Not Modified
Cache-Control: public, max-age=600
ETag: "28c3f612-ceb0-4ddc-ae35-791ca840c5fa"

```

### HTTP的内容协商机制
在 HTTP 协议的设计中，一个 URL 地址是有可能提供多份不同版本的资源的，比如说，一段文字的不同语言版本，一个文件的不同编码格式版本，一份数据的不同压缩方式版本，等等。因此针对请求的缓存机制，也必须能够提供对应的支持。

```shell
HTTP/1.1 200 OK
Vary: Accept, User-Agent
```

这个响应的含义是应该根据 MINE 类型和浏览器类型来缓存资源，另外服务端在获取资源时，也需要根据请求 Header 中对应的字段，来筛选出适合的资源版本。

## 传输链路，HTTP的演化

### **1. HTTP/1.x时代的困境与"奇技淫巧"**

- 根本矛盾：HTTP协议(短小快速的资源传输) 与TCP协议(为长连接大数据量设计)之间的不匹配。TCP建立连接的三次握手和慢启动成本很高。
- 优化策略：为环节这个矛盾，前端开发者被迫采用各种技巧：
  - 减少请求数：雪碧图、文件合并、内联资源等。
  - 增加连接数：域名分片，以突破浏览器对单个域名的连接数限制。
- 副作用：这些技巧带来了缓存失效、响应延迟、DNS负担加重、缓存效率下降等新问题，是一种"两害相权取其轻"的无奈选择。

### **2. HTTP/1.x的改进与局限：连接复用**

- 持久连接(Keep-Alive)：复用TCP连接，避免多次握手。但引入了**队首阻塞(Head-of-Line Blocking)** 问题 --- 一个慢请求会阻塞同连接上所有后续请求。
- HTTP管道(Pipelining)：尝试让服务器管理请求队列，但因此实现复杂且未能根本解决队首阻塞，推广失败。

### **3. 革命性的解决方案：HTTP/2的多路复用**

- 核心机制：引入了帧(Frame) 和 流(Stream) 的概念。
  - 帧：最小的数据单位，每个帧都携带一个流ID。
  - 流：一个独立的、虚拟(逻辑上)的请求-响应双向通道。
- 如何解决队首阻塞：在同一个TCP连接上，多个流的帧可以混杂在一起传输，接收方根据流ID重新组装。这意味着一个流的阻塞不会影响其他流。
- 带来的改变：
  - 但域名单链接：彻底摆脱了连接数的限制，域名分片不再需要。
  - 请求合并称为反模式：合并小文件反而会降低缓存效率和传输灵活性。
  - 头部压缩：HTTP/2专门设计了HPACK头部压缩算法，进一步减少了传输开销。

#### **4. 传输压缩与持久化连接的冲突以及解决方案**

- 冲突：现代服务器使用即使压缩以加快首字节时间(TTFFB)，但这导致无法再传输前知道body的准确长度(即无法给出Content-length Header)，这与HTTP/1.1的持久连接机制冲突。
- 解决方案：HTTP/1.1引入了分块传输编码(Chunked Transfer Encoding)，将数据分成若干块一次发送，最后一个零长度的块标记结束，完美解决了这一冲突。

### **5. 面向未来的根本性变革：HTTP/3与QUIC**

- 为什么需要HTTP/3：HTTP/2虽然解决了应用层的对首阻塞，但底层依然基于TCP。TCP协议本身的机制(丢失重传)会导致传输层的队首阻塞 --- 一个TCP包丢失会阻塞所有流。
- 核心：HTTP/3弃用TCP，代用基于UDP的QUIC协议。
- QUIC的优势：
  - 解决队首阻塞：在QUIC层实现了可靠的传输，每个流独立处理，彻底解决了所有层面的队首阻塞。
  - 极快的连接建立：继承了TLS1.3，通常只需要0-RTT或1-RTT即可完成建连和加密握手。
  - 连接迁移：使用连接ID而非IP地址来标识连接，网络切换(如Wifi换4G)时连接不会中断。

## CDN

### **一、CDN的本质与价值**

- 解决的核心问题：主要改善网络传输速度，针对以下三点：

 1. 网站服务器出口带宽：分流，减轻原站压力。
 2. 跨运营商互联点带宽：优化跨网访问
 3. 物理链路传输时延：通过就近访问降低延迟

- 用户客户端入口带宽无法通过CDN改善，需用户自行升级。

### **二、CDN的工作原理**

1. **路由解析(依靠DNS实现)**

- 流程：
- 将原站IP在CDN服务商注册，获取一个`CNAME`记录
- 在域名DNS服务商处，为该域名配置这条`CNAME`记录
- 用户首次访问时，本地DNS查询最终被只想CDN服务商的权威DNS服务器
- CDN的DNS根据策略(拓扑、容量、时延等)返回最合适的CDN缓存节点IP给用户。
- 用户直接访问该CDN节点获取资源。
- 关键：对用户和源站(几乎)时透明的。

2. **内容分发(如何获取和管理资源)**

- 两种分发方式：
- 主动分发(Push)：需要源站主动将资源推送到CDN节点，需API配合。
- 被动回源(Pull)：用户请求未命中缓存时，CDN节点实时从源站拉取资源。
- 资源管理(更新)策略：
- 无统一标准，常见结合两种方式：
- 超时被动失效: 为缓存设置生存时间(TTL)
- 手动主动失效：通过CDN提供的API接口主动刷新缓存(常与持续集成流水线结合)

### **三、CDN的广泛应用**

1. 加速静态资源
2. 安全防御：作为源站的堡垒机，有效抵御DDos等攻击。
3. 协议升级：

- HTTP源站 -> HTTPS对外服务
- HTTP/1.x -> HTTP/2/3
- IPv4 -> IPv6

4. 状态缓存：缓存源站状态码。
5. 修改资源：
1. 自动压缩资源 + 修改  `Content-Encoding`
2. 为资源添加缓存Header
3. 修改CORS Header实现跨域
6. 访问控制：
1. IP黑/白名单那
2. 根据IP提供不同响应、QoS控制、防盗链
7. 注入功能

## 四层和七层负载均衡

### **1. 负载均衡的两种形式与总体印象**

- 四层负载均衡：工作于OSI模型的传输层。优势是性能高，因为它通常维持同一个TCP连接，只处理底层(如IP、端口)的转发。
- 七层负载均衡：工作于OSI模型的应用层。优势是功能强大，它能解析HTTP等应用层协议内容，从而做出更智能的决策。
- 关键原则：在实际架构中，通常采用多级混合负载均衡，并且是低层(四层)在前，高层(七层)在后。这样可以用四层处理大量流量，七层处理更复杂的业务逻辑。

### **2. 常见的四层负载均衡工作模式**

它们都维持客户端到服务器的同一个TCP连接。

1. 数据链路层负载均衡(三角传输/直接路由-DSR)

- 工作原理：修改传入数据帧的目标MAC地址，直接转发给后台的真实服务器(Real Server)。
- 要求：负载均衡器和所有真实服务器必须配置相同的虚拟IP(VIP)，且必须在同一个子网内(二层可达)。
- 最大优点：响应数据包不需要经过负载均衡器，可以直接返回给客户端，性能及高。
- 缺点：不能跨VLAN，网络约束大。

2. 网络层负载均衡 - IP隧道模式

- 工作原理：将原始数据包整个作为新数据包的Payload，通过IP隧道封装转发给真实的服务器。服务器收到后需要拆包。
- 优点：可以跨越VLAN。同样具备三角传输特性，响应可以直接返回给客户端。
- 缺点：仍需配置VIP，封装和解包带来额外性能开销。

3. 网络层负载均衡 - NAT模式

- 工作原理：直接修改数据包头的目标IP地址，将其改为真实服务器的IP。
- 最大问题：响应必须返回给负载均衡器，由它修改源IP后再发给客户端。这使得负载均衡器容易成为带宽瓶颈。
- 变种SNAT：连源IP也修改，对服务器更透明，当服务器无法获取客户端的真实IP。
- 优点：配置简单(服务器网关指向均衡器即可)，不需要VIP。

### **3. 七层负载均衡(应用层负载均衡)**

- 本质是反向代理：客户端与负载均衡器、负载均衡器与真实服务器之间是两条独立的TCP连接。
- 性能对比：性能低于四层模式，因为需要完整的TCP代理和应用层解析，消耗更多CPU。
- 功能强大：因其感知应用内容，可实现：
  - 智能路由：根据URL、Cookie、用户身份等路由请求。
  - 流量优化：静态资源缓存、SSL卸载、压缩等。
  - 安全防护：抵御SYN Flood等DDos攻击，过滤SQL注入等应用层攻击。
  - 链路治理：实现服务降级、熔断等微服务治理策略。

### **4. 均衡策略与实现**

- 常见策略：轮询、加权轮询、随机、加权随机、一致性哈希、响应速度、最少连接数等。
- 实现方式：
  - 软件均衡器：
    - 内核态：如LVS(性能好)。
    - 应用态：如NGINX、HAProxy(功能丰富，使用方便)。
  - 硬件均衡器：如F5、A10，采用专用芯片(ASIC)，性能更高。

## 服务端缓存(进程内缓存)

### **一、引入缓存的理由与风险**

- 目的：主要为缓解CPU压力(如存储计算结果、复用数据)和缓存I/O压力(如将磁盘/网络访问转为内存访问)。
- 风险：引入缓存会增加系统复杂度(需考虑失效、更新、一致性)、增加运维难度(可能掩盖缺陷、延迟问题暴露)、带来安全隐患(可能泄露保密数据)。

### **二、缓存的关键属性**

1. **吞吐量(Throughput)**

- 衡量并发读写效率(OPS)。高并发场景下，不同缓存方案的吞吐量差异显著(最高最低可差一个数量级)。
- 优化手段：避免数据竞争是关键。以Caffine为例，其采用异步日志提交机制(读取状态变更写入专用环形缓冲Ring Buffer，由后台线程异步处理，容忍部分状态丢失)来减少锁竞争，使其读取性能接近ConcurrentHashMap，写入性能约低10%。

2. **命中率(Hit Rate)**

- 命中率直接决定引入缓存的价值。
- 核心问题是淘汰缓存(决定那些数据是"低价值"的):
- FIFO：淘汰最早进入的数据。实现简单，但效果往往较差，可能误伤热点数据。
- LRU：淘汰最久未访问的数据。在java中可以采用HashMap + LinkedList实现，适合处理短期热点，但可能因近期未访问而误伤"老热点"。
- LFU：淘汰访问频率最低的数据，需要维护计数器，开销大且难以应对热度变化(旧数据计数器难衰减)。
- 高级改进算法(如TinyLFU、W-TinyLFU)：
- TinyLFU：采用Count-Min Sketch算法 (类似布隆过滤器) 用少量空间估算频率，并结合时间衰退算法定期减半计数器，解决旧热点问题。
- W-TinyLFU：结合LRU和LFU。新增数据先进入一个小的LRU Window Cache，积累热度后再经TinyLFU筛选进入主缓存(Segmented LRU)，更好地应对突发稀疏访问。
- 高级算法(如W-TinyLFU，ARC，LIRS) 在多数场景下命中率更接近理想状态，远优于基础策略。

3. **扩展功能(Extended Features)**

- 加载器(CacheLoader)：支持主动加载数据，是实现自动刷新的基础。
- 多种淘汰策略：可供选择。
- 失效/刷新策略：支持基于时间的自动失效或刷新。
- 时间通知：支持监听数据移除、刷新等时间。
- 并发级别设置：对于分段锁缓存(如Guava Cache)，可调整并发段数。
- 容量控制：支持设置初始容量和最大容量。
- 引用方式：支持软引用、弱引用，与JVM GC联动。
- 统计信息：提供命中率、平均加载时间等统计。
- 持久化：分布式缓存常支持将数据持久化到数据库或磁盘，但是对于进程内缓存，一般不需要。

## 分布式缓存

### ***一、分布式缓存的两种主要形式*

1. 负值式缓存

- 每个节点存储完整数据副本，读取快(无网络开销)，但写入性能随着节点增加急剧下降。
- 代表产品：JBossCache、Infinspan
- 适合场景：读多写少的数据。

2. 集中式缓存

- 数据集中存储，读写均需网络访问，但扩展性好，适合异构系统。
- 代表产品：Redis。
- 使用场景：读写均频繁的数据。

### **二、透明多级缓存(TMC)**

- 结合进程内缓存(一级) 和分布式缓存(二级)，提升性能的同时减少网络开销。
- 设计原则：
  - 变更以分布式缓存为准。
  - 访问优先读取一级缓存，未命中再读取二级缓存。
  - 通过消息通知(如Redis PUB/SUB或Zookeeper/Etcd)同步一级缓存失效。

### **三、缓存常见风险及应对策略**

1. 缓存穿透(查询不存在的数据)

- 原因：业务逻辑缺陷或恶意攻击。
- 解决：
- 缓存空值(短时间有效，等有值了再更新缓存)。
- 使用布隆过滤器快速判断数据是否存在。

2. 缓存击穿(热点数据突然失效)

- 解决：
- 加锁(互斥锁或分布式锁)，只允许一个请求重建缓存。
- 手动管理热点数据(避免自动失效)

3. 缓存雪崩(大量数据同时失效)

- 解决：
- 提升缓存系统可用性(集群部署).
- 采用多级缓存(分散过期时间)。
- 设置随机过期时间(避免)

4. 缓存污染(数据不一致)

- 原因：缓存更新不规范。
- 解决：采用Cache Aside模式：
- 读：先读缓存，未命中读数据库并回填。
- 写：先写数据库，再失效缓存(而非更新)。

## 系统认证技术：原理、标准与实现

### **一、认证的基本概念**

认证(Authentication) 是系统安全的第一道防线，核心任务是解决"你是谁"的问题，即确认操者的身份。它与授权(Authorization，解决"你能做什么")、凭证(Credentials，解决"你如何证明")、保密(Confidentiality)、传输安全(Transport Security)和验证(Verification)共同构成了软件架构安全的基础。

### **二、认证的主要方法和技术**

认证可以根据其发生的位置和方式分为三种层面：

1. 通讯信道上的认证：在建立通信连接之前验证身份，如基于SSL/TLS的认证。
2. 通讯协议上的认证：在请求资源之前验证身份，即HTTP认证框架。
3. 通讯内容上的认证：在使用服务之前验证身份，即Web认证(如表单登录和新兴的WebAuthn)。

**基于通讯协议的HTTP认证**

| 认证方案 | 基本原理 | 安全性 |
| --------------- | --------------- | --------------- |
| Basic | 用户名和密码经过Base64编码后传输 | 非常低，相当于铭文传输 |
| Digest | 对用户名、密码、服务器提供的Nonce值进行哈希处理 | 较低，仍可能受到中间人攻击 |
| Bearer | 基于OAuth2.0协议的令牌机制 | 高，依赖于令牌的安全性和传输加密 |
| HOBA | 基于自签名证书的认证 | 高，依赖于公钥基础设置(PKI) |
| AWS4-HMAC-SHA256 | 亚马逊AWS使用的基于HMAC-SHA256 | 高 |
| NTLM/Negotiate | 微软Windows NT LAN Manager认证协议 | 中等 |

**基于通讯内容的Web认证**
这是目前最常见的方式，尤其时表单认证(Form Authentication)。其优点时灵活自由，开发者可以抗旨登录页面的样式/交互逻辑等。但其背后通信的安全保障(如防窃听、防篡改)人需遵循成熟的标准和最佳实践。

**WebAuthn** 是新一代Web认证标准，它彻底摒弃密码，改用生物识别或物理安全密钥作为凭证。其核心流程是：

1. 注册：服务其生成Challenge(随机字符串)和用户ID发送给客户端。用户设备上的验证器(Authenticator)生成非对称密钥对，私钥本地安全存储，公钥签名后的Challenge发回服务器存储。
2. 登录：服务器再次下发Challenge。用户使用注册时的私钥对challenge签名并返回。服务器用存储的公钥验证签名，确认用户身份。

WebAuthn的优势在于极强的安全性(避免密码泄露和钓鱼攻击)和便捷性(无需记忆密码)。

### **三、认证的标准与规范**

- HTTP认证框架(RFC 7235)
- OAuth 2.0 / OIDC：用户授权的框架，也常被用于认证(如社交登录)。
- WebAuthn：由W3C和FIDO联盟指定的无密码认证标准。
- JAAS(Java Authentication and Authorization Service)：Java早期的安全规范，提出了许多核心概念(如Subject，Principal)，但因复杂性和与容器绑定过紧而未被广泛应用。

### **四、认证的安全考虑和最佳实践**

- 传输安全：无论使用何种安全认证方案，都必须通过HTTPS(SSL/TLS)来加密传输过程，防止凭证在传输中被窃听或篡改。
- 密码安全：如果使用密码，服务器端不应该存储明文密码，而应该存储经过加盐哈希处理后的值。
- 会话管理：认证成功后生成会话标识需安全管理，如设置合理的过期时间、防止泄露。
- 防范常见攻击：需采取措施防范重放攻击(可通过Nonce/时间戳)、CSRF攻击、XSS攻击(防止Token被窃取)等。

### **五、认证技术的未来发展趋势**

- 无密码：像WebAuthn这样的标准
- 多因素认证(MFA)：结合多种不同因素的认证方式(如密码+手机验证)
- 分布式与标准化：在微服务、云原生架构中，认证技术趋向于标准化(如OIDC)，并将认证功能外置到专门的API网关或服务网格中统一处理。

## 授权

### **1.授权概念与AAA框架**

- 授权解决 "你能干什么" 的问题，通常认证(Authentication)、审计(Audit)、和账号(Account)共同构成AAA框架。
- 授权分为两个主要问题：
  - 确保授权过程可靠
  - 确保授权结果可控

### **2.授权协议：OAuth2.0**

- **OAuth2.0**是解决多方系统中第三方应用安全授权的标准协议，常见于允许第三方应用访问资源时避免密码泄露等问题。
  - OAuth2.0通过使用令牌(Token)代替密码，避免了密码泄露的风险。
  - 令牌具有独立性：每个应用拥有自己的令牌，令牌失效不会影响其他应用。

### **3.OAuth2.0授权模式**

OAuth2.0提供四种授权方式：

- **授权码模式(Authorization Code)**: 使用于需要高安全性的场景，过程包括先获取授权码，再通过授权码换取令牌。适合具有服务端支持的应用，避免令牌泄露。
![image](./attachments/250926-182334.avif)
- **隐式授权模式(Implicit)**: 简化了授权过程，不需要使用授权码，而是直接返回令牌。适合浏览器或客户端应用，但安全性相对较低，尤其容易受到中间人攻击。
![image](./attachments/250928-164922.avif)
- **密码模式(Password Credentials)**: 将认证于授权整合到一个步骤，适用于用户高度信任的第三方应用。风险较大，因为第三方需要获取用户密码。
![image](./attachments/250928-164940.avif)
- **客户端模式(Client Credentials)**: 适用于服务间通信，无需用户参与。常用于微服务架构中，服务通过自身的身份访问资源。
![image](./attachments/250928-165006.avif)

### **4.安全考虑与设计**

- 授权码模式具有较高的安全性，避免了令牌在传输过程中的泄露。
- 隐式授权虽然简化了过程，但因省略了授权码的交换步骤，令牌更容易被泄露。
- 密码模式虽然简单，但第三方应用必须高度可信。
- 客户端模式适用于服务将认证，但不涉及用户身份。

### **5.令牌的结构与功能**

- 令牌(如JWT)是OAuth2.0的核心，用于代替密码，通常包括：
  - Header: 令牌的类型和签名算法
  - Payload: 包含发行人、过期时间、用户信息
  - Signature: 用于验证令牌的签名
- 令牌有时限性，并通过刷新令牌(Refresh Token)来延续访问权限。

### **6.设备码模式(Device Code)**

- 适用于无输入能力的设备(如打印机、电视等)，通过用户在其他设备输入用户码来授权。而授权则决定用户能访问什么资源。

## RBAC(基于角色的访问控制模型)

### **1. RBAC的核心思想与要解决的问题**

- 根本问题：所有访问控制模型都在解决"谁(User)拥有什么权限(Authority)去操作(Operation)哪些资源(Resource)"。
- 核心矛盾：在复杂系统中，直接将权限分配给用户会导致配置量巨大、容易出错。
- RBAC的解决方案：引入角色(Role)作为中间层，解耦用户和权限的直接关联。权限分配给角色，用户通过扮演角色来间接获得权限。

### **2. RBAC得关键该概念与关系**

- 用户
- 角色
- 权限(允许对资源进行某种操作的抽象权力)
- 许可(是权限的具象化实力，对哪些资源进行何种操作)
- 关系(操作和资源的组合)

### **3. RBAC的优势与原则**

- 实现最小特权原则：只给角色分配完成其职责的最小权限集合
- 灵活性与可管理型:
  - 角色继承
  - 角色互斥

### **4. 访问控制的两种类型**

- 垂直权限：也成为功能权限
- 水平权限：也成为数据权限

## 凭证：系统如何保证与用户之间的承诺是准确完整且不可抵赖的？

### 1.HTTP 的无状态管理需求

- HTTP协议本质是无状态的，每隔请求独立，这简化了协议但是不符合需要识别用户身份的实际应用场景。
- 为了解决此矛盾，引入了状态管理机制。

### 2.传统方案：Cookie-Session机制

- **工作原理**：服务器通过`Set-Cookie`头向客户端发送一个唯一标识符(如`sessionid`),客户端后续请求自动附上此Cookie。服务器以此ID为Key，在服务端存储用户状态信息。
- **优势**：
  - 安全性高：敏感状态信息存于服务端，不易在传输中泄露或篡改。
  - 控制力强：服务端可主动管理回话，如强制用户下线。
- **分布式环境下的挑战(CAP困境)**：
  - 当服务需要水平扩展时，Session的存储面临三难选择：
    - 牺牲一致性：采用亲和式负载均衡，但节点宕机会导致回话丢失。
    - 牺牲可用性：节点间同步Session，但同步成本高。
    - 牺牲分区容错性：使用集中式存储Session，但该存储点成为单点故障源。

### 3. 现代方案：JWT

- 定位：并非完全替代Cookie-Session，而是专门用于解决认证授权问题的无状态凭证。
- 工作原理：将用户信息(Payload)经过数字签名后形成一个令牌(Token)。该令牌由客户端保存并在请求时发送给服务端。服务端通过验证签名来信任令牌中的信息。
- 结构：分为三部分，用`.`分隔：
  - Header：说明令牌类型和签名算法。
  - Payload：鞋带需要传递的信息(如用户身份、权限)。
  - Signature：对前两部分的签名，确保信息未被篡改。
- 优势：
  - 无状态/水平扩展友好：服务端无需存储会话状态，可轻松扩缩容。
  - 适用于多方系统：通过非对称加密，资源服务可独立验证令牌真伪。
- 缺陷：
  - 令牌难以主动失效：一旦签发，在过期前一直有效，实现"踢人下线"等功能需引入"黑名单"等有状态逻辑。
  - 易受重放攻击：解决起来较复杂，通常建议在HTTPS信道层面解决。
  - 数据承载量有限：受HTTP Header 大小限制。
  - 客户端存储安全：令牌在客户端(如localStorage)的存储有泄露风险。
  - 无状态的副作用：实现如"在线用户统计"等功能变得困难。

### 小结

- 权衡是关键：没有绝对完美的方案，架构设计需要根据具体场景进行权衡。
  - Cookie-Session在单体架构或服务端控制力要求高的场景下依然非常优秀。
  - JWT在微服务、分布式、需要无状态水平扩展的场景下优势明显，但要接受其固有的缺陷。
- 混合策略是常态：在实践中，常会根据不同需求混合使用这两种技术，甚至引入其他方案(如将短期JWT与状态化的刷新令牌结合)。
- 安全是系统工程：无论那种方案，都需要结合HTTPS、安全的秘钥管理、合理的令牌有效期等共同构建。

## 保密：加密和解密

### 核心观点

1. 安全是连续值，而非二元选项：保密强度需要根据系统需求在安全性与成本之间平衡。并非所有系统都需要无限拔高安全等级。
2. 客户端加密的意义有限：
  a. 为防御传输过程中的窃取而进行客户端加密没有太大意义，因为网络链路本身不安全，易受中间人攻击，无法替代HTTPS的作用。
  b. 但客户端加密可防止密码在服务端被滥用(如拖库后明文泄露)，因此从服务端安全角度仍有价值。
3. 服务端密码存储是关键：真正的防御应聚焦与服务端，通过加密存储防止批量密码泄露，而非依赖客户端加密提升传输安全。

### 保密强度分级

以下列举了逐步升级的保密手段，展示安全强度与成本的平衡：

- 简单哈希摘要：防御基本泄露，但弱密码易受彩虹表攻击。
- 加盐哈希：应对弱密码，但无法防止冒认。
- 动态盐值：防止冒认，但难以组织重放攻击。
- 动态令牌：防止重放攻击，但无法防御嗅探。
- HTTPS：防御链路嗅探和重放攻击，但有证书风险等弱点。
- 更高强度手段：如U盾、双重验证、专用内网，代价更高但更安全。
- 绝对安全：一次性密码(One Time Password) 理论绝对安全，但互联网场景不可行。

### 客户端加密的争议

- 传输安全：客户端加密无法解决链路不安全问题，中间人攻击可篡改页面或代码，使加密措施失效。
- 服务端滥用防御：客户端加密可今早消灭明文密码，避免服务端存储或日志记录明文，降低拖库风险。
- 动态盐值：在客户端动态加盐通常得不偿失，无法替代HTTPS，且增加复杂度。

### 服务端密码存储与验证实践

以Fenix's Bookstore为例，介绍普通安全强度系统的密码处理流程：

1. 客户端处理：
  a. 输入明文密码
  b. 进行哈希摘要(如MD5，SHA256)，再加盐(固定或伪动态盐值)。
  c. 使用慢哈希函数(如BCrypt)增加破解成本(控制计算时间)。
2. 服务端存储：
  a. 为每隔密码生成随机盐值(使用CSPRNG，如Java的SecureRandom)。
  b. 将客户端哈希值与随机盐值再次哈希(服务端可以使用慢哈希函数，但是cost要比较小，不然会影响服务端的性能)，存储最终密文和盐值。
  c. 服务端避免使用慢哈希函数，以节省资源。
3. 验证过程：
  a. 客户端发送加密后的哈希值。
  b. 服务端用存储的盐值重新计算哈希，与数据库比对。

### 保密小结

- 架构设计权衡：安全措施需结合系统实际，平衡强度与性能。例如，普通系统配合HTTPS和密码规则即可防御多数风险。
- 服务端责任：密码加密存储应在服务端完成，重点防御拖库后的批量泄露。
- 客户端角色：客户端加密主要用于防止服务端滥用，而非传输安全。

## 传输安全

### 1. 哈希摘要

- 特点：具有易变性(输入微小改变会导致输出巨变)和不可逆性(无法从摘要结果反推原始输入)。
- 作用：主要用于验证信息完整性，确保数据未被篡改。它本身不是加密。(只是有些地方会将其用来做加密)

### 2. 加密算法

- 对称加密：加解密使用同一秘钥。有点是速度快，适合大量数据加密；缺点是秘钥分发和管理困难。
- 非对称加密：使用公钥和私钥配对。优点是解决了密钥分发难题；缺点是计算复杂性，性能慢，无法直接加密大量数据，加密的内容的长度不能超过私钥的长度。
- 实际应用：通常采用混合加密(如TLS/SSL)，即用非对称加密安全地协商一个临时密钥，再用对称加密来高效传输大量数据。

### 3. 数字签名

- 原理：结合了摘要和非堆成加密。先对信息做哈希摘要，再用私钥对摘要进行加密。验证者用对应的公钥解密签名，再与计算出的摘要对比，一致则说明信息完整且来自私钥持有者。
- 目的：用于身份认证(不可抵赖)和防止信息篡改。

下面是汇总了前面三种与密码学相关的应用，可以去深入理解它们的主要特征、用途和局限性：

![image](./attachments/251022-180200.avif)

## 数字证书
>
> **核心论点**: 在网络世界"一切皆不可信"的假设下，通过数字证书解决公钥的可信分发问题，再通过传输安全层(TLS/SSL)将复杂的安全过程自动化、对应用透明，最终实现了安全的网路通信(如HTTPS)。
>
### 1. 数字证书：如何建立共同信任？

- 问题根源：数字签名需要分发公钥，但如何确保公钥在分发过程中不被篡改？
- 解决方案：引入受信任的第三方---数字证书认证中心(CA)。
- 工作原理：
  - CA充当公证人：CA用自己的私钥对服务端的公钥及相关信息进行签名，生成数字证书。
  - 预置根证书：操作系统和浏览器出厂时已预置了受信任CA的根证书(包含CA的公钥)。这就打破了"鸡生蛋"的循环，建立齐了信任的起点。
  - 验证链条：客户端本地预置的CA根证书中的公钥，来验证服务端证书的签名是否合法。若验证通过，则信任该证书中的公钥。
- 证书格式(X.509)：一个标准证书包含的关键信息如：版本号、序列号、签名算法、颁发者(CA)、有效期、主题(持有者信息，如域名)、持有者的公钥，以及最重要的---CA的数字签名。

### 2. 传输安全层(TLS/SSL)：如何隐藏复杂性？

- 设计思想：通过在网络分层架构中加入一个安全层，让上层应用无需关心底层的安全细节，自动获取加密、防篡改和身份验证能力。
- 发展历程：从网景公司的SSL协议演进为国际标准TLS。
  - SSL 1.0 -> SSL 2.0 ->
  SSL 3.0(成为事实标准) ->
  TLS 1.0(即SSL 3.1) ->
  TLS 1.1 ->
  TLS 1.2(目前绝对主流) ->
  TLS 1.3(性能和安全大幅提升)。
- TLS 1.2 握手过程详解 (以RSA密钥交换为例)(这是一个"两轮四次"的握手，核心目标是安全地协商出后续通信使用的堆成加密秘钥):
  - Client Hello：客户端发送支持TLS版本、一个随机数、支持的密码套件列表等。
  - Server Hello：服务端确认协议版本、发送另一个随机数、选定密码套件，并发送自己的证书。
  - Client Key Exchange：客户端验证证书通过后，用证书中的公钥加密第三个随机数(PreMasterSecret)发送给服务端。此时，双发已拥有三个随机数，可以计算出相同的主密钥(MasterSecret)，即后续对称加密的回话秘钥。客户端通知改用加密通信。
  - Server Finish：服务端通知改用加密通信。握手完成，此后所有通信都使用刚协商出的密钥进行加密传输。

### 3. 关键其实与提醒

- HTTPS不等于绝对安全：仅仅“启用HTTPS”是不够的。其安全强度取决于TLS协议版本、选择的密码套件、证书的有效性（是否过期、是否被吊销） 等多种因素。需要正确配置才能确保高强度安全。

- 自动化与透明性：TLS的成功在于它将极其复杂的密码学流程（非对称加密、对称加密、证书验证、哈希签名等）完全封装起来，对开发者和用户透明，使得安全通信得以普及。

- 双向认证（mTLS）：文章提到了在云原生基础设施中重要的“双向TLS”，即服务端也需要验证客户端的证书，用于严格的服务间认证。

## 数据验证

### 1. 数据验证是系统安全的关键环节

它不仅关系到程序的正确性和稳定性，也是防止安全漏洞的重要措施。数据验证不严谨造成的问题，比黑客攻击更常见也更危险。

### 2. 层级校验的争议与痛点

在Controller、service、持久层中做校验都会带来重复校验或职责混乱的问题，因此作者建议将校验逻辑从分层中剥离出来，独立于架构层次之外。

### 3. Java Bean Validation的优势

通过标准化的注解方式(如@NotNull，@Email，@Pattern等)统一管理格式验证和业务验证，能实现：

- 校验逻辑复用
- 避免冗余防御代码
- 统一错误提示与国际化支持
- 批量校验，改善用户体验

### 4. 自定义业务校验示例

原文中展示了`@UniqueAccount`、`@AuthenticatedAccount`、`@NotConflictAccount`等自定义注解的实现方式，演示如何将复杂的业务校验与核心逻辑解耦，让验证既灵活又集中管理。

### 5. 编码建议

- 格式类校验(不涉及业务)放在Bean内部自动出发；
- 业务类校验(需要外部资源或逻辑)放在外部，由使用者决定是否出发；
- 可使用"分组校验"机制应对不同业务场景。

## 分布式系统中如何实现共识

### 1. 背景：为什么要共识？

在分布式系统中，数据需要再多台机器上存储副本以保证可靠性，但网络是不可靠的，会导致节点间状态不同步。
所以系统必须解决两个关键问题:

- 可靠性：数据不会丢失。
- 可用性：系统随时能响应。

然而，越多机器副本，系统越容易出现不同步，从而可靠与可用会冲突。
-> 解决这个问题的核心思想是：通过共识算法，让多数节点达成一致。

### 2. 状态复制模型：State Machine Replication

与"直接复制数据"不同，分布式系统更倾向于复制 **操作日志(操作转移)** 而不是复制"数据状态"本身。

- 状态机思想：只要所有节点从相同初始状态执行相同的操作序列，最终必定一致。
- Quorum机制：当超过一半节点同意，就视为"全网共识达成"。

### 3. 共识 vs 一致性

- 一致性(Consistency)：副本之间的数据相同。
- 共识(Consensus)：达成一致的过程和算法。
-> 共识是实现一致性的"方法"，不是结果。

### 4. Paxos算法(Basic Paxos)：分布式共识的理论基石

由Leslie Lamport 提出，是几乎所有现代共识算法(Raft、ZAB、PBFT)的起点。

Paxos 角色

| 角色 | 职责 |
| -------------- | --------------- |
| Proposer(提案者) | 提出要写入的值(提案) |
| Acceptor(决策者) | 投票表决提案，半数以上同意即生效 |
| Learner(学习者) | 被动同步最终结果 |

### 5. Paxos的两阶段流程

- 阶段1：Prepare(准备阶段)：
  - Proposer 向所有Acceptor发请求，附带唯一编号n。
  - Acceptor承诺：
    - 不在接受编号<=n的Prepare请求；不再接受提案ID小于n的Accept请求。
    - 返回之前已同意的提案中ID最大的那个提案所设定的值和提案ID(若有)，如果该值从来没有被任何提案设定过，则返回空值。

- 阶段2：Accept(批准阶段):
  - 若Proposer收到多数派应答：
    - 若无已批准提案，则用自己的新值；
    - 若有旧值，则沿用旧值；
    - 向所有Accetor发出"Accept请求"
  - 超过半数Acceptor同意，则提案生效，Learner同步结果。

> **结论**：Paxos通过"少数服从多数"的投票机制，使系统在存在部分失败或延迟的情况下仍能达成一致。
> ![image](./attachments/251028-171506.avif)

Basic Paxos 的价值在于开拓了分布式共识算法的发展思路，但因为它有如下缺陷，一般不会直接用于实践：Basic Paxos只能对单个值形成决议，并且决议的形成至少需要两次网络请求和应答(准备和批准各一次)，
高并发情况下将产生较大的网络开销，极端情况下甚至可能形成活锁。而实际的应用一般都是基于Multi Paxos和 Fast Paxos算法的。

## Multi Paxos、Raft再到Gossip

### 1. 分布式共识问题的核心挑战

- 难点来源：
  - 网络的不可靠(如延迟、分区、丢包等)
  - 请求的并发性(多个节点同时提出提案)
- 典型问题：
  - Basic Paxos会出现活锁(多个节点反复竞争提案导致系统无法前进)

### 2. Multi Paxos：Paxos的改进版
>
> 目标：解决 Basic Paxos并发提案带来的活锁问题。
> 核心改进：增加"选主(Leader Election)"机制。

**主要流程**

![image](./attachments/251031-155932.avif)

1. 选主阶段：
  a. 节点定时通过心跳检测主节点是否存在。
  b. 若主节点失联，发起选举，通过Basic Paxos达成"由我当主"的共识。
  c. 获得多数派同意后成为主节点。
2. 提案阶段：
  a. 所有请求统一经由主节点处理。
  b. 由于无并发竞争，系统只需执行一次批准(accept)即可达成一致。
3. 任期机制：
  a. 采用三元组(id, term, value)，term表示主节点任期，确保分区恢复后能正确识别最新主节点。

### 3. 共识问题的三大核心子问题

1. Leader Election：解决谁是主节点的问题。
2. Entity Replication：保证数据再节点间一致复制。
3. Safety：确保不会出现多个主节点或数据冲突。
只要这三点被满足，就能实现共识。

### 4. 数据复制与故障场景

- 正常复制流程：
  - 主节点写入日志 -> 广播日志 -> 从节点确认 -> 主节点提交 -> 从节点提交。
- 异常情况(网络分区)：
  - 少数派无法提交操作(因未达过半确认)。
  - 多数派继续服务，保证系统可用性。
  - 分区恢复后，旧节点回滚未提交数据，与新主同步。

### 5. 安全性(Safety) 与 终止性(Liveness)

- Safety：坏事永远不会发生(例如不会出现两个主节点)。
- Liveness：好事最终会发生(例如最终能选出主节点)。

> 现实中，Raft算法只保证Safety，Liveness通过工程手段(如随机超时)优化实现。
>
### 6. Raft算法

- 论文 In Search of an Understandable Consensus Algorithm，USENIX 2014
- 思路：将共识问题分解为选主、复制、安全三部分。
- 特点：
  - 易理解、易实现。
  - 已成为etcd、Consul、LogCabin等系统基础。
  - 与ZooKeeper的ZAB算法等价。

### 7. Gossip协议(最终一致性)

- 定义：一种"流行病式"消息传播算法，用于节点间状态同步。
- 特点：
  - 节点随机选择若干邻居传播消息。
  - 所有节点最终都会获得一致信息(但有延迟)。
  - 高鲁棒性：可容忍节点上下线、网络波动。
  - 无主节点、完全去中心化。
- 缺点：
  - 状态传播存在延迟，不一致可能被外部观测到。
  - 消息存在重复、冗余，增加网络负担。
- 两种模式：
  - 反熵(Anti-Entropy)：同步全部数据，确保完全一致，但开销大。
  - 传谣(Rumor-Mongering)：只传播变更数据，效率高但一致性延迟。
