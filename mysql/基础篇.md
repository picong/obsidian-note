![[Pasted image 20250219140559.png]]
### 连接器
数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。段连接则是执行完很少的几次查询就断开连接，下次查询再重新建立一个。
建立连接的过程通常是比较复杂的，所以通常建议在使用中尽量减少建立连接的动作，也就是尽量使用长连接。
但是因为执行过程中临时使用的内存是管理在连接对象里面的。所以会导致Mysql占用内存涨得特别快。
如何解决这个问题呢？
1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
2. 如果你用的是Mysql 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connnection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。
### 查询缓存 (mysql8.0 已经移除该功能，弊大于利)
### 分析器
对SQL语句做解析，分析器先做"词法分析"，识别关键字，确定该sql语句用来做什么的，然后做语法分析，语法分析器会根据语法规则，判断输入的SQL语句是否满足MSQL语法。
### 优化器
优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联的时候，决定各个表的连接顺序。
### 执行器
开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去世使用这个引擎提供的接口。

### binlog和redo log日志的不同点：
1. redo log是 innoDB引擎特有的；binlog是Mysql的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是"在某个数据页上做了什么修改"；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如"给 ID = 2 这一行的c字段加1"。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。"追加写"是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

下面是InnoDB引擎在执行这个简单的update语句时的内部流程：
```sql
mysql> update T set c=c+1 where ID=2;
```
1. 执行器先找引擎取 ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的binlog，并把binlog写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log 改成提交(commit) 状态，更新完成。
下图是这个update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。
![[Pasted image 20250219150324.png]]
### 两阶段提交
如果不使用两阶段提交，那么数据库的状态就有可能和用它的日志回复出来的库的状态不一致。
### 小结
redo log 用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，标识每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证Mysql异常重启之后数据不丢失。
sync_binlog这个参数设置成1的时候，标识每次事务的binlog都持久化到磁盘。这个参数也建议设置为1，这样可以保证Mysql异常重启之后binlog不丢失。
## 事务隔离
在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在"可重复读"隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在"读提交"隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，"读未提交"隔离级别下直接返回记录上的最新值，没有视图概念；而 "串行化" 隔离级别下直接用加锁的方式来避免并行访问。
### 事务隔离的实现
在Mysql中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。
![[Pasted image 20250219165706.png]]
当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、 2 、 4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制(MVCC)。对于read-view A，要得到1，就必须将当前值一次执行图中所有的回滚操作得到。
系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。
建议不要使用长事务，长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，就会导致大量占用存储空间。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮真个库。
### 事务的启动方式
1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。
```sql
`select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(), trx_started))>60`
```
## 索引的常见模型
- 哈希表 **哈希表这种结构适用于只有等值查询的场景**
- 数组 有序数组再等值查询和范围查询场景中的性能都非常优秀，但是在更新数据的时候比较麻烦，往中间插入一个记录就必须挪动后面所有的记录，成本太高。**有序数组只适合静态存储引擎**
- 二叉树，树可以有二叉也可以有多叉。二叉树是搜索效率最高的，但是索引不止存在内存中，还要写到磁盘上，二叉树树高太高会导致访问磁盘的次数增多。
- N叉树 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少地数据块。所以需要使用N叉树。
- 其他 跳表、LSM树等数据结构。
## InnoDB的索引模型
每一个索引在InnoDB里面对应一颗 B+树。
索引分类：
- 主键索引(聚簇索引): 主键索引的叶子节点存的是整行数据。
- 非主键索引(二级索引): 非主键索引的叶子节点内容是主键的值。
基于主键索引和普通索引的查询有什么区别？
基于主键的查询只需要搜索ID这颗B+树即可；
基于非主键索引的查询需要先搜索非主键索引，得到ID值再到ID索引树根据ID值进行搜索，这个过程称为回表。
## 索引维护
![[Pasted image 20250220184121.png]]
B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。

插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。

也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。

而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。

**因为非主键索引的叶子节点存的是主键值，所以主键值战的空间越小，普通索引占用的空间也就越小。**
## 索引细节
### 覆盖索引
在一个查询里面，如果有一个索引已经"覆盖了"我们的查询需求，我们称之为覆盖索引。
**由于覆盖索引可以减少对树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**
索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要根据业务查询的场景权衡考虑了。
### 最左前缀索引
最左前缀索引可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符。
在建立联合索引的时候，如何安排索引内的字段顺序：**第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。**
### 索引下推
Mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配。范围列可以用到索引，但是范围列后面的列无法用到索引。即，索引最多用于一个范围列，因此如果查询条件中有两个范围列，则无法全用到索引。

Mysql5.6引入了索引下推优化(index condition pushdown)，可以在索引遍历过程中，对索引包含的字段(但是用不到查询的余下字段)先做判断，直接过滤掉不满足条件的记录，减少回表次数。
![[Pasted image 20250221105301.png]]
![[Pasted image 20250221105307.png]]
上面两图分别代表5.6之前的版本，每次都需要回表之后再进行age的判断，5.6及之后的版本则会在遍历索引时同时判断age是否满足条件。

## 全局锁和表锁
全局锁就是对整个数据库实例加锁。Mysql提供了一个加全局读锁的方法，命令是 `Flush tables with lock`。加上该锁后，整个库处于只读状态后，其他线程的以下语句会被阻塞：数据更新语句、数据定义语句和更新类食物的提交语句。**全局锁的典型使用场景是，坐全库逻辑备份。**

mysqldump 使用参数--single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 但是--single-transaction方法只适用于所有的表使用事务引擎的库。

**既然要全库只读，为什么不使用 set global readonly = true的方式呢？**
- 在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。
- 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么Mysql会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

Mysql里面表级别的锁有两种：一种是表锁，一种是元数据锁(meta data lock，MDL)。

表锁的语法：`lock tables ... read/write`。与FTWRL类型，可以用`unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

在Mysql5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。
- 读锁之间不互斥。
- 读写锁之间，写锁之间是互斥的。
MDL会直到事务提交才释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。

## 行锁
在InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这就是两阶段协议。

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
![[Pasted image 20250224114606.png]]
出现死锁后，有两种策略：
- 直接等待，直到超时。这个超时时间可以通过参数`innodb_lock_wait_timeout`来设置。默认值是50s。
- 发起死锁检测，发现死锁后，自动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数`innodb_deadlock_detect`设置为on，表示开启这个逻辑。
如果只采用第一种策略，即不开启死锁检测，当出现死锁后，第一个被锁住的线程要过50s才会退出，这个等待时间是无法忍受的。如果将超时时间设置为1s，这样出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待也会被误伤。

死锁检测也有其性能瓶颈：每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，所以死锁检测的时间复杂度是O(n²)。如果对单行并发修改比较大，可能导致这个期间要消耗大量的CPU资源，导致CPU利用率很高，但是TPS却不是很高的情况。

死锁检测的优化方案：
1. 关闭死锁检测。
2. 控制并发度，在客户端控制不太现实，可以考虑在中间件层实现，或者如果团队内有人能修改Mysql源码，也可以做在Mysql里面。基本思路是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。
3. 通过将一行改为逻辑上的多行来减少锁冲突。

## 事务隔离性
begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用start transaction with consistent snapshot命令。但是这个命令只在可重复读隔离级别下有用，读已提交命令不生效。

在 MySQL 里，有两个“视图”的概念：
- 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view … ，而它的查询方法与表一样。
- 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。

![[Pasted image 20250225185203.png]]
所以，事务 A 查询语句的读数据流程是这样的：
- 找到 (1,3) 的时候，判断出 row trx_id=101，比高水位大，处于红色区域，不可见；
- 接着，找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；
- 再往前找，终于找到了（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。

这样执行下来，虽然期间这一行数据被修改过，但是事务 A 不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。

所以，我来给你翻译一下。一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
- 版本未提交，不可见；
- 版本已提交，但是是在视图创建后提交的，不可见；
- 版本已提交，而且是在视图创建前提交的，可见。

**更新数据都是先读后写的，而这个读，只能读当前的值，称为"当前读"(current read)，除了 update 语句外，select 语句如果加锁，也是当前读。**

事务的可重复读的能力是怎么实现的？
可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。
而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：
- 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
- 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。


## 优化器选择索引的逻辑
优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的函数越少，意味着访问裁判数据的次数越少，消耗的CPU资源越少。

当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

![[Pasted image 20250304101439.png]]
如上图所示，Mysql是这样得到索引的Cardinality的呢？
Mysql采样统计时，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

而数据表是会持续更新的，索引统计信息也不回固定不变。所以，当变更的数据行数超过1/M 的时候，会自动触发重新做一次索引统计。

在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：
- 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
- 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。
analyze table t 命令，可以用来重新统计索引信息。
![[Pasted image 20250304102219.png]]
## 索引选择异常和处理
**一种方法是，采用force index强行选择一个索引。** Mysql会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选项列表中一次判断每个索引需要扫描多少行。如果force index 指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。
缺点：来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。

**第二种方法就是，我们可以考虑修改语句，引导Mysql使用我们期望的索引。**

**第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。**
## 怎么给字符串加索引
1. 直接创建完整索引，这样可能比较占用空间；
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；```/*可以通过该sql统计覆盖索引的大致区分度*/sqlselect count(distinct left(email,4)）as L4, count(distinct left(email,5)）as L5, count(distinct left(email,6)）as L6, count(distinct left(email,7)）as L7,from SUser;```

3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

## 为什么我的Mysql会 "抖" 一下？
**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为 "脏页"。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为"干净页"。**

下图为孔乙己赊账更新和flush过程
![[Pasted image 20250304171504.png]]

**哪些场景下，需要进行脏页的flush？**
- InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。
![[Pasted image 20250304171644.png]]
checkpoint 可不是随便往前修改一下位置就可以的。比如图 2 中，把 checkpoint 位置从 CP 推进到 CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都 flush 到磁盘上。之后，图中从 write pos 到 CP’之间就是可以再写入的 redo log 的区域。
- 系统内存不足。当需要新的内存页，而内存不够用的时候，就淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是"脏页"，就要先将脏页写到磁盘。刷脏页一定会写盘，就保证了每个数据页有两种状态：
	- 一种是内存里存在，内存里的就肯定是正确的结果，直接返回；
	- 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。
- Mysql认为系统"空闲"的时候，系统会合理的安排时间，找空闲时间刷脏页。
- Mysql正常关闭的情况。

所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：
1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。
### InnoDB 刷脏页的控制策略
首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：
```shell
 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
```


InnoDB 刷脏页速度策略如下所示：
![[Pasted image 20250304174256.png]]
所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。
要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%
其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：
```shell
select VARIABLE_VALUE into @a from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。
	在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。

## 为什么表数据删掉一半，表文件大小不变？
### 参数 innodb_file_per_table
1. 这个参数设置为OFF表示，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
2. 这个参数设置为ON表示的是，每个InnoDB表数据存在在一个以.ibd为后缀的文件中。
从Mysq 5.6.6版本开始，它的默认值就是ON了。
我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

### 增删改数据都有可能造成数据空洞
delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。
但是，数据页的复用跟记录的复用是不同的。记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。
但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。
以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。![[Pasted image 20250305142823.png]]

**不止是删除数据会造成空洞，插入数据也会**
如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。

**另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。** 不难理解，这也是会造成空洞的。也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。

## 重建表
可以使用 `alter table A engine=InnoDB` 命令来重建表。
在Mysql 5.5版本之前，这个命令的执行流程如下图所示：
![[Pasted image 20250305143354.png]]
显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会在造成数据丢失。因此，在整个DDL过程中，表A中不能有更新。也就是说这个DDL不是Online的。

而在 **MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。** 
我给你简单描述一下引入了 Online DDL 之后，重建表的流程：
1. 建立一个临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
5. 用临时文件替换表 A 的数据文件。
![[Pasted image 20250305143632.png]]
可以看到，与图 3 过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。
我记得有同学在第 6 篇讲表锁的文章《全局锁和表锁 ：给表加个字段怎么索这么多阻碍？》的评论区留言说，DDL 之前是要拿 MDL 写锁的，这样还能叫 Online DDL 吗？
确实，图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。
为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。

## Online 和 inplace
inplace是指表结构才重建的过程中使用的的 “tmp_file” 是在InnoDB在内部创建出来的。整个DDL过程都在InnoDB内部完成。对于server层来说，没有把数据挪动到临时表，是一个"原地"的操作，这就是"inplace"名称的来源。
我们重建表的这个语句 alter table t engine=InnoDB，其实隐含的意思是：
```sql
alter table t engine=innodb,ALGORITHM=inplace;
```
跟inpace 对应的就是拷贝方式了，用法是：
```sql
alter table t engine=innodb,ALGORITHM=copy;
```
Online DDL是指执行DDL期间不会阻塞增删改操作。

optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。
- 从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是上面图 4 的流程了；
- analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；
- optimize table t 等于 recreate+analyze。 

## Mysql中count操作的比较
在InnoDB中，`count(*)`做了优化，InnoDB是索引组织表，逐渐索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于`count(*)`这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此MySQL优化器会找到最小的那棵树来遍历。**在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。** 

到这里我们小结一下：
- MyISAM 表虽然 `count(*)` 很快，但是不支持事务；-
- show table status 命令虽然返回很快，但是不准确；-
- InnoDB 表直接 `count(*)` 会遍历全表，虽然结果准确，但会导致性能问题。

### **应用自己实现计数，将计数值存于Redis或者数据库中** 
其实，把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。
而把计数值也放在 MySQL 中，就解决了一致性视图的问题。InnoDB 引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。这也是 InnoDB 引擎备受青睐的原因之一。
### **`count(*) count(1) count(id)` 的区别**
- 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。
- 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。

- 但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。

**所以结论是：按照效率排序的话，`count(字段)<count(主键 id)<count(1)≈count(*)`，所以我建议你，尽量使用 `count(*)`。** 

## 全字段排序
![[Pasted image 20250307182908.png]]
Extra这个字段中的"Using filesort"表示的就是需要排序，Mysql会给每个线程分配一块内存用于排序，称为sort buffer。

下图是索引示意图：
![[Pasted image 20250307183000.png]]

通常情况下，这个语句执行流程如下所示 ：
1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；
6. 对 sort_buffer 中的数据按照字段 name 做快速排序；
7. 按照排序结果取前 1000 行返回给客户端。
![[Pasted image 20250307183102.png]]

图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。
如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

## rowid 排序
max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

执行流程就变成如下所示的样子：
1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；
2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；
3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；
4. 从索引 city 取下一个记录的主键 id；
5. 重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；
6. 对 sort_buffer 中的数据按照字段 name 进行排序；
7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。

![[Pasted image 20250307183524.png]]
## 可以利用索引本身有序的原则来避免排序
```sql
alter table t add index city_user(city, name);

select city, name,age from t where city='杭州' order by name limit 1000; 
```
这样整个查询过程的流程就变成了：
1. 从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；
2. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；
3. 从索引 (city,name) 取下一个记录主键 id；
4. 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。
![[Pasted image 20250307183847.png]]

**进一步，可以通过覆盖索引，减少回表的步骤，提升查询的性能。**
![[Pasted image 20250307183928.png]]

## 随机排序如何优化
```sql
select word from words order by rand() limit 3;
```
上述语句的执行流程：
1. 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。
2. 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。
3. 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。
4. 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。
5. 从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。
6. 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。
7. 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。
![[Pasted image 20250311200533.png]]

这时候，我们就要回到一个基本概念：MySQL 的表是用什么方法来定位“一行数据”的。
在前面第 4和第 5篇介绍索引的文章中，有几位同学问到，如果把一个 InnoDB 表的主键删掉，是不是就没有主键，就没办法回表了？
其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么 InnoDB 会自己生成一个长度为 6 字节的 rowid 来作为主键。
这也就是排序模式里面，rowid 名字的来历。实际上它表示的是：
- 每个引擎用来唯一标识数据行的信息。对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；
- 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；
- MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。

到这里，我来稍微小结一下：**order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。** 

### 磁盘临时表
tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。
```shell
set tmp_table_size=1024;
set sort_buffer_size=32768;
set max_length_for_sort_data=16;
/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; 
/* 执行语句 */
select word from words order by rand() limit 3;
/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G
```
通过上述语句得到OPTIMIZER_TRACE结果如下：
![[Pasted image 20250311201341.png]]
number_of_tmp_files 的值居然是 0，难道不需要用临时文件吗？
这个 SQL 语句的排序确实没有用到临时文件，采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。

**采用大顶堆排序算法，不需要后面的数据有序，只需要保证取到的数据是有序的即可。**
而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：
1. 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；
2. 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；
3. 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。这里我简单画了一个优先队列排序过程的示意图。
![[Pasted image 20250311201616.png]]
### 随机排序的优化方案
**方案一**
1. 取得这个表的主键 id 的最大值 M 和最小值 N;
2. 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N;
3. 取不小于 X 的第一个 ID 的行。
```sql
mysql> select max(id),min(id) into @M,@N from t ;
set @X= floor((@M-@N+1)*rand() + @N);
select * from t where id >= @X limit 1;
```
**因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。**

**方案二**
1. 取得整个表的行数，并记为 C。
2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。
3. 再用 limit Y,1 取得一行。
```sql
// 由于limit后面的参数不能直接跟变量，所以在代码中需要使用prepare+execute方法
mysql> select count(*) into @C from t;set @Y = floor(@C * rand());
set @sql = concat("select * from t limit ", @Y, ",1");
prepare stmt from @sql;
execute stmt;
DEALLOCATE prepare stmt;

// 应用上述代码，取三个值来随机取三个word
mysql> select count(*) into @C from t;
set @Y1 = floor(@C * rand());
set @Y2 = floor(@C * rand());
set @Y3 = floor(@C * rand());
select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行
select * from t limit @Y2，1；
select * from t limit @Y3，1；
```
**MySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。**

**如果你直接使用 order by rand()，这个语句需要 Using temporary 和 Using filesort，查询的执行代价往往是比较大的。所以，在设计的时候你要尽量避开这种写法。**

## 查询语句不走索引的案例
### 案例一：条件字段函数操作
```sql
mysql> select count(*) from tradelog where month(t_modified)=7;
```
下面是这个t_modified索引的示意图。方框上面的数字就是month()函数对应的值。
![[Pasted image 20250312200311.png]]
**对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。**

优化sql后使其走索引的方案：
```sql
mysql> select count(*) from tradelog where
    -> (t_modified >= '2016-7-1' and t_modified<'2016-8-1') or
    -> (t_modified >= '2017-7-1' and t_modified<'2017-8-1') or 
    -> (t_modified >= '2018-7-1' and t_modified<'2018-8-1');
```
###  案例二：隐式类型转换
在Mysql中，字符串和数字做比较的话，是将字符串转换成数字。
```sql
mysql> select * from tradelog where tradeid=110717;
// 对于优化器来说，这个语句相当于（tradeid字段是varchar类型）：
mysql> select * from tradelog where  CAST(tradid AS signed int) = 110717;
```
### 案例三：隐式字符编码转换
两个表的字符集不一样关联查询是，有可能出现不走索引的情况。
```sql
mysql> select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/

// 我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话
//下面是执行获取到驱动表数据后，到驱动表中根据查询出来的条件查询满足条件的记录
mysql> select * from trade_detail where tradeid=$L2.tradeid.value; 
// 对于优化器来说等同于下面的写法
select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 
```
字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。

有两种解决方案：
- 比较常见的优化方法是，把trade_detail表上的traderid字段的字符集也改成utf8mb4，这样就没有字符集转换的问题了。
```sql
alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;
```
- 如果能够修改字段的字符集的话，是最好不过了。但是如果数据量比较大，或者业务上暂时不能做这个DDL的话，那就只能采用SQL语句的方法了。
```sql
mysql> select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 
```
这里，我主动把 l.tradeid 转成 utf8，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了。
## 只查一行，也执行很慢的原因
### **第一类：查询长时间不返回**
- 等MDL锁，这种情况可以使用`show processlist`查看Waiting for table metadata lock的PID，然后使用kill命令断开即可。
![[Pasted image 20250313161303.png]]
或者通过查询sys.schema_table_lock_waits这张表，我们就可以直接找出造成阻塞的Process id，但是需要提前对数据库有些设置（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)。
![[Pasted image 20250313161503.png]]
- 等flush，通过 `show processlist` 找到对应process id，kill掉即可。
![[Pasted image 20250313161529.png]]
- 等行锁，如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。
![[Pasted image 20250313161720.png]]
不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。
实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。

### **慢查询**
- 没有走索引的范围查询
```sql
// 由于c列上没有索引，所以需要走主键扫描
mysql> select * from t where c=50000 limit 1;
```
![[Pasted image 20250313161923.png]]
- 快照读的之前，有其他线程执行了很多次更新操作，导致快照读需要应用很多次undo log才能读到正确的值。
![[Pasted image 20250313162104.png]]
![[Pasted image 20250313162111.png]]
![[Pasted image 20250313162118.png]]

## 幻读问题
即使把所有的记录都加上锁，还是阻止不了新插入的记录。产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的"间隙"。因此，为了解决幻读问题，InnoDB在可重复读隔离级别下引入了新的锁，也就是间隙锁(Gap Lock)。
![[Pasted image 20250314101946.png]]
<center>表 t 主键索引上的行锁和间隙锁</center>


在一行行扫描的过程中，不仅将给行加上行锁，还给行两边的空隙，也加上了间隙锁。

跟行锁有冲突关系的是"另外一个行锁"。
![[Pasted image 20250314102157.png]]
**但是，跟间隙锁存在冲突关系的，是"往这个间隙中插入一个记录"这个操作。间隙锁之间都不存在冲突关系。**

间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。
间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。

间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合

间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合

## InnoDB 加锁规则
![[Pasted image 20250314105610.png]]
1. 原则1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。
2. 原则2：查找过程中访问到的对象才会加锁。
3. 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。
4. 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。
5. 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

**MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 <=5.7.24，8.0 系列 <=8.0.13。**

```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```
### **案例一：等值查询间隙锁**
![[Pasted image 20250314160504.png]]
1. 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]；
2. 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。
### **案例二：非唯一索引等值锁**
![[Pasted image 20250314160703.png]]
1. 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。
2. 要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock。
3. 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。
4. 根据原则 2 ，**只有访问到的对象才会加锁** ，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。
需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。
### **案例三：主键索引范围锁**
![[Pasted image 20250314161136.png]]
1. 开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。
2. 范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。
当前mysql版本是 `8.0.32` 没有锁id=15这一行，可能后来的版本进行了优化。
### **案例四：非唯一索引范围锁**
![[Pasted image 20250314163525.png]]
这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10]这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。

所以从结果上来看，sesson B 要插入（8,8,8) 的这个 insert 语句时就被堵住了。

这里需要扫描到 c=15 才停止扫描，是合理的，因为 InnoDB 要扫到 c=15，才知道不需要继续往后找了。
**注意：这里我将c改为唯一索引，然后第一个语句改为 select id from t where c >= 10 and c < 11 lock in share mode，session B中insert语句一样的会被block住。所以这里对于优化规则1存疑，优化规则是否只对主键索引生效还是咋回事？**
###  **案例五：唯一索引范围锁 bug** 
![[Pasted image 20250314175940.png]]
session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。

但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20]这个 next-key lock 也会被锁上。

所以你看到了，session B 要更新 id=20 这一行，是会被锁住的。同样地，session C 要插入 id=16 的一行，也会被锁住。

照理说，这里锁住 id=20 这一行的行为，其实是没有必要的。因为扫描到 id=15，就可以确定不用往后再找了。但实现上还是这么做了，因此我认为这是个 bug。
**目前我试验的版本已经复现不了了，是否没有这个bug了，需要后续查询资料。**
### **案例六：非唯一索引上存在"等值"的例子**
是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录
```sql
mysql> insert into t values(30,10,30);
```
![[Pasted image 20250314181318.png]]
这时，session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。

然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。

也就是说，这个 delete 语句在索引 c 上的加锁范围，就是下图中蓝色区域覆盖的部分。
![[Pasted image 20250314181324.png]]
### **案例七：limit 语句加锁**
例子 6 也有一个对照案例，场景如下所示：
![[Pasted image 20250314183349.png]]
案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。

因此，索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示：
![[Pasted image 20250314183420.png]]**在删除数据的时候尽量加 limit**
### **案例八：一个死锁的例子**
![[Pasted image 20250314183506.png]]
1. session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)；
2. session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待；
3. 然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。
**我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。**

## 意向锁
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」
```sql
// 现在表上加上意向共享锁，然后对读取的记录加共享锁
select ... lock in share mode;
// 先在表上加意向独占锁，然后对读取的记录加独占锁
select ... for udpate;
```
**意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而意向锁之间也不会发生冲突，只会和共享表锁(lock tables .... read) 和 独占表锁(lock tables ... write) 发生冲突。**

表锁和行锁是满足读读共享、读写互斥，写写互斥的。

如果没有 表级意向锁，那么加独占表锁时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。

那么有了 意向锁，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加 独占表锁时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。

所以，**意向锁的目的是为了快速判断表里是否有记录被加锁。**
## AUTO-INC 锁
在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过AUTO-INC锁实现的。
AUTO-INC锁是特殊的表锁机制，锁不是在一个事务提交后才释放，而是在执行完插入语句后就会立即释放。
一个事务在持有AUTO-INC锁的过程中，其他事务如果要向该表插入语句都会被阻塞，从而保证插入数据时，被AUTO_INCREMENT 修饰的字段的值是连续递增的。有大量插入操作的时候，会影响插入性能。
因此，在Mysql 5.1.22版本开始，InnoDB存储引擎提供了一种**轻量级的锁**来实现自增。

一样也是在插入数据的时候，会为被 <code>AUTO_INCREMENT</code> 修饰的字段加上轻量级锁，<strong>然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁</strong>。

InnoDB提供了个innodb_autonic_lock_mode的系统变量，是用来控制选择用AUTO-INC锁，还是轻量级的锁。
- 当innodb_autonic_lock_mode = 0，就采用AUTO-INC锁，语句执行结束后才释放锁；
- 当innodb_autonic_lock_mode = 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。
- 当innodb_autonic_lock_mode = 1;
	- 普通insert语句，自增锁在申请之后就马上释放；
	- 类似insert ... select这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
当 innodb_autonic_lock_mode = 2是性能最高的方式，但是当搭配binlog的日志格式是statement一起使用的时候，在[主从赋值的场景]中会发生数据不一致的问题。
![[Pasted image 20250317160420.png]]
**当innodb_autoinc_lock_mode = 2时，并且binlog_format=row，既能提升并发性，又不会出现数据一致性问题。**

这次我以+MySQL+8.0.32+版本，在可重复读隔离级别之下，做了几个实验，让大家了解了唯一索引和非唯一索引的行级锁的加锁规则。

我这里总结下，MySQL+行级锁的加锁规则。

唯一索引等值查询：
- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的+next-key+lock+会退化成「记录锁」。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的+next-key+lock+会退化成「间隙锁」。

非唯一索引等值查询：

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是next-key锁，而对于第一个不符合条件的二级索引记录，该二级索引的next-key锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。
- 当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的+next-key+锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。
 
 非唯一索引和主键索引的范围查询的加锁规则不同之处在于：
 - 唯一索引在满足一些条件的时候，索引的+next-key+lock+退化为间隙锁或者记录锁。
 - 非唯一索引范围查询，索引的next-key lock不会退化为间隙锁和记录锁。
 
 其实理解MySQL为什么要这样加锁，主要要以避免幻读角度去分析，这样就很容易理解这些加锁的规则了。
 
 还有一件很重要的事情，在线上在执行update、delete、select ... for update等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加next-key锁，相当于把整个表锁住了，这是挺严重的问题。

> 使用下面的命令可以分析加了什么锁：
> `select * from performance_schema.data_locks\G;`
> ![[Pasted image 20250318180529.png]]
> 从上图可以看到，共加了两个锁，分别是：
> - 表锁：X类型的意向锁；
> - 行锁：X类型的记录锁；
> 图中LOCK_TYPE中的RECORD表示行级锁，而不是记录锁的意思。
> 通过LOCK_MODE 可以确认是next-key 锁，还是间隙锁，还是记录锁：
> - `X`，说明是next-key锁；
> - `X, REC_NOT_GAP`，说明是记录锁
> - `X, GAP`，说明是间隙锁；

可以通过 `select * from information_schema.innodb_trx\G;`来查询事务的状态。

## binlog的写入机制
![[Pasted image 20250319105350.png]]
write 和 fsync的时机，是由参数 sync_binlog 控制的：
1. sync_binlog=0的时候，表示每次提交事务都只write，不fsync；
2. sync_binlog=1的时候，表示每次提交事务都会执行fsync；
3. sync_binlog=N(N>1)的时候，表示每次提交事务都write，但累积到N事务后才fsync。
## redo log的写入机制
![[Pasted image 20250319105625.png]]
上图中redo log的三种状态分别是：
1. 存在 redo log buffer 中，物理上是在Mysql进程内存中；
2. 写到磁盘(write)，但是没有持久化(fsync)，物理上是在文件系统的page cache里面；
3. 持久化到磁盘，对应的是 hard disk。

为了控制redo log的写入策略，InnoDB提供了一个 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：
1. 设置为0的时候，表示每次事务提交时都只是把redo log留在 redo log buffer中；
2. 设置为1的时候，表示每次事务提交时都将redo log 直接持久化到磁盘；
3. 设置为2的时候，表示每次事务提交时都只是把redo log 写到page cache。

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。

实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。

1. 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。
2. 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。
## 组提交(group commit)
![[Pasted image 20250319110556.png]]
从图中可以看到，
1. trx1 是第一个到达的，会被选为这组的 leader；
2. 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；
3. trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；
4. 这时候 trx2 和 trx3 就可以直接返回了。
所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。

![[Pasted image 20250319110650.png]]
<center>两阶段提交细化图</center>
binlog也可以组提交，但是由于上图中的步骤3执行很快，所以binlog的write和fsync间的间隔时间短，导致能集合到一起持久化的binlog比较少，如果想提升binlog组提交的效果，可以通过设置 binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count来实现。
1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。
这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。

WAL机制减少磁盘写主要得益与两个方面：
1. redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；
2. 组提交机制，可以大幅度降低磁盘的IOPS消耗。

## Mysql怎么保证主备一致
### **Mysql主备的基本原理**
![[Pasted image 20250319172955.png]]
为什么建议把备库节点设置为readonly：
1. 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；
2. 防止切换逻辑有bug，比如切换过程中出现双写，造成主备不一致；
3. 可以用readonly状态，来判断节点的角色。

readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，就拥有超级权限。

下图就是一个update语句在节点A执行，然后同步到节点B的完整流程图：
![[Pasted image 20250319173247.png]]
一个事务日志同步的完整过程是这样的：
1. 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。
3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
5. sql_thread 读取中转日志，解析出日志里的命令，并执行。
### **binlog三种格式对比(binlog_format)**
1. 当 binlog_format=statement 时，binlog 里面记录的就是 SQL 语句的原文。由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。
2. 当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。
3. mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。为什么会出现mixed这种格式：
	1. 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。
	2. 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。
	3. 所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。
用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：
```shell
mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;
```
### **循环复制问题**
实际生产上使用比较多的是双 M 结构，也就是下图所示的主备切换流程：
![[Pasted image 20250319173921.png]]
MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：
1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；
2. 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；
3. 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。
## Mysql高可用
在备库上通过执行`show replica status`命令，它的返回结果里面会显示`seconds_behind_master`，用于表示当前备库延迟了多少秒。
seconds_behind_master 的计算方法是这样的：
1. 每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；
2. 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。
备库连接到主库的时候，会通过执行 SELECT UNIX_TIMESTAMP() 函数来获得当前主库的系统时间。如果这时候发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值。

### **主备延迟的来源**
1. 有些部署条件下，备库所在机器的性能要比主库所在机器性能差。不过现在一般都是对称部署，毕竟备库是有可能在HA过程中升级为主库的。
2. 备库压力大，一些运营后台需要的分析语句，以及定时任务等功能，基本都放在备库上面执行。结果就是，备库上的查询耗费了大量的CPU资源，影响了同步速度，造成主备延迟。这种情况一般可以这么处理：
	1. 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。
	2. 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。
3.  大事务：一次性地用delete语句删除太多数据、大表DDL。
4.  造成主备延迟还有一个大方向的原因，就是备库的并行复制能力。

由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。

![[Pasted image 20250320175724.png]]
### **可靠性优先策略**
在图 1 的双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：
1. 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
2. 把主库 A 改成只读状态，即把 readonly 设置为 true；
3. 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
4. 把业务请求切到备库 B。

这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程。
### **可用性优先策略**
如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。

我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。

下图是可用性优先策略，且 binlog_format=mixed 时的切换流程和数据结果。
![[Pasted image 20250320180007.png]]

下图是可用性优先策略，但设置 binlog_format=row：
![[Pasted image 20250320180042.png]]

从上面的分析中，你可以看到一些结论：
1. 使用 row 格式的 binlog 时，数据不一致的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。
2. 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议你使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。

在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。所以需要实时对延迟时间进行监控。

## 并行复制策略
![[Pasted image 20250325163452.png]]
谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。如果用箭头的粗细来代表并行度的话，那么真实情况就如图 1 所示，第一个箭头要明显粗于第二个箭头。

在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。

而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。

在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。
### Mysql5.5版本上自己实现的按表分发策略
![[Pasted image 20250325163758.png]]
现在我们用事务 T 的分配流程，来看一下分配规则。
1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。
2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。
3. 事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。
4. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。
5. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。
6. coordinator 继续读下一个中转日志，继续分配事务。
### Mysql5.5版本上自己实现的按行分发策略
基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。
**相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。**

对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：
1. 耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。
2. 耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。


这两个方案其实都有一些约束条件：
1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；
2. 表必须有主键；不能有外键。
3. 表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。

### Mysql 5.6版本的并行复制策略
官方Mysql 5.6版本，支持了并发复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。

这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。
### MariaDB 的并行复制策略
而 MariaDB 的并行复制策略利用的是redo log组提交(group commit)：
1. 能够在同一组里提交的事务，一定不会修改同一行；
2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。

在实现上，MariaDB 是这么做的：
1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；
2. commit_id 直接写到 binlog 里面；
3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
4. 这一组全部执行完成后，coordinator 再去取下一批。
而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。
但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。
下图主库上事务的执行情况：
![[Pasted image 20250325170239.png]]下图是MariaDB 并行复制，备库上的事务执行情况：
![[Pasted image 20250325170357.png]]
可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。
另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。
### Mysql5.7 的并行复制策略
在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：
1. 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；
2. 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。

MySQL 5.7 并行复制策略的思想是：
1.  同时处于 prepare 状态的事务，在备库执行时是可以并行的；
2. 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的

讲 binlog 的组提交的时候，介绍过两个参数：
1.  binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。
这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。
### MySQL 5.7.22 的并行复制策略
新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。
1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。
当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。

MySQL 官方的这个实现还是有很大的优势：
1. writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；
2. 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。
当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。
## 一主多从架构，主备切换
![[Pasted image 20250326182007.png]]
一主多从结构在切换完成后，A’会成为新的主库，从库 B、C、D 也要改接到 A’。
### 基于位点的主备切换
当我们把节点B设置成节点A' 从库的时候，需要执行一条change master命令：
```sql
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
MASTER_LOG_FILE=$master_log_name 
MASTER_LOG_POS=$master_log_pos  
```
这条命令有这么 6 个参数：
- MASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。
- 最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。

考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。
一种取同步位点的方法是这样的：
1. 等待新主库 A’把中转日志（relay log）全部同步完成；
2. 在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position；
3. 取原主库 A 故障的时刻 T；
4. 用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。
```sql
mysqlbinlog File --stop-datetime=T --start-datetime=T
```
![[Pasted image 20250326182344.png]]
图中，end_log_pos 后面的值“123”，表示的就是 A’这个实例，在 T 时刻写入新的 binlog 的位置。

由于位点存在不精确的情况，所以我们在进行切换任务的时候，要先主动跳过这些错误，一般有两种常用的方法。
- 主动跳过一个事务。跳过命令的写法是：
```sql
set global sql_slave_skip_counter=1;
start slave;
```
- 通过设置slave_skip_errors参数，直接设置跳过指定的错误，如下是主备切换时经常会遇到的两类错误：
	- 1062 错误是插入数据时唯一键冲突；
	- 1032 错误是删除数据时找不到行。
	因此，我们可以把 slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。

## GTID
MySQL 5.6 版本引入了 GTID，彻底解决了主备切换复杂，容易出错的这个困难。
GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：
```sql
GTID=server_uuid:gno
```
其中：
- server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；
- gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。
GTID 模式的启动也很简单，我们只需要在启动一个 MySQL 实例的时候，加上参数 gtid_mode=on 和 enforce_gtid_consistency=on 就可以了

在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 中变量 gtid_next 的值。
1. 如果 gtid_next=automatic，代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。
	1. 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’;
	2. 把这个 GTID 加入本实例的 GTID 集合。
2. 如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next='current_gtid’指定为 current_gtid，那么就有两种可能：
	1.  如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；
	2.  如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。
	
	注意，一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。
## 基于GTID的主备切换
在 GTID 模式下，备库 B 要设置为新主库 A’的从库的语法如下：
```sql
CHANGE MASTER TO 
MASTER_HOST=$host_name 
MASTER_PORT=$port 
MASTER_USER=$user_name 
MASTER_PASSWORD=$password 
master_auto_position=1 
```
其中，master_auto_position=1 就表示这个主备关系使用的是 GTID 协议。

我们把现在这个时刻，实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。接下来，我们就看看现在的主备切换逻辑。

我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：
1. 实例 B 指定主库 A’，基于主备协议建立连接。
2. 实例 B 把 set_b 发给主库 A’。
3. 实例 A’算出 set_a 与 set_b 的差集，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。
	1.  如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；
	2.  如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；
4. 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行

其实，这个逻辑里面包含了一个设计思想：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B。
## GTID和在线DDL
在双 M 结构下，备库执行的 DDL 语句也会传给主库，为了避免传回后对主库造成影响，要通过 set sql_log_bin=off 关掉 binlog。

这样操作的话，数据库里面是加了索引，但是 binlog 并没有记录下这一个更新，是不是会导致数据和日志不一致？

假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。
这时的主备切换流程可以变成下面这样：
- 在实例 X 上执行 stop slave。
- 在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。
- 执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。
- 到实例 X 上执行以下语句序列：
```sql
set GTID_NEXT="server_uuid_of_Y:gno";
begin;
commit;
set gtid_next=automatic;
start slave;
```
这样做的目的在于，既可以让实例 Y 的更新有 binlog 记录，同时也可以确保不会在实例 X 上执行这条更新。
- 接下来，执行完主备切换，然后照着上述流程再执行一遍即可
## 读写分离的两种不同的结构
1. 下图中的结构是客户端（client）主动做负载均衡，这种模式下一般会把数据库的连接信息放在客户端的连接层。也就是说，由客户端来选择后端数据库进行查询。
![[Pasted image 20250327114144.png]]

2. 还有一种架构是，在 MySQL 和客户端之间有一个中间代理层 proxy，客户端只连接 proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。
![[Pasted image 20250327114210.png]]

**这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。** 之前我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能100% 避免的。

## 处理过期读的几种方案：
- **强制走主库**；
- **sleep方案**；（不一定就是真正的sleep，可能是通过ajax异步的将写入的数据先在页面上展示，后面刷新的时候再去从库查询，也能起到sleep的效果)
- **判断主备无延迟方案**；
	- 第一种确保主备无延迟的方法是：每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。
	- 第二种方法，对比位点确保主备无延迟：
		- Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；
		- Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。
		如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。
	- 第三种方法，对比GTID结合确保主备无延迟：
		- Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；
		- Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。
		如果这两个集合相同，也表示备库接收到的日志都已经同步完成。下图是`show slave status`命令的结果：
![[Pasted image 20250327115038.png]]
- **配合semi-sync方案；semi-sync 做了这样的设计**：
	- 事务提交的时候，主库把 binlog 发给从库；
	- 从库收到 binlog 以后，发回给主库一个 ack，表示收到了；
	- 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。
	也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。
	但是，semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。这时如果查询落到没有ack过的从库可能就会存在过期读的情况。
- **等主库位点方案**；
```sql
select master_pos_wait(file, pos[, timeout]);
```
这条命令的逻辑如下：
1. 它是在从库执行的；
2. 参数file和pos指的是主库上的文件名和位置；
3. timeout可选，设置为正整数N表示这个函数最多等待N秒。
这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。
![[Pasted image 20250327140150.png]]
这里我们假设，这条 select 查询最多在从库上等待 1 秒。那么，如果 1 秒内 master_pos_wait 返回一个大于等于 0 的整数，就确保了从库上执行的这个查询结果一定包含了 trx1 的数据。
- **等GTID方案**。
如果你的数据库开启了GTID模式，对应的也有等待GTID的方案。
```sql
 select wait_for_executed_gtid_set(gtid_set, 1);
```
这条命令的逻辑是：
1. 等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；
2. 超时返回 1。
在前面等位点的方案中，我们执行完事务后，还要主动去主库执行 show master status。而 MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。
![[Pasted image 20250327140342.png]]

在上面的第一步中，trx1 事务更新完成后，从返回包直接获取这个事务的 GTID。问题是，怎么能够让 MySQL 在执行事务后，返回包中带上 GTID 呢？

你只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可。
[Mysql api函数#shw9](https://dev.mysql.com/doc/refman/5.7/en/c-api-functions.html))

## 如何判断一个数据库是不是出问题

### **select 1 判断**
在 InnoDB 中，innodb_thread_concurrency 这个参数的默认值是 0，表示不限制并发线程数量。

通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值。

实际上，在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 128 里面的。

虽然说等锁的线程不算在并发线程计数里，但如果它在真正地执行查询，就比如我们上面例子中前三个事务中的 select sleep(100) from t，还是要算进并发线程的计数的。

![[Pasted image 20250327154159.png]]
在这个例子中，同时在执行的语句超过了设置的 innodb_thread_concurrency 的值，这时候系统其实已经不行了，但是通过 select 1 来检测系统，会认为系统还是正常的。所以可能还需要用到下面的检测方法。

**查表判断**
```sql
mysql> select * from mysql.health_check; 
```
使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。
但是，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。

**更新判断**
```sql
mysql> update mysql.health_check set t_modified=now();
```
如果我们把数据库A和B的主备关系设计为双M结构，所以在B上执行的检测命令，也要发回给主库A。
但是，如果主库A和备库B都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。

为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。
```sql
mysql> CREATE TABLE `health_check` (
  `id` int(11) NOT NULL,
  `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

/* 检测命令 */
insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();
```

**内部统计**
其实，MySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。

file_summary_by_event_name 表里有很多行数据，我们先来看看 event_name='wait/io/file/innodb/innodb_log_file’这一行。
![[Pasted image 20250327154657.png]]
如果打开所有的 performance_schema 项，性能大概会下降 10% 左右。所以，我建议你只打开自己需要的项进行统计。你可以通过下面的方法打开或者关闭某个具体项的统计。
如果要打开 redo log 的时间监控，你可以执行这个语句：
```sql
mysql> update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';
```

你可以通过 MAX_TIMER 的值来判断数据库是否出问题了。比如，你可以设定阈值，单次 IO 请求时间超过 200 毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。
```sql
mysql> select event_name,MAX_TIMER_WAIT  FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT>200*1000000000;
```
发现异常后，取到你需要的信息，再通过下面这条语句：
```sql
mysql> truncate table performance_schema.file_summary_by_event_name;
```
把之前的统计信息清空。这样如果后面的监控中，再次出现这个异常，就可以加入监控累积值了。

我个人比较倾向的方案，是优先考虑 update 系统表，然后再配合增加检测 performance_schema 的信息。

## 动态观点看加锁
### 不等号条件里的等值查询
```sql
begin;
select * from t where id>9 and id<12 order by id desc for update;
```
利用上面的加锁规则，我们知道这个语句的加锁范围是主键索引上的 (0,5]、(5,10]和 (10, 15)。也就是说，id=15 这一行，并没有被加上行锁。为什么呢？
我们说加锁单位是 next-key lock，都是前开后闭区间，但是这里用到了优化 2，即索引上的等值查询，向右遍历的时候 id=15 不满足条件，所以 next-key lock 退化为了间隙锁 (10, 15)。

但是，我们的查询语句中 where 条件是大于号和小于号，这里的“等值查询”又是从哪里来的呢？

要知道，加锁动作是发生在语句执行过程中的，所以你在分析加锁行为的时候，要从索引上的数据结构开始。这里，我再把这个过程拆解一下。

如下图所示 ，是这个表的索引 id 的示意图。
![[Pasted image 20250328162000.png]]
1. 首先这个查询语句的语义是 order by id desc，要拿到满足条件的所有行，优化器必须先找到“第一个 id<12 的值”。
2. 这个过程是通过索引树的搜索过程得到的，在引擎内部，其实是要找到 id=12 的这个值，只是最终没找到，但找到了 (10,15) 这个间隙。
3. 然后向左遍历，在遍历过程中，就不是等值查询了，会扫描到 id=5 这一行，所以会加一个 next-key lock (0,5]。

也就是说，在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法。
### 等值查询的过程
```sql
begin;
select id from t where c in(5,20,10) lock in share mode;
```
在查找 c=5 的时候，先锁住了 (0,5]。但是因为 c 不是唯一索引，为了确认还有没有别的记录 c=5，就要向右遍历，找到 c=10 才确认没有了，这个过程满足优化 2，所以加了间隙锁 (5,10)。

同样的，执行 c=10 这个逻辑的时候，加锁的范围是 (5,10] 和 (10,15)；执行 c=20 这个逻辑的时候，加锁的范围是 (15,20] 和 (20,25)。

通过这个分析，我们可以知道，这条语句在索引 c 上加的三个记录锁的顺序是：先加 c=5 的记录锁，再加 c=10 的记录锁，最后加 c=20 的记录锁。
### 怎么看死锁？
执行 show engine innodb status 命令得到的部分输出。这个命令会输出很多信息，有一节 LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息。
![[Pasted image 20250328163623.png]]
两个结论：
1. 由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；
2. 在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。
### 删除间隙锁左边值对应的行后，会扩大间隙锁的范围（在mysql 8.0.32上面不会扩大）
![[Pasted image 20250328163920.png]]

所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。但是mysql 8.0.32版本不会出现间隙锁扩大的问题，需要看源代码。8.0.31还是会存在这个问题。
### update 的例子
![[Pasted image 20250328164059.png]]
mysql 8.0.32中不会阻塞，8.0.31中还是会阻塞，所以目前来看，随着mysql版本的升级，加锁的范围是会变化的。

## 数据恢复
了找到解决误删数据的更高效的方法，我们需要先对和 MySQL 相关的误删数据，做下分类：
1. 使用 delete 语句误删数据行；
2. 使用 drop table 或者 truncate table 语句误删数据表；
3. 使用 drop database 语句误删数据库；
4. 使用 rm 命令误删整个 MySQL 实例。

### **误删行**
 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。
 Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。
 
 具体恢复数据时，对单个事务做如下处理：
 1. 对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可；
 2. 同理，对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event；
 3. 而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。
如果误删数据涉及到了多个事务的话，需要将事务的顺序调过来再执行。
### **误删库/表**
这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。
![[Pasted image 20250331095424.png]]
关于这个过程，我需要和你说明如下几点：
1. 为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况。
2. 在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：
	1. 如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；
	2. 如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。
使用mysqlbinlog方法恢复数据的速度不够快，如果误删表，最好就是只回复出这张表，也就是只重放这张表的操作，但是mysqlbinlog工具并不能指定只解析一个表的日志；用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。

**一种加速的方法是，** 在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样：
1. 在 start slave 之前，先通过执行﻿﻿change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；
2. 这样做也可以用上并行复制技术，来加速整个数据恢复过程。
![[Pasted image 20250331095755.png]]
## 延迟复制备库
Mysql5.6版本引入了延迟复制。
延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。
这个误操作的命令还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。
## 预防误删库/表的方法
第一条建议是，账号分离。这样做的目的是，避免写错命令。比如：
- 我们只给业务开发同学 DML 权限，而不给 truncate/drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持。
- 即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。
 
第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。比如：
- 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。
- 改表名的时候，要求给表名加固定的后缀（比如加 `_to_be_deleted`)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。
## rm 删除数据
对于一个有高可用机制的Mysql集群来说，最不怕的就是rm删除数据了。
如果某个节点被rm删除了，只需要把这个节点的数据恢复之后，再接入整个集群。
但是有可能一个批量下线机器的操作，会让你整个Mysql集群的所有节点都全军覆没，应对这种情况，尽量把备份跨机房，或者最好是跨城市保存。
## 为什么还有kill不掉的语句？
在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id，表示终止这个线程中正在执行的语句；一个是 kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。
### 收到kill后，线程需要做什么？
实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：
1. 把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；
2. 给 session B 的执行线程发一个信号。
为什么要发送信号？
发送信号是为了唤醒被kill的线程来处理THD::KILL_QUERY状态。

下面的例子是kill不掉的：
首先，执行 set global innodb_thread_concurrency=2，将 InnoDB 的并发线程上限数设置为 2；然后，执行下面的序列：
![[Pasted image 20250331142249.png]]
![[Pasted image 20250331142308.png]]
其实，即使是客户端退出了，这个线程的状态仍然是在等待中。那这个线程什么时候会退出呢？
答案是，只有等到满足进入 InnoDB 的条件后，session C 的查询语句继续执行，然后才有可能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION，再进入终止逻辑阶段。

**这个例子是 kill 无效的第一类情况，即：线程没有执行到判断线程状态的逻辑。** 跟这种情况相同的，还有由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态。

**另一类情况是，终止逻辑耗时较长。** 这时候，从 show processlist 结果上看也是 Command=Killed，需要等到终止逻辑完成，语句才算真正完成。这类情况，比较常见的场景有以下几种：
1. 超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。
2. 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。
3. DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。
## 两个关于客户端的误解
**第一个误解是：如果库里面的表特别多，连接就会很慢。**
当使用默认参数连接的时候，MySQL 客户端会提供一个本地库名和表名补全的功能。为了实现这个功能，客户端在连接成功后，需要多做一些操作：
1. 执行 show databases；
2. 切到 db1 库，执行 show tables；
3. 把这两个命令的结果用于构建一个本地的哈希表。

 在这些操作中，最花时间的就是第三步在本地构建哈希表的操作。所以，当一个库中的表个数非常多的时候，这一步就会花比较长的时间。
如果在连接命令中加上 -A，就可以关掉这个自动补全的功能。

除了加 -A 以外，加–quick(或者简写为 -q) 参数，也可以跳过这个阶段。但是，这个 **–quick 是一个更容易引起误会的参数，也是关于客户端常见的一个误解。**
MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：
1. 一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法。
2. 另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result 方法。
 
MySQL 客户端默认采用第一种方式，而如果加上–quick 参数，就会使用第二种不缓存的方式。采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。

## 全表扫描对server层的影响
服务端并不需要保存一个完整的结果集。取数据和发数据的流程是这样的：  
1. 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
2. 重复获取行，直到 net_buffer 写满，调用网络接口发出去。
3. 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
4. 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。![[Pasted image 20250331183434.png]]

也就是说，**MySQL 是“边读边发的”，这个概念很重要。** 这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。

如果你看到执行show processlist命令后 State 的值一直处于“Sending to client”，就表示服务器端的网络栈写满了。

- 对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，我都建议你使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。
- 有同学说到自己因为执行了一个大查询导致客户端占用内存近 20G，这种情况下就需要改用 mysql_use_result 接口了。
## 全表扫描对 InnoDB 的影响
内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。
而 Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：内存命中率。
你可以在 show engine innodb status 结果中，查看一个系统当前的 BP 命中率。
比如下图这个命中率，就是 99.0%。
![[Pasted image 20250331184024.png]]
InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%。

InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。
下图是LRU算法的模型：
![[Pasted image 20250331184120.png]]
InnoDB 管理 Buffer Pool 的 LRU 算法，是用链表来实现的。
1. 在上图的状态 1 里，链表头部是 P1，表示 P1 是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；
2. 这时候有一个读请求访问 P3，因此变成状态 2，P3 被移到最前面；
3. 状态 3 表示，这次访问的数据页是不存在于链表中的，所以需要在 Buffer Pool 中新申请一个数据页 Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表末尾 Pm 这个数据页的内存，存入 Px 的内容，然后放到链表头部。
4. 从效果上看，就是最久没有被访问的数据页 Pm，被淘汰了。
按照这个算法扫描的话，如果全表扫描一个冷表数据，就可能会把当前的Buffer Pool里的数据全部淘汰掉。

所以，InnoDB 不能直接使用这个 LRU 算法。实际上，InnoDB 对 LRU 算法做了改进。
![[Pasted image 20250331184352.png]]
在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。

改进后的 LRU 算法执行流程变成了下面这样。
1. 上图 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。
2. 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。
3. 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：
	1. 若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；
	2. 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。

## Index Nested-Loop Join
```sql
CREATE TABLE `t2` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`)
) ENGINE=InnoDB;

drop procedure idata;
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=1000)do
    insert into t2 values(i, i, i);
    set i=i+1;
  end while;
end;;
delimiter ;
call idata();

create table t1 like t2;
insert into t1 (select * from t2 where id<=100)


explain select * from t1 straight_join t2 on (t1.a=t2.a);
```
![[Pasted image 20250401160339.png]]
可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：
1. 从表 t1 中读入一行数据 R；
2. 从数据行 R 中，取出 a 字段到表 t2 里去查找；
3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；
4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束
这种情况下，可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。

通过上面的分析我们得到了两个结论：
1. 使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；
2. 如果使用 join 语句的话，需要让小表做驱动表。
但是，你需要注意，这个结论的前提是“可以使用被驱动表的索引”。

## Block Nested-Loop Join
被驱动表上没有可用的索引，算法的流程是这样的：
1. 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 `select *`，因此是把整个表 t1 放入了内存；
2. 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。
这个过程的流程图如下：
![[Pasted image 20250401160750.png]]
![[Pasted image 20250401160759.png]]
如果join_buffer放不下驱动表的所有数据，策略很简单，就是分段放。
```sql
// b列没有加索引
select * from t1 straight_join t2 on (t1.a=t2.b);
```
执行过程就变成了：
1. 扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；
2. 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；
3. 清空 join_buffer；
4. 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。
![[Pasted image 20250401161023.png]]
**join_buffer_size 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少。**

第一个问题：能不能使用 join 语句？
1. 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；
2. 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。

第二个问题是：如果要使用 join，应该选择大表做驱动表还是选择小表做驱动表？
 1. 如果是 Index Nested-Loop Join 算法，应该选择小表做驱动表；
 2. 如果是 Block Nested-Loop Join 算法：
	- 在 join_buffer_size 足够大的时候，是一样的；
	- 在 join_buffer_size 不够大的时候（这种情况更常见），应该选择小表做驱动表。
所以，这个问题的结论就是，总是应该使用小表做驱动表。

**在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。**
## Hash join
MySQL 中的 **`Using join buffer (hash join)`** 是在 **MySQL 8.0.18** 版本中首次引入的。
在8.0.18之后的版本已经使用hash join替代了 block nested loop join。
### 1. 构建阶段(Build Phase)
- Mysql 选择比较小的表(驱动表),读取其数据，并在内存中构建哈希表。
- 哈希表的Key是连接字段hash计算后的值，value是该行数据（指针）。
- 如果哈希表太大(超过 join_buffer_size)，Mysql会使用磁盘分片(Grace Hash Join)，将部分数据写入临时文件。
### 2. 探测阶段(Probe Phase)
- Mysql 扫描 较大的表(被驱动表)，计算其连接字段的哈希值，并在哈希表中查找匹配项。
- 如果找到匹配的Key，则返回连接结果；否则跳过该行。
- 如果 构建阶段使用了磁盘分片，探测阶段也会分批处理，以减少内存占用。
## Multi-Range Read 优化
因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。
这就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：
1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;
2. 将 read_rnd_buffer 中的 id 进行递增排序；
3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。
read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。
如果你想要稳定地使用 MRR 优化的话，需要设置set optimizer_switch="mrr_cost_based=off"。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。）
![[Pasted image 20250402181828.png]]
![[Pasted image 20250402181834.png]]

MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。
## Batched Key Access
MySQL 在 5.6 版本后开始引入的 Batched Key Access(BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。
下图是NLJ算法的流程图：
![[Pasted image 20250402182029.png]]
下图是对上面NLJ算法优化后的BKA算法的流程：
![[Pasted image 20250402182054.png]]
NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。

那怎么才能一次性地多传些值给表 t2 呢？方法就是，从表 t1 里一次性地多拿些行出来，一起传给表 t2。

既然如此，我们就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存不是别人，就是 join_buffer。

如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置
```sql
set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
```
## BNL(Block Nested-Loop Join) -- Mysql 8.0.x中引入了hash join，高版本中已经不存在BNL了
大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。
BNL 算法对系统的影响主要包括三个方面：
1. 可能会多次扫描被驱动表，占用磁盘 IO 资源；
2. 判断 join 条件需要执行 `M*N` 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；
3. 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。
## BNL 转 BKA
一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成 BKA 算法了。
但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。
这时候，我们可以考虑使用临时表。使用临时表的大致思路是：
1. 把表 t2 中满足条件的数据放在临时表 tmp_t 中；
2. 为了让 join 使用 BKA 算法，给临时表 tmp_t 的字段 b 加上索引；
3. 让表 t1 和 tmp_t 做 join 操作。
但是目前在mysql 8.0.31版本上，上述优化后，explain结果中没有显示BKA(可能是显示bug？)。
![[Pasted image 20250402182737.png]]

## 临时表的特性
1. 建表语法是 create temporary table ... 。
2. 一个临时表只能被创建它的session访问，对其他线程不可见。
3. 临时表可以与普通表同名。
4. 同一个session中有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。
5. show tables 命令不显示临时表。

临时表的优势包括以下两个方面：
1. 不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。
2. 不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。
## 临时表的应用
由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。

一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。比如。将一个大表 ht，按照字段 f，拆分成 1024 个分表，然后分布到 32 个数据库实例上。如下图所示：
![[Pasted image 20250408102937.png]]
如果查询语句是这样的：
```sql
select v from ht where k >= M order by t_modified desc limit 100;
```
这时候，由于查询条件里面没有用到分区字段 f，只能到所有的分区中去查找满足条件的所有行，然后统一做 order by 的操作。这种情况下，有两种比较常用的思路。

- **第一种思路是** ，在 proxy 层的进程代码中实现排序。
- **另一种思路就是** ，把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。
![[Pasted image 20250408103214.png]]
**在实践中，我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表 temp_ht 放到 32 个分库中的某一个上** 。这时的查询逻辑与上图类似。
## 不同线程可以创建同名的临时表的原理
```sql
create temporary table temp_t(id int primary key)engine=innodb;
```
执行上述创建临时表的命令时，MySQL 要给这个 InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据。**这个 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是“`#sql{进程 id}_{线程 id}_ 序列号`”**。你可以使用 select @@tmpdir 命令，来显示实例的临时文件目录。

而关于表中数据的存放方式，在不同的 MySQL 版本中有着不同的处理方式：
- 在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件；
- 而从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建 ibd 文件了。
![[Pasted image 20250408103645.png]]
上图中进程的进程号是 1234（4d2就是1234），session A 的线程 id 是 4，session B 的线程 id 是 5。所以你看到了，session A 和 session B 创建的临时表，在磁盘上的文件不会重名。

MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。
- 一个普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了。
- 而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。
在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作。
## 临时表和主备复制
如果当前的 binlog_format=row，那么跟临时表有关的语句，就不会记录到 binlog 里。也就是说，只在 binlog_format=statment/mixed 的时候，binlog 中才会记录临时表的操作。
这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行。

MySQL 在记录 binlog 的时候，不论是 create table 还是 alter table 语句，都是原样记录，甚至于连空格都不变。但是如果执行 drop table t_normal，系统记录 binlog 就会写成：
```sql
DROP TABLE `t_normal` /* generated by server */
```
原因是：drop table 命令是可以一次删除多个表的。比如，在上面的例子中，设置 binlog_format=row，如果主库上执行 "drop table t_normal, temp_t"这个命令，那么 binlog 中就只能记录：
```sql
DROP TABLE `t_normal` /* generated by server */
```

**主库上不同的线程创建同名的临时表是没关系的，但是传到备库执行是怎么处理的呢？**
![[Pasted image 20250408104351.png]]
MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key：session A 的临时表 t1，在备库的 table_def_key 就是：
1. 库名 +t1+“M 的 serverid”+“session A 的 thread_id”;
2. session B 的临时表 t1，在备库的 table_def_key 就是 ：库名 +t1+“M 的 serverid”+“session B 的 thread_id”。
由于 table_def_key 不同，所以这两个表在备库的应用线程里面是不会冲突的。

## union使用内部临时表暂存数据
```sql
(select 1000 as f) union (select id from t1 order by id desc limit 2);
```
![[Pasted image 20250410093326.png]]
这个过程的流程图如下所示：
![[Pasted image 20250410093356.png]]
可以看到，这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键 id 的唯一性约束，实现了 union 的语义。

顺便提一下，如果把上面这个语句中的 union 改成 union all 的话，就没有了“去重”的语义。这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。
![[Pasted image 20250410093418.png]]
## group by 的执行流程
```sql
select id%10 as m, count(*) as c from t1 group by m;
```
![[Pasted image 20250410093501.png]]
**上图是mysql8.0之前的执行结果，mysql 8.0之后group by已经不会再默认排序了。下面的描述都是针对上图这个执行流程而言的。**

这个语句的执行流程是这样的：
1. 创建内存临时表，表里有两个字段 m 和 c，主键是 m；扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x；
2. 如果临时表中没有主键为 x 的行，就插入一个记录 (x,1);如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1；
3. 遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。
![[Pasted image 20250410093708.png]]

内存临时表的大小是有限制的，参数 tmp_table_size 就是控制这个内存大小的，默认是 16M。
如果需要放入内存临时表的数据超过16M，这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是 InnoDB。
## group by 优化方法 -- 索引
假设，现在有一个类似下图的这么一个数据结构，我们来看看 group by 可以怎么做。
![[Pasted image 20250410094641.png]]
以看到，如果可以确保输入的数据是有序的，那么计算 group by 的时候，就只需要从左到右，顺序扫描，依次累加。也就是下面这个过程：
- 当碰到第一个 1 的时候，已经知道累积了 X 个 0，结果集里的第一行就是 (0,X);
- 当碰到第一个 2 的时候，已经知道累积了 Y 个 1，结果集里的第二行就是 (1,Y);
按照这个逻辑执行的话，扫描到整个输入的数据结束，就可以拿到 group by 的结果，不需要临时表，也不需要再额外排序。

在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新。你可以用下面的方法创建一个列 z，然后在 z 列上创建一个索引（如果是 MySQL 5.6 及之前的版本，你也可以创建普通列和索引，来解决这个问题）。
```sql
alter table t1 add column z int generated always as(id % 100), add index(z);
// 这样之前的sql就可以改成下面这一条sql语句了
select z, count(*) as c from t1 group by z;
```
![[Pasted image 20250410094912.png]]
## group by 优化方法 -- 直接排序
在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。不需要先存内存临时表，发现内存临时表空间不够存再转为磁盘临时表。

MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高（这里的数组，其实就是sort buffer）。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。
```sql
select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m;
```
因此上述sql的执行流程就变成了：
1. 初始化 sort_buffer，确定放入一个整型字段，记为 m；
2. 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中；
3. 扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）；
4. 排序完成后，就得到了一个有序数组。

![[Pasted image 20250410095304.png]]
MySQL 什么时候会使用内部临时表？
1. 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；
2. join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；
3. 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。
## 内存表的数据组织结构
```sql
create table t1(id int primary key, c int) engine=Memory;
create table t2(id int primary key, c int) engine=innodb;
insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);
```
然后，我分别执行 select * from t1 和 select * from t2。
![[Pasted image 20250410112709.png]]
InnoDB 表的数据就放在主键索引树上，主键索引是 B+ 树。所以表 t2 的数据组织方式如下图所示：
![[Pasted image 20250410112740.png]]
与 InnoDB 引擎不同，Memory 引擎的数据和索引是分开的:
![[Pasted image 20250410112800.png]]
内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。

可见，InnoDB 和 Memory 引擎的数据组织方式是不同的：
- InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为**索引组织表**（Index Organizied Table）。
- 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为**堆组织表**（Heap Organizied Table）。

从中我们可以看出，这两个引擎的一些典型不同：
1. InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；
2. 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；
3. 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；
4. InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。InnoDB 支持变长数据类型，不同记录的长度可能不同；
5. 内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。
hash索引不支持范围查询，可以通过给内存表添加btree索引来让范围查询走btree索引。
## hash索引和B-Tree索引
实际上，内存表也是支持 B-Tree 索引的。在 id 列上创建一个 B-Tree 索引，SQL 语句可以这么写：
```sql
alter table t1 add index a_btree_index using btree (id);
```
这时，表 t1 的数据组织形式就变成了这样：
![[Pasted image 20250410113132.png]]
## 内存表的锁
内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会渎职其他所有在这个报上的读写操作。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好。
## 数据持久性问题
数据放在内存中，是内存表的优势，但也是一个劣势。因为，数据库重启的时候，所有的内存表都会被清空。
**在M-S架构下，使用内存表存在的问题**
![[Pasted image 20250410113837.png]]
我们来看一下下面这个时序：
1. 业务正常访问主库；
2. 备库硬件升级，备库重启，内存表 t1 内容被清空；
3. 备库重启后，客户端发送一条 update 语句，修改表 t1 的数据行，这时备库应用线程就会报错“找不到要更新的行”。

**双 M 结构的话：**
由于 MySQL 知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，MySQL 在实现上做了这样一件事儿：在数据库重启之后，往 binlog 里面写入一行 DELETE FROM t1。
![[Pasted image 20250410113932.png]]在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。

1. 如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB 支持行锁，并发度比内存表好；
2. 能放到内存表的数据量都不大。如果你考虑的是读的性能，一个读 QPS 很高并且数据量不大的表，即使是使用 InnoDB，数据也是都会缓存在 InnoDB Buffer Pool 里的。因此，使用 InnoDB 表的读性能也不会差。

所以，**建议你把普通内存表都用 InnoDB 表来代替**。但是，有一个场景却是例外的。
内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因：
1. 临时表不会被其他线程访问，没有并发性的问题；
2. 临时表重启后也是需要删除的，清空数据这个问题不存在；
3. 备库的临时表也不会影响主库的用户线程。
之前优化join语句，关联字段没有索引时，需要创建 innodb临时表，其实可以替换成内存临时表：
```sql
create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;
insert into temp_t select * from t2 where b>=1 and b<=2000;
select * from t1 join temp_t on (t1.b=temp_t.b);
```
这里使用内存临时表的效果更好，原因有三个：
1. 相比于 InnoDB 表，使用内存表不需要写磁盘，往表 temp_t 的写数据的速度更快；
2. 索引 b 使用 hash 索引，查找的速度比 B-Tree 索引快；
3. 临时表数据只有 2000 行，占用的内存有限。
## 自增主键保存在哪儿？
不同的引擎对于自增值的保存策略不同。
- MyISAM 引擎的自增值保存在数据文件中。
- InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，具体情况是：
	- 在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。﻿
	> 举例来说，如果一个表当前数据行里最大的 id 是 10，AUTO_INCREMENT=11。这时候，我们删除 id=10 的行，AUTO_INCREMENT 还是 11。但如果马上重启实例，重启后这个表的 AUTO_INCREMENT 就会变成 10。﻿
	
	> 也就是说，MySQL 重启可能会修改一个表的 AUTO_INCREMENT 的值。
	- 在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。

## 自增值修改机制
新的自增值生成算法是：从 auto_increment_offset 开始，以 auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。

其中，auto_increment_offset 和 auto_increment_increment 是两个系统参数，分别用来表示自增的初始值和步长，默认值都是 1。
> 备注：在一些场景下，使用的就不全是默认值。比如，双 M 的主备结构里要求双写的时候，我们就可能会设置成 auto_increment_increment=2，让一个库的自增 id 都是奇数，另一个库的自增 id 都是偶数，避免两个库生成的主键发生冲突。

当 auto_increment_offset 和 auto_increment_increment 都是 1 的时候，新的自增值生成逻辑很简单，就是：
1. 如果准备插入的值 >= 当前自增值，新的自增值就是“准备插入的值 +1”；
2. 否则，自增值不变。
## 自增值的修改时机
![[Pasted image 20250410160100.png]]

![[Pasted image 20250410160010.png]]
**唯一键冲突是导致自增主键 id 不连续的第一种原因。**
**回滚也会产生类似的现象，这就是第二种原因。**

自增值为什么不能回退。

假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请。
1. 假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。
2. 事务 B 正确提交了，但事务 A 出现了唯一键冲突。
3. 如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。
4. 接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。

而为了解决这个主键冲突，有两种方法：
1. 每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在。
2. 把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。
## 自增锁的优化
在 MySQL 5.0 版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。
MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值是 1。
1. 这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁；
2. 这个参数的值被设置为 1 时：
	1. 普通 insert 语句，自增锁在申请之后就马上释放；
	2. 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；
3. 这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁

![[Pasted image 20250410160750.png]]
由于两个 session 是同时执行插入数据命令的，所以 binlog 里面对表 t2 的更新日志只有两种情况：要么先记 session A 的，要么先记 session B 的。

但不论是哪一种，这个 binlog 拿去从库执行，或者用来恢复临时实例，备库和临时实例里面，session B 这个语句执行出来，生成的结果里面，id 都是连续的。这时，这个库就发生了数据不一致。

这是因为原库 session B 的 insert 语句，生成的 id 不连续。这个不连续的 id，用 statement 格式的 binlog 来串行执行，是执行不出来的。

而要解决这个问题，有两种思路：
1. 一种思路是，让原库的批量插入数据语句，固定生成连续的 id 值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的。
2. 另一种思路是，在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是 innodb_autoinc_lock_mode 设置为 2，同时 binlog_format 设置为 row。

需要注意的是，我这里说的**批量插入数据，包含的语句类型是 insert … select、replace … select 和 load data 语句。**

但是，在普通的 insert 语句里面包含多个 value 值的情况下，即使 innodb_autoinc_lock_mode 设置为 1，也不会等语句执行完成才释放锁。因为这类语句在申请自增 id 的时候，是可以精确计算出需要多少个 id 的，然后一次性申请，申请完成后锁就可以释放了。

对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：
1. 语句执行过程中，第一次申请自增 id，会分配 1 个；
2. 1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；
3. 2 个用完以后，还是这个语句，第三次申请自增 id，会分配 4 个；
4. 依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。
```sql
insert into t values(null, 1,1);
insert into t values(null, 2,2);
insert into t values(null, 3,3);
insert into t values(null, 4,4);
create table t2 like t;
insert into t2(c,d) select c,d from t;
insert into t2 values(null, 5,5);
-- 结果为8,5,5
```
**主键id出现不连续的第三种原因就是因为上述的批量会预先分配两倍的id。**

## insert ... select 语句的加锁规则
我们一起来看看为什么在可重复读隔离级别下，binlog_format=statement 时执行：
```sql
insert into t2(c,d) select c,d from t;
```
这个语句时，需要对表 t 的所有行和间隙加锁呢？
![[Pasted image 20250411151521.png]]
实际的执行效果是，如果 session B 先执行，由于这个语句对表 t 主键索引加了 (-∞,1]这个 next-key lock，会在语句执行完成后，才允许 session A 的 insert 语句执行。

但如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况。于是，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：
```sql
insert into t values(-1,-1,-1);
insert into t2(c,d) select c,d from t;
```
这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。
## insert 循环写入
```sql
insert into t2(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
```
这个语句的加锁范围，就是表 t 索引 c 上的 (3,4]和 (4,supremum]这两个 next-key lock，以及主键索引上 id=4 这一行。它的执行流程也比较简单，从表 t 中按照索引 c 倒序，扫描第一行，拿到结果写入到表 t2 中。因此整条语句的扫描行数是 1。这个语句执行的慢查询日志（slow log），如下图所示：
![[Pasted image 20250411151822.png]]
通过这个慢查询日志，我们看到 Rows_examined=1，正好验证了执行这条语句的扫描行数为 1。

那么，如果我们是要把这样的一行数据插入到表 t 中的话：
```sql
insert into t(c,d)  (select c+1, d from t force index(c) order by c desc limit 1);
```
**老版本Mysql上面扫描行数是5，但是目前在mysql8.0.31上面扫描行数是1. 一下说明是针对老版本的。**

个语句会导致在表 t 上做全表扫描，并且会给索引 c 上的所有间隙都加上共享的 next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。
至于这个语句的执行为什么需要临时表，原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。
**新版本中，不会加所有的next-key lock，也是在索引 c 上的加(3,4]和 (4,supremum]这两个next-key lock。**
## insert 唯一键冲突
![[Pasted image 20250411152830.png]]
session A 执行的 insert 语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。我们前面说过，一个 next-key lock 就是由它右边界的值定义的。这时候，session A 持有索引 c 上的 (5,10]共享 next-key lock（读锁）。**注意这里，我们可以通过 select * from performance_schema.data_locks\G; 来查看加锁情况。**

至于为什么要加这个读锁，其实我也没有找到合理的解释。从作用上来看，这样做可以避免这一行被别的事务删掉。

### 一个唯一键冲突导致死锁的例子
![[Pasted image 20250411153558.png]]

![[Pasted image 20250411153613.png]]
## insert into ... on duplicate key update
```sql
insert into t values(11,10,10) on duplicate key update d=100; 
```
上面的sql会给索引 c 上 (5,10] 加一个排他的 next-key lock（写锁）。
insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。

现在表 t 里面已经有了 (1,1,1) 和 (2,2,2) 这两行，我们再来看看下面这个语句执行的效果
![[Pasted image 20250411153720.png]]
可以看到，主键 id 是先判断的，MySQL 认为这个语句跟 id=2 这一行冲突，所以修改的是 id=2 的行。

需要注意的是，执行这条语句的 affected rows 返回的是 2，很容易造成误解。实际上，真正更新的只有一行，只是在代码实现上，insert 和 update 都认为自己成功了，update 计数加了 1， insert 计数也加了 1。

**insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。**

## mysqldump导出一组Insert语句。
```sql
create database db1;
use db1;

create table t(id int primary key, a int, b int, index(a))engine=innodb;
delimiter ;;
  create procedure idata()
  begin
    declare i int;
    set i=1;
    while(i<=1000)do
      insert into t values(i,i,i);
      set i=i+1;
    end while;
  end;;
delimiter ;
call idata();

create database db2;
create table db2.t like db1.t
```

假设，我们要把 db1.t 里面 a>900 的数据行导出来，插入到 db2.t 中。使用mysqldump如下命令导出一组Insert语句：
```shell
mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
```
这条命令中，主要参数含义如下：
1. –single-transaction 的作用是，在导出数据的时候不需要对表 db1.t 加表锁，而是使用 START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法；
2. –add-locks 设置为 0，表示在输出的文件结果里，不增加" LOCK TABLES t WRITE;" ；
3. –no-create-info 的意思是，不需要导出表结构；
4. –set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息；
5. –result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的。
如果你希望生成的文件中一条 INSERT 语句只插入一行数据的话，可以在执行 mysqldump 命令时，加上参数–skip-extended-insert，不建议一条sql插入一行，这样插入更耗性能。

可以使用下面命令在db2上面执行这些导出的Insert语句。
```shell
mysql -h127.0.0.1 -P13000  -uroot db2 -e "source /client_tmp/t.sql"
```

mysql 客户端执行这个命令的流程是这样的：
1. 打开文件，默认以分号为结尾读取一条条的 SQL 语句；
2. 将 SQL 语句发送到服务端执行。
## 导出CSV文件
MySQL 提供了下面的语法，用来将查询结果导出到服务端本地目录：
```sql
select * from db1.t where a>900 into outfile '/server_tmp/t.csv';
```

我们在使用这条语句时，需要注意如下几点：
1. 这条语句会将结果保存在服务端。如果你执行命令的客户端和 MySQL 服务端不在同一个机器上，客户端机器的临时目录下是不会生成 t.csv 文件的。
2. into outfile 指定了文件的生成位置（/server_tmp/），这个位置必须受参数 secure_file_priv 的限制。参数 secure_file_priv 的可选值和作用分别是：
	- 如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置；
	- 如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录；
	- 如果设置为 NULL，就表示禁止在这个 MySQL 实例上执行 select … into outfile 操作。
3. 这条命令不会帮你覆盖文件，因此你需要确保 /server_tmp/t.csv 这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。

得到.csv 导出文件后，你就可以用下面的 load data 命令将数据导入到目标表 db2.t 中。
```sql
load data infile '/server_tmp/t.csv' into table db2.t;
```
执行流程如下所示：
1. 打开文件 /server_tmp/t.csv，以制表符 (\t) 作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取；
2. 启动事务。
3. 判断每一行的字段数与表 db2.t 是否相同：
	- 若不相同，则直接报错，事务回滚；
	- 若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。
4. 重复步骤 3，直到 /server_tmp/t.csv 整个文件读入完成，提交事务。

**如果 binlog_format=statement，这个 load 语句记录到 binlog 里以后，怎么在备库重放，如下所示：**
1. 主库执行完成后，将 /server_tmp/t.csv 文件的内容直接写到 binlog 文件中。
2. 往 binlog 文件中写入语句 load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE `db2`.`t`。
3. 把这个 binlog 日志传到备库。
4. 备库的 apply 线程在执行这个事务日志时：
	1.  先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录 /tmp/SQL_LOAD_MB-1-0 中；
	2.  再执行 load data 语句，往备库的 db2.t 表中插入跟主库相同的数据。
![[Pasted image 20250411173446.png]]

load data 命令有两种用法：
1. 不加“local”，是读取服务端的文件，这个文件必须在 secure_file_priv 指定的目录或子目录下；
2. 加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。
## 物理拷贝
假设我们现在的目标是在 db1 库下，复制一个跟表 t 相同的表 r，具体的执行步骤如下：
![[Pasted image 20250411173721.png]]
关于拷贝表的这个流程，有以下几个注意点：
1. 在第 3 步执行完 flsuh table 命令之后，db1.t 整个表处于只读状态，直到执行 unlock tables 命令后才释放读锁；
2. 在执行 import tablespace 的时候，为了让文件里的表空间 id 和数据字典中的一致，会修改 r.ibd 的表空间 id。而这个表空间 id 存在于每一个数据页中。因此，如果是一个很大的文件（比如 TB 级别），每个数据页都需要修改，所以你会看到这个 import 语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，import 语句的耗时是非常短的。

我们来对比一下这三种方法的优缺点。
1. 物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性：
	-  必须是全表拷贝，不能只拷贝部分数据；
	-  需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用；
	- 由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。
2. 用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。
3. 用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份

## Mysql中创建用户
```sql
create user 'ua'@'%' identified by 'pa';
```
这条语句的逻辑是创建一个用户’ua’@’%’，密码是 pa。注意，在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户。
这条命令做了两个动作：
1. 磁盘上，往 mysql.user 表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是 N；
2. 内存里，往数组 acl_users 里插入一个 acl_user 对象，这个对象的 access 字段值为 0。
## 权限
**全局权限**
```sql
grant all privileges on *.* to 'ua'@'%' with grant option;
```
这个 grant 命令做了两个动作：
1. 磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为‘Y’；
2. 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。
在这个 grant 命令执行完成后，如果有新的客户端使用用户名 ua 登录成功，MySQL 会为新连接维护一个线程对象，然后从 acl_users 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。

如果要回收上面的 grant 语句赋予的权限，你可以使用下面这条命令：
```sql
revoke all privileges on *.* from 'ua'@'%';
```
这条 revoke 命令的用法与 grant 类似，做了如下两个动作：
1. 磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为“N”；
2. 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 的值修改为 0。

**db权限**
```sql
grant all privileges on db1.* to 'ua'@'%' with grant option;
```
基于库的权限记录保存在 mysql.db 表中，在内存里则保存在数组 acl_dbs 中。这条 grant 命令做了如下两个动作：
1. 磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”；
2. 内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。
每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 acl_dbs 数组，根据 user、host 和 db 找到匹配的对象，然后根据对象的权限位来判断。也就是说，grant 修改 db 权限的时候，是同时对磁盘和内存生效的。

grant操作对于已经存在的连接的影响，在全局权限和db的权限效果是不同的。
![[Pasted image 20250415183223.png]]
需要说明的是，图中 set global sync_binlog 这个操作是需要 super 权限的。

可以看到，虽然用户 ua 的 super 权限在 T3 时刻已经通过 revoke 语句回收了，但是在 T4 时刻执行 set global 的时候，权限验证还是通过了。这是因为 super 是全局权限，这个权限信息在线程对象中，而 revoke 操作影响不到这个线程对象。

而在 T5 时刻去掉 ua 对 db1 库的所有权限后，在 T6 时刻 session B 再操作 db1 库的表，就会报错“权限不足”。这是因为 acl_dbs 是一个全局数组，所有线程判断 db 权限都用这个数组，这样 revoke 操作马上就会影响到 session B。

这里在代码实现上有一个特别的逻辑，如果当前会话已经处于某一个 db 里面，之前 use 这个库的时候拿到的库权限会保存在会话变量中。

**表权限和列权限**
```sql
create table db1.t1(id int, a int);

grant all privileges on db1.t1 to 'ua'@'%' with grant option;
GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO 'ua'@'%' with grant option;
```

flush privileges 命令会清空 acl_users 数组，然后从 mysql.user 表中读取数据重新加载，重新构造一个 acl_users 数组。也就是说，以数据表中的数据为准，会将全局权限内存数组重新加载一遍。
也就是说，如果内存的权限数据和磁盘数据表相同的话，不需要执行 flush privileges。而如果我们都是用 grant/revoke 语句来执行的话，内存和数据表本来就是保持同步更新的。
**因此，正常情况下，grant 命令之后，没有必要跟着执行 flush privileges 命令。**
## flush privileges 使用场景
显然，当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态。
这种不一致往往是由不规范的操作导致的，比如直接用 DML 语句操作系统权限表。

不建议像下面一样使用grant语句：
```sql
grant super on *.* to 'ua'@'%' identified by 'pa';
```
这条命令加了 identified by ‘密码’， 语句的逻辑里面除了赋权外，还包含了：
1. 如果用户’ua’@’%'不存在，就创建这个用户，密码是 pa；
2. 如果用户 ua 已经存在，就将密码修改成 pa。
这也是一种不建议的写法，因为这种写法很容易就会不慎把密码给改了。
## 分区表的创建
```sql
CREATE TABLE `t` (
  `ftime` datetime NOT NULL,
  `c` int(11) DEFAULT NULL,
  KEY (`ftime`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1
PARTITION BY RANGE (YEAR(ftime))
(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,
 PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,
 PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,
PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);
insert into t values('2017-4-1',1),('2018-4-1',1);
```
下图是表t的磁盘文件：
![[Pasted image 20250416105259.png]]
也就是说：
1. 对于引擎层来说，这是 4 个表；
2. 对于 Server 层来说，这是 1 个表。
## 分区表的引擎层行为
![[Pasted image 20250416105341.png]]
![[Pasted image 20250416105413.png]]

看完 InnoDB 引擎的例子，我们再来一个 MyISAM 分区表的例子。

我首先用 alter table t engine=myisam，把表 t 改成 MyISAM 表；然后，我再用下面这个例子说明，对于 MyISAM 引擎来说，这是 4 个表。
![[Pasted image 20250416105512.png]]这正是因为 MyISAM 的表锁是在引擎层实现的，session A 加的表锁，其实是锁在分区 p_2018 上。因此，只会堵住在这个分区上执行的查询，落到其他分区的查询是不受影响的。

区表和手工分表，一个是由 server 层来决定使用哪个分区，一个是由应用层代码来决定使用哪个分表。因此，从引擎层看，这两种方式也是没有差别的。
## 分区策略
MyISAM 分区表使用的分区策略，我们称为**通用分区策略**（generic partitioning），每次访问分区都由 server 层控制。通用分区策略，是 MySQL 一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。

从 MySQL 5.7.9 开始，InnoDB 引擎引入了**本地分区策略**（native partitioning）。这个策略是在 InnoDB 内部自己管理打开分区的行为。

MySQL 从 5.7.17 开始，将 MyISAM 分区表标记为即将弃用 (deprecated)。
## 分区表的server层行为
如果从 server 层看的话，一个分区表就只是一个表。
![[Pasted image 20250416105729.png]]
可以看到，虽然 session B 只需要操作 p_2017 这个分区，但是由于 session A 持有整个表 t 的 MDL 锁，就导致了 session B 的 alter 语句被堵住。

小结：
1. MySQL 在第一次打开分区表的时候，需要访问所有的分区；
2. 在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；
3. 在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。
## 分区表的应用场景
分区表的一个显而易见的优势是对业务透明。
可以直接通过 alter table t drop partition ... 这个语法删掉分区，从而删掉过期的历史数据。
这个 alter table t drop partition ... 操作是直接删除分区文件，效果跟 drop 普通表类似。

实际使用时，分区表跟用户分表比起来，有两个绕不开的问题：一个是第一次访问的时候需要访问所有分区，另一个是共用 MDL 锁。
## 优化器对join不同写法的优化
```sql
create table a(f1 int, f2 int, index(f1))engine=innodb;
create table b(f1 int, f2 int)engine=innodb;
insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);
insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8);
```

下面两个sql执行的结果会不一样：
```sql
select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/
select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/
```
![[Pasted image 20250416184231.png]]
为什么语句 Q1 和 Q2 这两个查询的执行流程会差距这么大呢？
其实，这是因为优化器基于 Q2 这个查询的语义做了优化。

为了理解这个问题，我需要再和你交代一个背景知识点：在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。
这里包括， select NULL = NULL 的结果，也是返回 NULL。因此，语句 Q2 里面 where a.f2=b.f2 就表示，查询结果里面不会包含 b.f2 是 NULL 的行，这样这个 left join 的语义就是“找到这两个表里面，f1、f2 对应相同的行。对于表 a 中存在，而表 b 中匹配不到的行，就放弃”。

这样，这条语句虽然用的是 left join，但是语义跟 join 是一致的。

在执行 explain 之后，你再执行 show warnings，就能看到这个改写的结果:
![[Pasted image 20250416184349.png]]

个例子说明，即使我们在 SQL 语句中写成 left join，执行过程还是有可能不是从左到右连接的。也就是说，**使用 left join 时，左边的表不一定是驱动表。**
**join 将判断条件是否全部放在 on 部分就没有区别了。**

## 表自定义自增id
表定义的自增值达到上限后的逻辑是：再申请下一个id时，得到的值保持不变。会导致了第二个 insert 语句又拿到相同的自增 id 值，再试图执行插入语句，报主键冲突错误。
## InnoDB系统自增row_id
如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 row_id。InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。

row_id就有两个特征：
1. row_id 写入表中的值范围，是从 0 到 248-1；
2. 当 dict_sys.row_id=248时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。
## Xid
MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。

而 global_query_id 是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。

但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。
## Innodb trx_id
Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。

InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。

InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。
![[Pasted image 20250417115543.png]]
只读事务不分配 trx_id，有什么好处呢？
1. 一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB 就只需要拷贝读写事务的 trx_id。
2. 另一个好处是，可以减少 trx_id 的申请次数。在 InnoDB 里，即使你只是执行一个普通的 select 语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请 trx_id，就大大减少了并发事务申请 trx_id 的锁冲突。
## thread_id
接下来，我们再看看线程 id（thread_id）。其实，线程 id 才是 MySQL 中最常见的一种自增 id。平时我们在查各种现场的时候，show processlist 里面的第一列，就是 thread_id。

MySQL 设计了一个唯一数组的逻辑，给新线程分配 thread_id 的时候，逻辑代码是这样的：
```c
do {
  new_id= thread_id_counter++;
} while (!thread_ids.insert_unique(new_id).second);
```
### 小结
每种自增 id 有各自的应用场景，在达到上限后的表现也不同：
1. 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
2. row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。
3. Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
4. InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
5. thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。
