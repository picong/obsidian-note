# Mysql的逻辑架构
- 最上层的客户端所包含的服务并不是Mysql所独有的：包括连接处理、身份验证、确保安全性等。
- 第二层服务层，大多数Mysql的核心功能都在这一层，包括解析、分析、优化、以及所有的内置函数（例如，日期、时间、数学和加密函数），所有跨存储引擎的功能也都在这一层实现：存储过程、触发器、视图等。
- 第三层是存储引擎层。
# 事务日志
事务日志有助于提高事务的效率。储存引擎只需要更改内存中的数据副本，而不需要每次修改磁盘中的表，这会非常快。然后再把更改的记录写入日志中，事务日志会被持久化保存在硬盘上。因为事务日志采用的是追加写操作，是在硬盘中一小块区域内的顺序I/O，而不是需要写多个地方的随机I/O，所以写入事务日志是一种相对较快操作。最后会有一个后台进程在某个时间去更新磁盘中的表。因此大多数使用这种技术（write-ahead logging，预写日志）的存储引擎修改数据最终需要写入磁盘两次。

![[Pasted image 20231018174344.png]]

# 多版本并发控制 (MVCC)
可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。
MVCC的工作原理是使用数据在某个时间点的快照来实现的。这意味着，无论事务运行多长时间，都可以看到数据的一致视图，也意味着不同的事务可以在同一时间看到同一张表中的不同数据！
![[Pasted image 20231018180625.png]]
MVCC仅试用于REPEATABLE READ和READ COMMITED隔离级别。READ UNCOMMITED与MVCC不兼容，是因为查询不会读取适合其事务版本的行版本，而不管怎么样都读最新版。SERIALIZABLE与MVCC也不兼容，是因为读取会锁定它们返回的每一行。

## RAID缓存
RAID缓存是物理安装在硬件RAID控制器上的少量内存。当数据在磁盘和主机系统之间传输时，RAID缓存可以用来缓冲数据。以下是RAID卡使用缓存的一些可能原因。
- 缓存读操作
- 缓存预读取数据
- 缓存写操作
- 内部操作
一般来说，RAID控制器的内存是一种稀缺资源，应该明智地使用它。将其用于读操作通常是一种浪费，将其用于写操作是提高I/O性能的一种重要方式。很多控制器允许你选择如何分配内存。例如，可以选择其中有多少用于缓存写操作，有多少用于读操作。

# 网络配置
DND解析中断或缓慢对于许多应用程序来说都是问题，对于Mysql来说尤其重要。

# InnoDB缓冲池
InnoDB缓冲池不仅缓存索引，还缓存行数据、自适应哈希索引、更改缓冲区、锁和其他内部结构等。InnoDB还使用缓冲池来实现延迟写操作，从而可以将多个写操作合并在一起并按顺序执行。
大型缓冲池也会带来一些挑战，比如更长的关闭时间和预热时间。

当脏页的百分比超过阈值时，InnoDB会尽可能地刷新页面，以尽量降低脏页的数量。与之前行为相比，这些页面清理操作已经得到了极大的优化，包括能够配置多个线程来执行刷新。

当Mysql再次启动时，缓冲池缓存是空的，也称为冷缓存。但是默认情况下，innodb_buffer_pool_dump_at_shutdown和innodb_buffer_pool_load_at_startup这两个配置可以配合使用，以在启动时预热缓冲池。

# 线程缓存
线程缓存保存了当前没有与连接关联但已准备好为新连接提供服务的线程。创建新连接时，如果缓存中有一个线程，Mysql会从缓存中取出该线程并将其提供给新连接。
变量thread_cache_size指定了Mysql可以保存在缓存中的线程数。其默认值为-1或auto-sized,通常不用更改这个变量，除非服务器会收到很多连接请求。

# 配置Mysql的I/O行为
![[Pasted image 20231026161935.png]]
为了正常使用，需要更改几个最重要的参数包括InnoDB日志文件大小、InnoDB如何刷新其日志缓存区，以及InnoDB如何执行I/O。

# InnoDB事务日志(redo log 、undo log)
InnoDB使用日志来降低提交事务的成本。它不会再每个事务提交时将缓冲池刷新到磁盘，而是将事务记录到日志中。事务对数据和索引所做的更改通常映射到表空间的随机位置，因此将这些更改刷新到磁盘将需要随机I/O。
使用日志，InnoDB可以将随机磁盘I/O转换为顺序I/O。
日志文件的中大小由innodb_log_file_size和innodb_log_files_in_group控制，这对写入性能非常重要。如果使用innodb_dedicated_server,日志文件的大小将根据系统内存量来自动管理。

## 日志缓冲区
InnoDB修改数据时会将修改记录写入日志缓冲区，并将其保存在内存中。当缓冲区满了、事务提交时，或者每秒1次(这三个条件以先满足为准),InnoDB会将缓冲区刷新到磁盘上的日志文件中。控制缓冲区大小的变量是innodb_log_buffer_size,通常不用设置的太大，建议1 ~ 8MB。
## InnoDB如何刷新日志缓冲区
可以通过更改innodb_flush_log_at_trx_commit来控制日志缓冲区的刷新位置和刷新频率。
可能设置如下。
0：
	每秒定时将日志缓冲区写入日志文件，并刷新日志文件，但在事务提交时不做任何操作。
1:
	每次事务提交时，将日志缓冲区写入日志文件，并将其刷新到持久存储中。这是默认的(也是最安全的) 设置；它保证你不会丢失任何已提交的事务，除非磁盘或操作系统 "假装" 进行刷新操作 (没有将数据真正写入磁盘)。
2: 
	每次提交时都将日志缓冲区写入日志文件，但不执行刷新。InnoDB按计划每秒刷新1次。与0设置最重要的区别是，如果只是Mysql进程奔溃，设置为2不会丢失任何事物。但是，如果整个服务器奔溃或断电，仍然可能丢失事务。

高性能事务需求的最佳配置将innodb_flush_log_at_trx_commit设置为1，并将日志文件放在具有备用电池的写缓存和SSD和RAID卷上，这既安全又非常快。

## InnoDB表空间
表空间不仅仅是存储表和索引，表空间还包含了Undo日志、修改缓冲区、双写缓冲区和其他内部结构。

# 配置Mysql并发
如果遇到InnoDB并发问题，并且运行的Mysql版本低于5.7，解决方案通常是升级服务器。
InnoDB有自己的 "线程调度器", 它控制线程如何进入内核访问数据，以及进入内核后可以做什么。限制并发性的最基本方法是使用innodb_thread_concurrency变量，该变量限制了内核中同时可以有多少线程。值为0表示对线程的数量没有限制。如果再老版本的Mysql中遇到InnoDB并发问题，这个变量是最重要的配置变量。
innodb_commit_concurrency变量控制着可以同时提交的线程数。如果再innodb_thread_concurrency设置为较低时仍存在大量线程抖动，配置此选项可能会有帮助。

# 安全设置
如果没有使用持久连接，但是应用程序没有正常断开连接，也会出现服务器连接被占满的情况。服务器将保持连接，知道达到TCP超时，或者在最坏的情况下，直到wait_timeout配置的秒数。

# 高级InnoDB设置
- innodb_autoinc_lock_mode
- innodb_buffer_pool_instances
- innodb_io_capacity
- innodb_read_io_thread 和 innodb_write_io_threads
- innodb_strict_mode
- innodb_old_blocks_time

# 小节
不要 "调优" 服务器，不要使用比率、公式或 "调优脚本" 作为设置配置变量的基础。
如果运行的是专用数据库服务器，那么可以设置的最佳选项是 Innodb_dedicated_server, 它可以处理90%的性能配置。如果无法使用此选项，那么最重要的两个选项是：
- innodb_buffer_pool_size
- innodb_log_file_size


# 选择优化的数据类型

## 整数类型
如果存储证书，可以使用这几种整数类型：TYNYINT、SMALLINT、MEDIUMINT、INT或BIGINT。它们分别使用8、16、24、32和64位存储空间。可以存储的值的范围从-2^(N-1) 到 2^(N-1) - 1。
Mysql可以为证书类型指定宽度，例如，INT(11)，这对大多数应用毫无意义：它不会限制值的合法范围，只是规定了Mysql的一些交互工具 (例如，Mysql命令行客户端) 用来显示字符的个数。对于存储和计算来说，INT(1) 和 INT(20) 是相同的。

## 实数类型
浮点类型通常比DECIMAL使用更少的空间来存储相同范围的值。FLOAT列使用4字节的存储空间。DOUBLE使用8字节。由于额外的空间需求和计算成本，应该尽量只对小数进行精确计算时才使用DECIMAL -- 例如，存储财务数据。但在一些大容量的场景，可以考虑使用BIGINT代替DECIMAL，将需要存储的货币单位根据小数的为数乘以相应的倍数即可。

## 字符串类型
VARCHAR用于存储可边长的字符串，是最常见的字符串数据类型。它比固定长度的类型更节省空间，因为它仅使用必要的空间(即，更少的空间用于存储更短的值)。
下面这些情况使用VARCHAR是合适的：字符串的最大长度远大于平均长度；列的更新很少，所以碎片不是问题；使用了像UTF-8这样复杂的字符集，每个字符都使用不同的字节数进行存储。
InnoDB更为复杂，它可以将过长的VARCHAR值存储为BLOB。

CHAR是固定长度的：Mysql总是为定义的字符串长度分配足够的空间。当存储CHAR值时，Mysql删除所有尾随空格。如果需要进行比较，值会用空格填充。假如设计为只保存Y和N的值的CHAR(1) 在单字节字符集中只使用1字节，但VARCHAR(1) 需要2字节，因为还有一个记录长度的额外字节。
```ad-note
**慷慨是不明智的**
使用VARCHAR(5) 和 VARCHAR(200) 存储‘hello’的空间开销是一样的。那么使用更短的列有什么优势吗？
事实证明有很大的优势。较大的列会使用更多的内存，因为mysql通常会在内部分配固定大小的内存块来保存值。这对于使用内存临时表的排序或操作来说尤其糟糕。在利用磁盘临时表进行文件排序时也同样糟糕。
最好的策略是只分配真正需要的空间。
```
虽然ENUM类型在存储值的方式上非常有效，但更改ENUM中的有效值会导致需要做schema变更。
## 日期和时间类型
**DATETIME**
这种类型可以保存大范围数值，从1000年到9999年，精度为1微妙。它以YYYYMMDDHHMMSS格式存储压缩成证书的日期和时间，且与时区无关。这需要8字节的存储空间
**TIMESTAMP**
TIMESTAMP类型存储自1970年1月1日格林尼治时间标准时间(GMT) 午夜以来经过的秒数 -- 与UNIX时间戳相同。只使用4字节的存储空间，所以它的范围比DATETIME小得多：只能表示从1970年到2038年1月19日。Mysql提供 `FROM_UNIXTIME()`函数来将UNIX时间戳转换为日期，并提供了 `UNIX_TIMESTAMP()` 函数将日期转换为UNIX时间戳。
时间戳显示的值依赖于时区。Mysql服务器、操作系统和客户端连接都有时区设置。
区别：
1.如果存储或访问多个时区的数据，TIMESTAMP和DATETIME的行为将很不一样。前者保留与所使用时区相关的值，而后者保留日期和时间的文本表示。
2.默认情况下，当插入一行没有指定第一个TIMESTAMP列的值，Mysql将该列的值设置为当前时间，更新时也一样。最后，TIMESTAMP列在默认情况下为NOT NULL，这也和其他的数据类型不一样。(跟版本有关，需要通过 SHOW CREATE TABLE查看该字段的实际情况)

## 位压缩数据类型
整数列上的位操作
SET的另一种替代方法是使用整数作为二进制位的打包集合。例如，可以在TINYINT中打包8位，并使用逐位操作符对它们进行操作。可以在应用程序代码中为每个位定义命名常量来简化这一过程。

## JSON数据类型
```sql
SELECT json_data->'$.designation' FROM asteroids_json
```
中的来说，决定使用原生SQL还是JSON取决于在书库中存储JSON的便捷性是否大于性能。如果每天访问这些数据数百万次或数十亿此，速度差异就会累加起来。

# 多列索引
Mysql引入了一种叫 "索引合并" (index merge) 的策略，它在一定程度上可以使用表中的多个单列索引来定位指定的行。这种算法有三个变种：OR条件的联合 (union), AND条件的相交 (intersection), 组合前两种情况的联合及相交。
索引合并策略有时候效果不错，但更多时候，它说明了表中的索引建得很糟糕：
- 当优化器需要对多个索引做相交操作时 (通常有多个AND条件)，通常意味着需要一个包含所有相关列的多列索引，而不是多个单独的单列索引。
- 当优化器需要对多个索引做联合操作时 (通常有多个OR条件), 通常需要在算法的缓存、排序和合并操作上耗费大量CPU和内存资源，尤其是当其中有些索引的选择性不高，需要合并扫描返回的大量数据的时候。
- 更重要的是，优化器不会把这些操作计算到 "查询成本" (cost) 中，优化器只关心随机页面读取。这会使得查询的成本被 "低估", 导致该执行计划还不如直接进行全表扫描。这样做不但会消耗更多的CPU和内存资源，还可能会影响并发的查询，但如果单独运行这样的查询则往往会忽略对并发性的影响。通常来说，使用UNION改写查询，往往是最好的办法。
**如果EXPLAIN中看到有索引合并，那么就应该好好检查一下查询语句的写法和表的结构，看是不是已经是最优的。也可以通过参数 optimizer_switch来关闭索引合并功能，还可以使用IGNORE INDEX语法让优化器强制忽略掉某些索引， 从而避免优化器使用包含索引合并的执行计划。**

## 选择合适的索引列顺序
将选择性最高的列放到索引最前列。这个建议准确吗？在很多场景中可能有帮助，但是要全面地考虑各种场景的话，考虑避免大量随机I/O和排序可能更重要。
尽管关于选择性和基数的经验法则值得去研究和分析，但一定别忘了查询子句中的排序、分组和范围条件等其他因素，这些因素可能会对查询的性能造成非常大的影响。

## 聚簇索引
聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。具体的细节依赖于其实现方式，但InnoDB的聚簇索引实际上在同一个结构中保存了B-tree索引和数据行。
一个表只能有一个聚簇索引，因为无法同时把数据行存放在两个不同的地方。
在InnoDB中，如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。这样做的缺点在于，所有需要使用这种隐藏主键的表都依赖一个单点的 "自增值", 这可能会导致非常高的锁竞争，从而出现性能问题。
聚簇索引的有点：
- 可以把相关联的数据保存在一起，减少随机I/O次数
- 数据访问更快。聚簇索引将索引和数据保存在同一个B-tree中，因此从聚簇索引中获取数据通常比在非聚簇索引中查找要快。
- 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。
聚簇索引的缺点：
- 插入速度严重依赖于插入顺序。按照主键的顺序插入行是将数据加载到InnoDB中最快的方式。但如果不是按照主键的顺序加载数据，那么在加载完成后最好使用 OPTIMIZE TABLE 命令重新组织一下表。
- 更新聚簇索引列的代价很高，因为它会强制InnoDB将每个被更新的行移动到新的位置。
- 基于聚簇索引的表在插入新行，或者主键被更新导致需要移动行的时候，可能面临也分裂(page split) 的问题。当行的主键值要求必须将这行插入某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间。
- 二级索引 (非聚簇索引) 可能比想象中的要更大，因为二级索引的叶子节点包含了引用行的主键列。
- 二级索引访问需要两次索引查找，而不是一次。
![[Pasted image 20231031101759.png]]
![[Pasted image 20231031101818.png]]

向聚簇索引中插入无序的记录(主键采用UUID这种随机的形式)
![[Pasted image 20231031103714.png]]
缺点:
- 写入目标页可能已经刷到磁盘上并从缓存中移除，或者还没有被加载到缓存中，InnoDB在插入之前不得不先找到，并从磁盘将目标页读取到内存中。这将导致大量的随机I/O.
- 因为写入是乱序的，所以InnoDB不得不频繁地做页分裂操作，以便为新记录分配空间。页分裂会导致移动大量数据，一次插入最少需要修改三个页而不是一个。
- 由于频繁的页分裂，页会变得稀疏并被不规则地填充，所以最终数据会有碎片。
```ad-tip
**什么时候按主键顺序插入反而会更糟**
对于高并发的工作负载，在InnoDB中按主键顺序插入可能会造成明显的写入竞争。主键的上界会成为 "热点"。因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。另一个热点可能是AUTO_INCREMENT锁机制；如果遇到这个问题，则可能需要考虑重新设计表或者应用，或者更改innodb_autoinc_lock_mode配置。若果你的服务器版本还不支持这个蚕食，可以升级到新版本的InnoDB，该版本对这种场景会适应得更好。
```

如果查询需要连接多张表，则只有当ORDER BY子句引用的字段全部在第一个表中时，才能使用索引做排序。ORDER BY子句也需要满足索引的最左前缀的要求。
有一种特殊情况，如果前导列为常量的时候，ORDER BY 子句的列也可以不满足索引的最左前缀要求。如果在WHERE子句或者JOIN ON子句中将这些列指定为了常量，就可以 "填补" 索引字段的间隙了。

```sql
EXPLAIN SELECT rental_id, staff_id FROM sakila.rental
WHERE rental_date = '2005-05-25'
ORDER BY inventory_id, customer_id;
```
下面是一些不能使用索引做排序的查询：
- 下面这个查询使用了两种不同的排序方向，但是索引中的列都是按正序排列的:
```sql
... WHERE retal_date = '2005-05-25' ORDER BY invetory_id DESC, customer_id ASC;
```
- 在西面这个查询的ORDER BY子句中，引用了一个不再索引中的列：
```sql
... WHERE rental_date = '2005-05-25' ORDER BY inventory_id, staff_id;
```
- 下面这个查询的WHERE和ORDER BY中的列无法组合成索引的最左前缀：
```sql
... WHERE rental_date = '2005-05-25' ORDER BY customer_id;
```
- 下面这个查询在索引列的第一列上是范围条件，所以Mysql无法使用索引的其余列：
```sql
... WHERE rental_date > '2005-05-25' ORDER BY inventory_id, customer_id;
```
- 下面例子也是范围查询
```sql
... WHERE reatal_date = '2005-05-25' AND inventory_id IN (1, 2) ORDER BY customer_id;
```
通过下面的语句可以找到数据库中从来没有被使用的索引：
```sql
select * from sys.schema_unused_indexes;
```

## 维护索引和表
维护表有三个主要目的：找到并修复损坏的表，维护准确的索引统计丝逆袭，减少碎片。
## 找到并修复损坏的表
可以尝试运行CHECK TABLE 来检查是否发生了表损坏(不是所有引擎都支持该命令)。
可以使用REPAIR TABLE命令来修复损坏的表，但同样不是所有的存储引擎都支持该命令。如果不支持，可通过一个不做任何操作(no-op) 的ALTER操作来重建表。下面是一个针对InnoDB表的例子：
```sql
ALTER TABLE <table> ENGINE=INNODB;
```
此外，还可以将数据导出再导入一次。不过，如果损坏的是系统区域，或者是表的 "行数据" 区域，而不是索引，那么上面的办法就没有用了。这种情况下，可以从备份中恢复表，或者尝试从损坏的数据文件中尽可能地恢复数据。
如果遇到数据损坏，最重要的是找出是什么导致了损坏，而不只是简单地修复。可以通过Innodb_force_recovery参数进入InnoDB的强制恢复模式来修复数据。

## 更新索引统计信息
Mysql的优化器使用的是基于成本模型，而衡量成本的主要指标就是一个查询需要扫描多少行。如果表没有统计信息，或者统计信息不准确，优化器就很有可能做出错误的决定。可以通过运行 `ANALYZE TABLE` 来重新生成统计信息，以解决这个问题。
可以使用 `SHOW INDEX FROM <table>` 命令来查看索引的基数(cardinality)。
InnoDB在打开某些INFORMATION_SHCEMA表，或者使用SHIOW TABLE STATUS和SHOW INDEX，或者在Mysql客户端开启自动补全功能的时候，会触发索引统计信息的更新(这是非常耗资源，并且有可能阻塞用户的操作)。

## 减少索引和数据的碎片
B-tree索引可能会产生碎片化，这会降低查询的效率。碎片化的索引可能会以很差或者无序的方式存储在磁盘上。
数据存储的碎片化比索引更新复杂。有三种类型的数据碎片。
- 行碎片（Row fragmentation)
- 行间碎片 （Intra-row fragmentation)
- 剩余空间碎片 （Free space fragmentation）
可以通过OPTIMIZE TABLE或者导出再导入的方式来重新整理数据。对于不支持该操作的存储引擎，可以通过 `ALTER TABLE <table> ENGINE=<egine>` (将表的存储引擎修改为当前的引擎)操作来重建表。

## 小结
在选择索引和编写利用这些索引的查询时，有如下三个原则始终需要记住：
- 单行访问是很慢的，特别是在机械硬盘中存储 (SSD随机I/O要快很多，不过这一点仍然成立)。如果服务器从存储中读取一个数据块只是为了其中一行，那么就是浪费了很多工作。最好读取的块中能包含尽可能多的所需要的行。
- 按顺序访问范围数据是很快的，有两个原因。第一，顺序I/O不需要多次磁盘寻道，所以比随机I/O要快很多 (特别是对于机械硬盘)。第二，如果服务器能够按需顺序读取数据，那么就不再需要额外的排序操作，并且GROUP BY查询也无须再做排序和将行按组进行聚合计算了。
- 索引覆盖查询是很快的。如果一个索引包含了查询需要的所有列，那么存储引擎就不需要再回表查找行。这避免了大量的单行访问，而上面的第一点已经写明单行访问是很慢的。


# SQL查询语句优化
查询的生命周期大致可以按照如下顺序来看：从客户端到服务器，然后再服务器上进行语法解析，生成执行计划，执行，并给客户端返回结果。其中，“执行” 可以被认为是整个生命周期中最重要的阶段，这其中包括大量为了检索数据对存储引擎的调用以及调用后的数据处理，包括排序、分组等。
EXPAIN语句中的type列反映了访问类型。访问类型有很多种，从全表扫描到索引扫描、范围扫描、唯一索引查询、常数引用等。
一般地，Mysql能够使用如下三种方式引用WHERE条件，从好到坏依次为：
- 在索引中使用WHERE条件来过滤不匹配的记录。这是在存储引擎层完成的。
- 使用索引覆盖扫描 (在Extra列中出现了Using index) 来返回记录，直接从索引中过滤不需要的记录并返回命中的结果。这是在Mysql服务器层完成的，但无须再回表查询记录。
- 从数据表中返回数据，然后过滤不满足条件的记录 (在Extra列中出现Using where)。这在Mysql服务器层完成，Mysql需要先从数据表中读出记录然后顾虑。
如果发现查询需要扫描大量的数据但只返回少数行，那么通常可以尝试下面的技巧去优化它：
- 使用索引覆盖扫描，把所有需要用的列都放到索引中，这样存储引擎无须回表获取对应行就可以返回结果了。
- 改变库表结构。例如，使用单独的汇总表。
- 重写这个复杂的查询，让Mysql优化器能够以更优化的方式执行这个查询。

## 重构查询的方式

### 一个复杂查询还是多个简单查询
### 切分查询
删除旧数据是一个很好的例子。
例如，我们需要每个月运行一次下面的delete：
```sql
DELETE FROM messages
WHERE created < DATE_SUB(NOW(), INTERVAL 3 MONTH);
```
那么可以用类似下面的的办法来完成同样的工作：
```rust
rows_affected = 0
do {
	rows_affected = do_query(
	"DELETE FROM messages WHERE created < DATE_SUB(NOW(), INTERVAL 3 MONTH)"
	)
} while rows_affected > 0
```
## 分解联结查询
例子：
```sql
SELECT * FROM tag
JOIN tag_post ON tag_post.tag_id=tag.id
JOIN post ON tag_post.post_id=post.id
WHERE tag.tag='mysql';
```
分解后：
```sql
SELECT * FROM tag WHERE tag = 'mysql';
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id in (123, 456, 567, 9098, 8904)
```
事实上，用分解联结查询的方式重构查询有如下优势
- 让缓存的效率更高。许多应用程序可以方便地缓存单表查询对应的结果对象。例如，上面查询中的tag mysql已经被缓存了，那么应用就可以跳过第一个查询。
- 将查询分解后，执行单个查询可以减少锁的竞争。
- 在引用层做联结，可以更容易对数据库进行拆分，更容易做到高性能和可扩展。
- 查询本身的效率也可能会有所提升。在这个例子中，使用IN()代替联结查询，可以让Mysql按照ID顺序进行查询，这可能比随机的联结要更高效。
- 可以减少对冗余记录的访问。在应用层做联结查询，意味着对于某条记录应用只需要查询一次，而在数据库中做联结查询，则可能需要重复地访问一部分数据。从这点看，这样的重构还可能会减少网络和内存的消耗。

## 查询状态
使用 `SHOW FULL PROESSLIST` 命令，该命令的Command列，就表示当前状态。
Sleep
	线程正在等待客户端发送新的请求。
Query
	线程正在执行查询或者正在将结果发送给客户端
Locked
	在Mysql服务器层，该线程正在等待表锁。在存储引擎级别实现的锁，例如InnoDB的行锁，并不会提现在线程状态中。
Analyzing and statistics
	线程正在检查存储引擎的统计信息，并优化查询。
Copying to tmp table [on disk]
	线程正在执行查询，并且将其结果复制到一个临时表中，这种状态一般要么是在做GROUP BY操作，要么是在进行文件排序操作，或者是在进行UNION操作。如果这个状态后面还有 "on disk"标记，那表示Mysql正在将一个内存临时表放到磁盘上。
Sorting result
	线程正在对结果集进行排序。

有很多找那个原因会导致Mysql优化器选择错误的执行计划，如下所示：
- 统计信息不准确。
- 成本指标并不完全等同于运行查询的实际成本，因此即使统计数据是准确的，查询的成本也可能超过或者低于Mysql估算的近似值。Mysql并不知道哪些页面在内存中、哪些在磁盘中，所以查询实际执行过程中到底需要多少次物理I/O是无法得知的。
- Mysql的最优可能和你想的最优不一样。所以，这里我们看到的根据执行成本来执行计划并不是完美的模型。
- Mysql从不考虑其他并发执行的查询，这可能会影响到当前查询的速度。
- Mysql也并不是任何时候都是基于成本的优化。它有时也会基于一些固定的规则，例如，全文索引。
- Mysql不会考虑不受其控制的操作的成本，例如，执行存储函数或者用户自定义函数的成本。
- 后面我们还会看到，优化器有时候无法估算所有可能的执行计划，所以它可能错误实际上最优的执行计划。
**Mysql 能够处理的优化类型:**
- 重新定义联结表的顺序。
- 将外连接转化成内联结。
- 使用代数等价变化规则。（Mysql可以使用一些代数等价变换规则来简化并规范表达式。他可以合并和减少一些比较，还可以移除一些恒成立和一些恒不成立的判断）
- 优化COUNT()、MIN()、MAX()
- 预估并转化为常数表达式
联结优化器会尝试在所有的联结顺序中选择一个成本最低的来生成执行计划树。如果可能，优化器会遍历每一个表，然后逐个做嵌套循环，计算执行每一颗可能的计划树的成本，最后返回一个最优的执行计划。

## Mysql查询优化器的局限性
Mysql所实现的查询执行方式并不是对每种查询都是最优的。不过还好，Mysql查询优化器只对少部分查询不适用，而且我们往往可以通过改写查询让Mysql高效地完成工作。

UNION的限制
有时，Mysql无法将限制条件从UNION的外层 "下推"到内层，这使得原本能够限制部分返回结果的条件无法应用到内层查询的优化上。
可以通过在UNION各自的子查询中加上限制条件，来减少临时表中的数据：
```sql
(SELECT first_name, last_name FROM sakila.actor ORDER BY last_name LIMIT 20)
UNION ALL
(SELECT first_name, last_name FROM sakila.customer ORDER BY last_name LIMIT 20)
ORDER BY last_name
LIMIT 20;
```
## 等值传递
某些时候，等值传递会带来一些意想不到的额外消耗。例如，考虑一列上的巨大IN()列表，优化器知道它将等于其他表中的一些列，这是由于WHERE、ON或USING子句使列彼此相等。如果这个列表非常大，则会导致优化和执行都会编码。目前还没有什么办法能绕过该问题。
## 并行执行
Mysql无法利用多核特性来并行执行查询，很多其他的关系数据库能够提供这个特性，但是Mysql做不到。

## 在同一个表中查询和更新
Mysql是不允许对同一张表进行查询和更新。不过可以使用生成表的形式绕过此限制。
```sql
UPDTATE tbl AS outer_tbl
SET c = (
SELECT count(*) FROM tbl AS inner_tbl
WHERE inner_tbl.type = outer_tbl.type
);
该语句会报错：ERORR 1093 (HY000)
```
```sql
UPTATE tbl
INNER JOIN (
SELECT type, count(*) AS c
FROM tbl
GROUP BY type
) AS der USING(type)
SET tbl.c = der.c;
在这里，子查询会在UPDATE语句打开表之前就完成，所以上面的查询将会正常执行。
```
# 优化特定类型的查询
以下这些优化技巧和特定版本有关，所以对于未来Mysql的版本未必使用。
## 优化COUNT() 查询
###  简单优化
通常会看到这样的问题：如何在一个查询中统计同一列的不同值的数量，以减少语句量。
可以使用以下方式简化：
```sql
SELECT COUNT(category_id = 6 OR NULL) as six, COUNT(category_id = 11 OR NULL) as eleven
FROM sakila.film_category;
-- count(null)是不会增加count数量的。

SELECT SUM(IF(category_id = 6, 1, 0)) six, SUM(IF(category_id = 11, 1, 0)) eleven
FROM sakila.film_category;
```
### 使用近似值
EXPLAIN出来的优化器估算的行数就是一个不错的近似值。
去掉一些约束条件对总数影响很小，但却可能提升查询的性能，更进一步的优化则可以尝试删除DISTINCT这样的约束来避免文件排序。这样重写过的查询比原来精确统计的查询快很多，而返回的结果则几乎相同。
### 更复杂的优化
Count()查询需要扫描大量的行，因此很难优化的。在Mysql层面能做的只有索引覆盖扫描了。如果这还不够，可以引入外部缓存系统。不过，"快速、精确和实现简单"。三者永远只能满足其二，必须舍掉一个。

## 优化联结查询
- 确保ON或者USING子句中的列上有索引。没有用到的索引只会带来额外的负担。一般来说，除非有其他理由，否则只需要在联接顺序中的第二个表的相应列上创建索引。
- 确保任何Group By和Order By中的表达式只涉及一个表中的列，这样Mysql才有可能使用索引来优化这个过程。
- 当升级Mysql的时候需要注意：联接语法、运算符优先级等其他可能会发生变化的地方。因为以前是普通联接的地方可能会变成笛卡尔积，不同类型的联接可能会生成不同的结果，甚至会产生语法错误。
## 使用WITH ROLLUP优化GROUP BY
可以通过EXPLAIN来观察其执行计划，特别要注意分组是否通过文件排序或者临时表实现。然后去掉WITH ROLLUP子句来看执行计划是否相同。也可以使用优化器提示来强制执行计划 (hint)。
最好的办法是尽可能地将WITH ROLLUP功能转移到应用程序中处理。
## 优化LIMIT和OFFESET子句
一个非常常见又令人头疼的问题是，在偏移量非常大的时候，例如，可能是LIMIT 1000, 20 这样的查询。要优化这种查询，要么是在页面中限制分页的数量，要么是优化大偏移量的性能。
优化此类分页查询的一个简单的办法就是尽可能地使用索引覆盖扫描，而不是查询所有的行。然后根据需要做一次联接操作再返回所需的列。在偏移量很大的时候，这样做的效率会非常大的提升。
考虑下面的查询：
```sql
SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50, 5;
```
可以改写为：
```sql
SELECT film.film_id, film.description
FROM sakila.film
INNER JOIN (
SELECT film_id FROM sakila.film
ORDER BY title LIMIT 50, 5
) AS lim USING(film_id);
```
有时候也可以将LIMIT查询转换为一直位置的查询，让Mysql通过范围扫描获得对应的结果。例如，若果在一个位置列上有索引，并且预先计算出了边界值，上面的查询可以改写为：
```sql
SELECT film_id, description FROM sakila.film
WHERE position BETWEEN 50 AND 54 ORDER BY position;
```
如果主键是单调递增，可以避免使用OFFSET，因为LIMIT和OFFSET的问题，其实是OFFSET的问题。
```sql
SELECT * FROM sakila.rental
ORDER BY rental_id DESC LIMIT 20;
-- 前面一条sql查出来最大的id值，作为下次查询的过滤条件，也可以实现分页
SELECT * FROM sakila.rental
WHERE rental_id < 16030
ORDER BY rental_id DESC LIMIT 20;
```
这种优化的好处是无论翻页到多么靠后，其性能都会很好。
其他优化办法还包括使用预先计算的汇总表，或者联接到一个冗余表，冗余表只包含主键列和需要做排序的数据列。
## 优化SQL CALC FOUND ROWS
SQL_CALC_FOUND_ROWS提示(hint)已经在高版本的Mysql中被标记为已废弃。一个更好的设计是将具体的页数换成 "下一页"按钮，如果不存在下一页，那就不显示 "下一页"按钮。
另一种做法是先获取并缓存较多的数据，如果数据量大于缓存中的数据量，可以设计一个额外的 "找到更多"之类的按钮。这两种策略都比每次生成全部结果集再抛弃不需要的数据的效率高得多。
有时候可以采用近似值的方式，当需要精确结果的时候，再单独使用COUNT(`*`)来满足需求，这时如果能够使用索引覆盖扫描则通常也会比SQL_CALC_FOUND_ROWS快得多。
## 优化UNION查询
- 手工地将WHERE、LIMIT、ORDER BY等子句 "下推" 到UNION各个子查询中，以便优化器可以充分利用这些条件进行优化。
- 除非你确定需要服务器消除重复的行，否则一定要使用UNION ALL，如果没有ALL关键字，Mysql会给临时表加上DISTINCT选项，这会导致整个临时表的数据做唯一性检查。这样做的代价很高。

# 复制
## 复制概述
下面是复制比较常见的用途。
- 数据分发
- 读流量扩展
- 备份
- 分析与报告
- 高可用性和故障切换
- Mysql升级测试
## 复制如何工作
总的来说，复制有三个步骤：
1. 源端把数据更改记录到二进制日志中，称之为 "二进制日志事件" (binary log events --- binlog)。
2. 副本将源上的日志复制到自己的中继日志找那个。
3. 副本读取中继日志中的时间，将其重放到副本数据之上。
![[Pasted image 20231102160813.png]]
## 选择复制的格式
Mysql提供了三种不同的二进制日志格式用于复制：基于语句的、基于行的和混合模式。可以通过系统参数binlog_format控制日志写入时使用哪种日志格式。
- 基于语句的复制是通过记录所有在源端执行的数据变更语句来实现的。基于语句的复制的有点是简单且紧凑。一条更新大量数据的SQL语句，在二进制日志中可能仅仅需要几十字节存储。其最大的弊端在于会遇到某些具有 "不确定性" 的SQL语句问题。
- 基于行的复制将事件写入二进制日志。基于行的复制，通过查看二进制日志中的事件，可以看到究竟是哪一行记录发生了什么样的变化，是确定的。但是这种模式的弊端是可能会导致二进制日志的大小发生巨大的增长。
- "混合模式"下，事件的写入，默认使用基于语句的格式，仅在需要时才切换到基于行的格式。但是在写入每个事件时会有很多的判断条件，以确定使用哪种格式，而这也会导致二进制日志出现不可预测的事件。
建议坚持使用基于行的复制，除非某些场景下明确需要临时使用基于语句的复制。基于行的复制提供了更安全的数据复制方法。
## 全局事务标识符 (GTID)
使用GTID，源服务器提交的每个事务都被分配一个唯一标识符。此标识符是由server_uuid和一个递增的事务编号组成的。当事务被写进二进制日志时，GTID也随之被写入。
GTID解决了运行Mysql复制的一个令人痛苦的问题：处理日志文件和位置。强烈建议始终按照Mysql官方文档中的说明，在数据库中启动GTID。
## 奔溃后的复制安全
为了尽量降低复制中断的可能性，建议Mysql的部分参数按照如下讲解内容进行配置：
- innodb_flush_log_at_trx_commit=1
	严格来说这并不是一个复制相关的配置。不过，这个参数可以保障每个事务日志都被同步地写到磁盘。这是一个符合ACIC要求的配置，将最大限度地保护你的数据 -- 即使是在复制中也是这样。这是因为二进制日志事件首先被提交，然后事务将被提交并写入磁盘。将此参数设置为1将增加磁盘写入操作的频次，同时确保数据的持久性。
- sync_binlog=1
	该变量控制Mysql将二进制日志数据同步到磁盘的频率。将此值设置为1意味着在每次事务执行的时候都会把二进制日志同步写入磁盘。这可以防止在服务器奔溃时丢失事务。就像之前的参数一样，它也会增加磁盘写入量。
- relay_log_info_repository=TABLE
	以前，Mysql的复制通常依赖磁盘上的文件来跟踪复制位置。这意味着，复制完成事务操作之后，还需要完成同步写入磁盘操作。如果在事务提交和同步之间发生了服务器奔溃，此时，磁盘上的文件将可能包含错误的文件和位置信息。在该配置下，该信息将被转移到Mysql本身的InnoDB表中，允许复制更新同一事务中的事务和中继日志信息。这会在一个原子操作中完成，并有助于奔溃恢复。
-  relay_log_recovery=ON
	简单地说，该参数使得副本服务器在检测到奔溃时会丢弃所有本地中级日志，并从源服务器中获取丢失的数据。配置该参数后，不再需要配置sync_relay_log,因为在发生奔溃时，中级日志将删除，也就无须话费额外的操作将它们同步到磁盘。
## 延迟复制
延迟复制可以让副本中的数据保持在线并且持续运行，但同时落后于源数据库数小时或者数天。延迟复制的配置语句是CHANGE REPLICATION SOURCE TO，配置选项为SOURCE_DELAY。
但是延迟复制会给其他操作带来复杂性。选择新的源服务器的时候，通常要排除延迟副本，如何监控延迟复制，以及如何处理这个特殊的副本等。
## 多线程复制
最新的Mysql版本提供了多线程复制能力，可以在副本端运行多个SQL线程，从而加快本地中继日志的应用。
![[Pasted image 20231102183938.png]]
多线程复制有两种模式：DATABASE和LOGICAL_CLOCK。在DATABASE模式下，可以使用多线程更新不同的数据库；但不会有两个线程同时更新同一个数据库。而LOGICAL_CLOCK允许对同一个数据库进行并行更新，只要它们都是同一个二进制日志组提交的一部分。
在大多数情况下，可以简单地通过replica_parallel_workers设置为非零值来开启该配置，并立即看到效果。如果再单个数据库上操作，还需要将replica_parallel_type更改为LOGICAL_CLOCK。此外，确保你的副本配置了参数replica_preserve_commit_order,这样就不会出现无序提交的问题。请参阅官方文档中Gaps小节。
## 半同步复制
在启用半同步复制后，源在完成每个事务提交时，都需要确保事务至少被一个副本接收。需要确认副本已收到并成功将其写入自己的中继日志(但不一定应用到本地数据),不要依赖该功能来保证数据完整性。
## 复制过滤器
通常不建议使用该功能。
## 复制拓扑
几乎任何一个源和副本可以配置Mysql复制。

## 主动/被动模式
在这种模式中，应用将所有读取和写入都指向单个源服务器。
![[Pasted image 20231103181134.png]]
- 配置：在这个拓扑架构下，应该尽量让源和副本CPU、内存等方面具有相同的配置，当需要的时候可以进行切换。
- 冗余：在屋里硬件环境中，推荐使用至少3台服务器的n+2冗余。
- 注意事项：如果读达到扩展上线，则必须演进到更复杂的拓扑 (比如主动/只读配置)，否则就不得不利用分片来减少源上的读取压力。
## 主动/只读池模式
在这种模式中，我们将所有写入指向源服务器。根据应用程序的需要，读取则可以被发送到源服务器或只读池。
![[Pasted image 20231103181547.png]]
- 配置：在理想情况下，至少要有一个副本 (最好是两个) 与原服务器具有相同的配置。同样的当需要故障切换到其中一个副本时，该副本应该有足够的容量支撑业务的流量。
- 冗余：在只读池中的服务器数量应该满足先前提出的要求，还需要至少一台服务器可以充当故障切换的目标。此外，还需要有足够的节点来支撑读流量，以及用于节点故障的小缓冲区。
- 注意事项：在读取的时候，应用程序对延迟读取有一定的容忍度，因为你永远无法保证在源服务器上完成的写入已经被复制到副本上。可能需要一种方法来识别那些复制延迟太大的节点，并根据需要将其踢出只读池。只读池的大小会决定管理的复杂度，以及何时应该考虑自动化。

最好的解决方案是心跳记录，它需要在源上每秒更新一次时间戳。需要计算延迟时，就可以简单地在副本上用当前时间戳减去记录的心跳时间。

## 备份恢复
建议混合使用裸文件备份和逻辑备份两种方式：先使用裸文件备份，用得到的数据启动Mysql服务器实例并运行Mysqlcheck。然后，周期性地使用mysqldump执行逻辑备份。
## 文件系统快照
文件系统快照是一种非常好的在线备份方法。支持快照的文件系统能够瞬间创建用来备份的内容一致的镜像。支持快照文件系统合设备包括FreeBSD的文件系统、ZFS文件系统、GNU/Linux的逻辑卷管理(LVM), 以及许多的SAN系统和文件存储解决方案。
不要把快照和备份相混淆。创建快照是减少必须持有锁的时间的一个简单方法；释放锁后，必须将文件复制到备份中。

```ad-note
**快照误区**
快照，无论是LVM、ZFS还是SAN快照，都不是真正的备份，因为它们不包含数据的完整副本。因为快照是写时复制，所以它们只包含数据的实时副本与快照发生时的数据之间的差异。如果未修改的块在数据的实时副本中损坏，则没有可用于恢复的该块的完整副本，这时，每个快照都会看到与实时卷相同的损坏块。在进行备份时，可以使用快照“冻结”数据，但不要将快照本身当做备份来依赖。
```
可以在升级前创建一个快照，这样如果升级有问题，只需要回滚到该快照即可。

## LVM快照的工作原理
LVM使用写时复制 (copy-on-write) 的技术来创建快照 -- 例如，对整个卷的某个瞬间的逻辑副本。这与数据库中的MVCC有点像，不同的是，LVM只保留一个老的数据版本。
当原始卷中的某些数据有变化时，LVM在任何变更写入之前，都会将受影响的块复制到快照预留的区域中。对于每个块，只有第一次对每个块的写入才会导致将写时复制写入预留的区域。(这里，我觉得翻译的有点问题，应该是修改时会将原来老版本的数据复制到预留区域中，这样才能快照)

## 从备份找那个恢复数据
如何恢复数据取决于数据是怎么备份的。可能需要一下部分或全部步骤。
1. 停止Mysql服务器。
2. 记录服务器的配置和文件权限。
3. 将数据从备份中移到Mysql数据目录。
4. 改变配置。
5. 改变文件权限。
6. 以限制访问模式重启服务器，等待其完成启动。
7. 载入逻辑备份文件。
8. 检查和重放二进制日志。
9. 检测已经还原的数据。
10. 以完全权限重启服务器。

## 使用`Percona XtraBackup`进行恢复
在本章前面"XtraBackup的工作原理“一节中，我们提到XtraBackup使用InnoDB的奔溃恢复过程来进行安全备份。这意味着在使用XtraBackup备份的文件之前，还需要执行额外的步骤。