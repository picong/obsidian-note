队列模式和发布-订阅模式最大的区别**其实就是，一份数据能不能被消费多次的问题。**
如果发布订阅模式只有一个订阅者，那它和队列模型就基本是一样的了。也就是，发布-订阅模型在功能层面上是可以兼容队列模型的。
## 队列的适用场景
1. 异步处理
2. 流量控制
**我们的设计思路是，使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。**
![[Pasted image 20241231171458.png]]
这种设计的优点是：能根据下游的处理能力自动调节流量，达到"削峰填谷"的作用。
另外一种更简单的思路是，用消息队列实现一个令牌桶。
![[Pasted image 20241231171704.png]]
3. 服务解耦


## 如何利用事务消息实现分布式事务？
消息队列中的"事务"，主要解决的是消息生产者和消息消费者的数据一致性问题。
Kafka和RocketMq都对事物有所支持，Rocket支持事务反查机制，这种机制通过定期反查事务状态，来补偿提交事务消息可能出现的通信失败。再Kafka的事务功能中，并没有类似的反查机制，需要用户自行去解决这个问题。
![[Pasted image 20241227183530.png]]
## 消息重复的解决方案
**消息重复的情况必然存在**，再MQTT协议中，给出了三种传递消息时能够提供的服务质量标准：
- **At most once**：至多一次，没什么消息可靠性保证，允许丢消息。
- **At least once**：至少一次，不允许丢消息，但是允许有少量重复消息出现。
- **Exactly once**：恰好一次，不允许丢失也不允许重复。
消息队列无法保证消息不重复，因为消息生产端可能会因为没有收到broker端的发送确认而重发消息，broker端通过将消息本地存储之后再发送ack通知生产者已经保存消息来保证消息不丢，而broker如果收不到消费者的消费确认，会重发消息给消费者来确保消息不丢，所以这里也有可能会产生重复消息，所以消息重复是不可避免的。
### 用幂等性解决重复消息问题
幂等操作的特点是，**其任意多次执行所产生的影响均与一次执行的影响相同。**
从对系统的影响结果来说：**At least once + 幂等消费 = Exactly once。**
### 常用的设计幂等操作的方法：
1. 利用数据库的唯一约束实现幂等，或者其他的类似“Insert If Not Exist”语义的的存储系统都可以用于实现幂等，比如，可以用Redis的SETNX命令来替代数据库中的唯一约束，来实现幂等消费。
2. 为更新的数据设置前置条件，比如数据中的通过版本号来实现的乐观锁。
3. 记录并检查操作
如果上面提到的两种幂等方法都不能适用于我们的场景，我们还有一种通用性最强，适用范围最广的实现幂等性的方法：记录并检查操作，也称为"Token 机制或者GUID(全局唯一 ID)机制"，实现的思路特别简单：再执行数据更新操作之前，先检查一下是否执行过这个更新操作。
具体的实现方法是，在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。
但是在分布式系统中，在“检查消费状态，然后更新数据并且设置消费状态”中，三个操作必须作为一组操作保证原子性，才能真正实现幂等，否则就会出现 Bug。
一般可以通过分布式锁来保证原子性，或者使用分布式事务来实现。
## 消息积压的如何处理？
### 优化性能来避免消息积压
作为开发者，我们一般不太需要关注消息队列本身的性能，我们一般只需要关注，**在消息收发两端，我们的业务代码怎么合消息队列配合，达到一个最佳的性能。**
1. 发送端性能优化
在线业务比较在意的是时延，所以在线业务我们如果是使用的rpc框架，直接在每次请求的线程中直接发送消息即可，因为rpc框架都是多线程支持多并发的，所以这种情况下，比较明智的方式就是通过并发来提升发送性能。
离线系统一般不关注时延，而是更注重整个系统的吞度量，这种情况更适合批量发送，同样用少量的并发就可以获得非常高的吞吐量。
2. 消费端性能优化
如果消费速度一直比生产慢，时间长了，整个系统就会出现问题，要么，消息队列的存储被填满无法提供服务，要么消息丢失，这对于整个系统来说都是严重故障。所以，**一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。**
消费端的性能优化除了优化消费业务逻辑以外，也可以通过水平扩容，增加消费端的并发数来提升总体的消费性能。特别需要注意的一点是，**在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。**如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。原因我们之前讲过，因为对于消费者来说，在每个分区上实际上只能支持单线程消费。**
### 消息积压该如何处理
快速解决消息积压的方法是，水平扩容消费者的实力数量。如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。
还需要看监控生产和消费速度和原来都没有什么变化，这时候需要检查消费端，是不是有消息消费失败在不断重复消费，或者像rabbitmq中的延迟消息的消息时间不一致，导致前面的消息被阻塞。
如果监控到消费变慢了，你需要检查你的消费实例，分析一下是什么原因导致消费变慢。优先检查一下日志是否有大量的消费错误，如果没有错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。

## Kafka如何实现高性能IO
### 使用批量消息提升服务端处理能力
### 使用顺序读写提升磁盘IO性能
Kafka的存储设计非常简单，对于每个分区，它把从Producer收到的消息，顺序地写入对应的log文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个log文件中的某个位置开始，顺序地把消息读出来。
### 利用PageCache加速消息读写
Kafka在读写消息文件的时候，充分利用了PageCache的特性。一般来说，消息刚刚写入到服务端就会被消费，按照LRU的"优先清除最近最少使用的页"这种策略，读取的时候，对于这种刚刚写入的PageCache，命中的几率会非常高。大部分情况下，消费读消息都会命中PageCache，带来的好处有两个：
- 读取的速度会非常快
- 读取走PageCache会给写入消息让出磁盘IO资源，间接也提升了写入的性能。
### ZeroCopy：零拷贝技术 来进一步提升消费的性能
所谓零拷贝就是直接从PageCache中把数据复制到Socket缓冲区中，这样可以减少从PageCache将数据复制到用户内存空间，DMA控制器可以直接完成数据复制，不需要CPU参与，速度更快。
下面是零拷贝对应的系统调用：
```c
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

Kafka消费模型的几个要点：
- Kafka的每个Consumer (消费者) 实例属于一个ConsumerGroup(消费组)；
- 在消费时，ConsumerGroup 中的每个Consumer独占一个或多个Partition(分区)；
- 对于每个ConsumerGroup，在任意时刻，每个Partition至多有一个Consumer至多有1个Consumer在消费；
- 每个ConsumerGroup都有一个Coordinator (协调者) 负责分配 Consumer 和 Partition的对应关系，当Partition或是Consumer发生变更时，会触发rebalance (重新分配) 过程，重新分配Consumer 与 Partition 的对应关系；
- Consumer 维护与Coordinator之间的心跳，这样Coordinator就能感知到Consumer的状态，在Consumer故障的时候及时触发rebalance。

RocketMQ NameSever在急群中起到的一个核心作用就是，为客户端提供路由信息，帮助客户端找到对应的Broker。

每个NameServer节点上都保存了集群所有Broker的路由信息，可以独立提供服务。Broker会与所有NameServer节点建立长连接，定期上报Broker的路由信息。客户端会选择连接某一个NameServer节点，定期获取订阅主题的路由信息，用于Broker寻址。

NameServer的所有核心功能都是在RouteInfoManager这个类中实现的，这类中使用了几个Map来在内存中保存集群中所有Broker的路由信息。

![[Pasted image 20250115110003.png]]
## Zookeeper
Zookeeper是一个分布式的协调服务，它的核心服务是一个高可用、高可靠的一致性存储，在此基础上，提供了包括读写元数据、节点监控、选举、节点间通信和分布式锁等很多功能，**这些功能可以极大的方便我们快速开发一个分布式的集群系统。**

使用Zookeeper时需要注意的几个问题：
1. 不要往Zookeeper里面写入大量数据，它不是一个真正意义上的存储系统，只适合存放少量的数据。依据服务器配置的不同，Zookeeper在写入超过几百MB数据之后，性能和稳定性都会严重下降。
2. 不要让业务集群的可用性依赖于Zookeeper的可用性，因为Zookeeper的选举过程是比较慢的，而它对网络的抖动又比较敏感，一旦触发选举，这段时间内的Zookeeper是不能提供任何服务的。
Kafka主要使用Zookeeper来保存它的元数据、监控Broker和分区的存活状态，并利用Zookeeper来进行选举。

Kafka在Zookeeper中保存的元数据，主要就是Broker的列表和主题分区信息两颗树。这份元数据同时也被缓存到每一个Broker中。客户端并不直接和Zookeeper来通信，而是在需要的时候，通过RPC请求去Broker上拉取它关心的主题的元数据，然后保存到客户端的元数据缓存中，以便支撑客户端生产和消费。
![[Pasted image 20250115184518.png]]

## RocketMQ和Kafja中的事务实现
RocketMQ中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且，RocketMQ增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。

而Kafka中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功过，要么都失败。注意，这里面的多条消息不一定要在同一个主题和分区中，可以是发往多个主题和分区的消息。当然，你可以在Kafka的事务执行过程中，加入本地事务，来实现和RocketMQ中事务类似的效果，但是Kafka是没有事务反查机制的。

### Kafka中的Exactly Once主要是为了解决什么问题？
它解决的是，在流计算中，用Kafka作为数据源，并且将计算结果保存到Kafka这种场景下，数据从Kafka的某个主题中消费，在计算集群中计算，再把计算结果保存在Kafka的其他主题中。这样的过程中，保证每条消息都被恰好计算一次，确保计算结果正确。
![[Pasted image 20250116165520.png]]
### Kafka的事务实现
![[Pasted image 20250116165632.png]]
首先，当我们开启事务的时候，生产者会给协调者发一个请求来开启事务，协调者在事务日志中记录下事务ID。

然后，生产者在发送消息之前，还要给协调者发送请求，告知发送的消息属于哪个主题和分区，这个信息也会被协调者记录在事务日志中。接下来，生产者就可以像发送普通消息一样来发送事务消息，直接发给Broker，保存这些消息对应的分区中，Kafka会在客户端的消费者中，暂时过滤未提交的事务消息。

消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，完成事务。第一阶段，协调者把事务的状态设置为"预提交"，并写入事务日志。到这里，实际上事务已经成功过了，无论接下来发生什么情况，事务最终都会被提交。

之后便开始第二阶段，协调者在事务相关的所有分区中，都会写一条"事务结束"的特殊消息，当Kafka的消费者，也就是客户端，读到这个事务结束的特殊消息之后，它就可以把之前暂时过滤的哪些未提交的事务消息，放行给业务代码进行消费了。最后，协调者记录最后一条事务日志，表示这个事务已经结束了。

![[Pasted image 20250116165646.png]]

### Kafka和RocketMQ事务实现的相同点：
它们在实现事务过程中，都是基于两阶段提交来实现事务的，都利用了特殊的主题中的队列和分区来记录事务日志。
### Kafka和RocketMQ事务实现的不同之处：
对处于事务中的消息的处理方式，RocketMQ是把这些消息暂存在一个特殊的队列中，待事务提交后再移动到业务队列中；而Kafka直接把消息放到对应的业务分区中，配合客户端过滤来暂时屏蔽进行中的事务消息。
